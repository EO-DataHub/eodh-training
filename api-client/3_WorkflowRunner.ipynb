{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Workflows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Description & purpose__: A set of code snippets and guidance to help users submit and execute workflows using the pyeodh API client.   \n",
    "\n",
    "__Author(s)__: Alastair Graham, Dusan Figala\n",
    "\n",
    "__Date created__: 2024-09-10\n",
    "\n",
    "__Date last modified__: 2024-12-10\n",
    "\n",
    "__Licence__: This notebook is licensed under [Creative Commons Attribution-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-sa/4.0/).  The code is released using the [BSD-2-Clause](https://www.tldrlegal.com/license/bsd-2-clause-license-freebsd) license.\n",
    "\n",
    "\n",
    "<span style=\"font-size:0.75em;\">\n",
    "Copyright (c) , All rights reserved.</span>\n",
    "\n",
    "<span style=\"font-size:0.75em;\">\n",
    "Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</span>\n",
    "\n",
    "<span style=\"font-size:0.75em;\">\n",
    "Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "This notebook demonstrates how to use the EODH API through `pyeodh` to interact with the Workflow Runner (WR). \n",
    "\n",
    "The EODH platform provides access to a component called the Application Deployment & Execution Service (ADES), otherwise known as the WR. To this, a user can deploy CWL workflows and execute parametrised processing jobs. `pyeodh` provides an interface to simplify interaction with ADES from python scripts.\n",
    "\n",
    "# How-to\n",
    "\n",
    "**Note**: This API requires authentication credentials to be provided by the user (in this case read from environment variables). This is a subject to change as the hub is implementing proper IAM solution. For information about obtaining API credentials, please see the [page introducing the API client](1_ClientIntro.html).\n",
    "\n",
    "**Note**: Once you have the necessary API token, create a .env file and point `dotenv_path` (see below) at the file. The file should contain at lease two lines in the following format:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "ADES_USER=username\n",
    "ADES_TOKEN=api_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where username and api_token are the values you use on the system.\n",
    "\n",
    "First we need to instantiate the `pyeodh` client and create an ADES entrypoint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# package imports\n",
    "from requests import HTTPError\n",
    "import os\n",
    "from pprint import pp\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "import pyeodh\n",
    "\n",
    "# import API token information\n",
    "dotenv_path = Path('reqts/.env')\n",
    "load_dotenv(dotenv_path=dotenv_path)\n",
    "\n",
    "username = os.getenv(\"ADES_USER\")\n",
    "token = os.getenv(\"ADES_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the link to ADES\n",
    "client = pyeodh.Client(username=username, token=token)\n",
    "ades = client.get_ades()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Workflows (represented as executable processes) are predefined applications which can be parameterised and run by users. To get a list of currently available processes in our user workspace we need to implement the `ades.get_processes()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "echo\n",
      "convert-url\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for p in ades.get_processes():\n",
    "    print(p.id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we can see how many workflows are in the workspace, it is possible to fetch information about a specific workflow (assuming the user knows its name). The process object also contains metadata giving us more information about the process and how to execute it. \n",
    "\n",
    "For example, it is possible to interrogate the schema of inputs. From this it is possible to parameterise the process, or set the output schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Schema\n",
      "{'fn': {'title': 'the operation to perform',\n",
      "        'description': 'the operation to perform',\n",
      "        'schema': {'type': 'string'}},\n",
      " 'size': {'title': 'the percentage for a resize operation',\n",
      "          'description': 'the percentage for a resize operation',\n",
      "          'schema': {'type': 'string'}},\n",
      " 'url': {'title': 'the image to convert',\n",
      "         'description': 'the image to convert',\n",
      "         'schema': {'type': 'string'}}}\n",
      "----------------------------------------\n",
      "Output Schema\n",
      "{'converted_image': {'title': 'converted_image',\n",
      "                     'description': 'None',\n",
      "                     'extended-schema': {'oneOf': [{'allOf': [{'$ref': 'http://zoo-project.org/dl/link.json'},\n",
      "                                                              {'type': 'object',\n",
      "                                                               'properties': {'type': {'enum': ['application/json']}}}]},\n",
      "                                                   {'type': 'object',\n",
      "                                                    'required': ['value'],\n",
      "                                                    'properties': {'value': {'oneOf': [{'type': 'object'}]}}}]},\n",
      "                     'schema': {'oneOf': [{'type': 'object'}]}}}\n"
     ]
    }
   ],
   "source": [
    "convert_url_proc = ades.get_process(\"convert-url\")\n",
    "\n",
    "print('Input Schema')\n",
    "pp(convert_url_proc.inputs_schema)\n",
    "\n",
    "print('-'*40)\n",
    "\n",
    "print('Output Schema')\n",
    "pp(convert_url_proc.outputs_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further information can be found out about the process object, including its id, process_id (name) and its status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "672f0742-b6f5-11ef-a8b0-6a040e2afd6f convert-url successful\n"
     ]
    }
   ],
   "source": [
    "for j in ades.get_jobs():\n",
    "    print(j.id, j.process_id, j.status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only one process with the same ID can exist. To demonstrate deploying a process further down in this notebook, we first need to undeploy `convert-url`. Note that attempting to delete a non-existent process will result in an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    ades.get_process(\"convert-url\").delete()\n",
    "except HTTPError:\n",
    "    print(\"Process not found, no need to undeploy.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's deploy the `convert-url` process again. \n",
    "\n",
    "There are two ways we can provide the CWL file - either referencing the file by URL or by passing the CWL file content directly. Note that the `ades.deploy_process()` command will fail if we try to create a process with an ID that already exists. If we want to update an existing process, we should use the `process.update()` method instead. \n",
    "\n",
    "Both methods can handle URL or CWL YAML inputs. In the example below a process referenced by URL is deployed and then updated by passing the new CWL YAML content directly. \n",
    "\n",
    "**Note**: When updating a worklow you need to provide the entire workflow, the API does not support partial updates (i.e. to change the description we need to provide the entire workflow again)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert-url Convert URL\n"
     ]
    }
   ],
   "source": [
    "convert_url_proc = ades.deploy_process(\n",
    "    cwl_url=\"https://raw.githubusercontent.com/EOEPCA/deployment-guide/main/deploy/samples/requests/processing/convert-url-app.cwl\"\n",
    ")\n",
    "print(convert_url_proc.id, convert_url_proc.description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "convert-url Convert URL YAML\n"
     ]
    }
   ],
   "source": [
    "cwl_yaml = \"\"\"cwlVersion: v1.0\n",
    "$namespaces:\n",
    "  s: https://schema.org/\n",
    "s:softwareVersion: 0.1.2\n",
    "schemas:\n",
    "  - http://schema.org/version/9.0/schemaorg-current-http.rdf\n",
    "$graph:\n",
    "  # Workflow entrypoint\n",
    "  - class: Workflow\n",
    "    id: convert-url\n",
    "    label: convert url app\n",
    "    doc: Convert URL YAML\n",
    "    requirements:\n",
    "      ResourceRequirement:\n",
    "        coresMax: 1\n",
    "        ramMax: 1024\n",
    "    inputs:\n",
    "      fn:\n",
    "        label: the operation to perform\n",
    "        doc: the operation to perform\n",
    "        type: string\n",
    "      url:\n",
    "        label: the image to convert\n",
    "        doc: the image to convert\n",
    "        type: string\n",
    "      size:\n",
    "        label: the percentage for a resize operation\n",
    "        doc: the percentage for a resize operation\n",
    "        type: string\n",
    "    outputs:\n",
    "      - id: converted_image\n",
    "        type: Directory\n",
    "        outputSource:\n",
    "          - convert/results\n",
    "    steps:\n",
    "      convert:\n",
    "        run: \"#convert\"\n",
    "        in:\n",
    "          fn: fn\n",
    "          url: url\n",
    "          size: size\n",
    "        out:\n",
    "          - results\n",
    "  # convert.sh - takes input args `--url`\n",
    "  - class: CommandLineTool\n",
    "    id: convert\n",
    "    requirements:\n",
    "      ResourceRequirement:\n",
    "        coresMax: 1\n",
    "        ramMax: 512\n",
    "    hints:\n",
    "      DockerRequirement:\n",
    "        dockerPull: eoepca/convert:latest\n",
    "    baseCommand: convert.sh\n",
    "    inputs:\n",
    "      fn:\n",
    "        type: string\n",
    "        inputBinding:\n",
    "          position: 1\n",
    "      url:\n",
    "        type: string\n",
    "        inputBinding:\n",
    "          position: 2\n",
    "          prefix: --url\n",
    "      size:\n",
    "        type: string\n",
    "        inputBinding:\n",
    "          position: 3\n",
    "    outputs:\n",
    "      results:\n",
    "        type: Directory\n",
    "        outputBinding:\n",
    "          glob: .\n",
    "\"\"\"\n",
    "\n",
    "convert_url_proc.update(cwl_yaml=cwl_yaml)\n",
    "print(convert_url_proc.id, convert_url_proc.description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process needs to be parameterised before it is run, but how does a user know what inputs this particular workflow is expecting? That is where the `process.inputs_schema` response is useful (see above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's execute the deployed process. The inputs are best supplied as a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "007b69d0-b70b-11ef-aba4-6a040e2afd6f running ZOO-Kernel accepted to run your service!\n"
     ]
    }
   ],
   "source": [
    "convert_url_job = convert_url_proc.execute(\n",
    "    {\n",
    "        \"fn\": \"resize\",\n",
    "        \"url\": \"https://eoepca.org/media_portal/images/logo6_med.original.png\",\n",
    "        \"size\": \"50%\",\n",
    "    }\n",
    ")\n",
    "\n",
    "print(convert_url_job.id, convert_url_job.status, convert_url_job.message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The job should now be running. \n",
    "\n",
    "To get the most up-to-date status of the job the user can call the `job.refresh()` method and then interrogate the `job.status` and `job.message` properties. \n",
    "\n",
    "**Note**: these properties only hold the latest response from the API, and don't keep any historical records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "007b69d0-b70b-11ef-aba4-6a040e2afd6f running upload required files\n"
     ]
    }
   ],
   "source": [
    "convert_url_job.refresh()\n",
    "print(convert_url_job.id, convert_url_job.status, convert_url_job.message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Status: running\n",
      "Message: execution submitted\n",
      "Message: delivering outputs, logs and usage report\n",
      "\n",
      "\n",
      "Status: successful\n",
      "Message: ZOO-Kernel successfully run your service!\n"
     ]
    }
   ],
   "source": [
    "# We can continually poll the job using a simple loop and print status and message updates like so:\n",
    "\n",
    "from pyeodh.ades import AdesJobStatus\n",
    "import time\n",
    "\n",
    "\n",
    "old_status = \"\"\n",
    "old_message = \"\"\n",
    "while convert_url_job.status == AdesJobStatus.RUNNING.value:\n",
    "    time.sleep(2)\n",
    "    convert_url_job.refresh()\n",
    "    if convert_url_job.status != old_status:\n",
    "        print(\"\\n\")\n",
    "        print(f\"Status: {convert_url_job.status}\")\n",
    "    if convert_url_job.message != old_message:\n",
    "        print(f\"Message: {convert_url_job.message}\")\n",
    "\n",
    "    old_status = convert_url_job.status\n",
    "    old_message = convert_url_job.message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the job has finished successfully, we can view the results as a link to where the data files are stored.\n",
    "\n",
    "**Note**: the outputs of a workflow is a directory conataining a STAC catalogue, where individual assets are represented in the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logo6_med.original-resize-1733844363.263300377 {'logo6_med.original-resize': <Asset href=https://ajgwords.workspaces.test.eodhp.eco-ke-staging.com/files/workspaces-eodhp-test/processing-results/cat_007b69d0-b70b-11ef-aba4-6a040e2afd6f/col_007b69d0-b70b-11ef-aba4-6a040e2afd6f/logo6_med.original-resize.png>}\n"
     ]
    }
   ],
   "source": [
    "results = convert_url_job.get_result_items()\n",
    "for res in results:\n",
    "    print(res.id, res.assets)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eodh",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
