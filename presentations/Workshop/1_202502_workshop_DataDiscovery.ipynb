{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa784be4",
   "metadata": {},
   "source": [
    "# Pathfinder Phase Workshop: Finding Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d48c75c",
   "metadata": {},
   "source": [
    "__Description & purpose__: This Notebook is designed to showcase the functionality of the Earth Observation Data Hub (EODH) as the project approaches the end of the Pathfinder Phase. It provides a snapshot of the Hub, the `pyeodh` API client and the various datasets as of February 2025.   \n",
    "\n",
    "__Author(s)__: Alastair Graham, Dusan Figala\n",
    "\n",
    "__Date created__: 2025-02-18\n",
    "\n",
    "__Date last modified__: 2025-02-20\n",
    "\n",
    "__Licence__: This notebook is licensed under [Creative Commons Attribution-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-sa/4.0/).  The code is released using the [BSD-2-Clause](https://www.tldrlegal.com/license/bsd-2-clause-license-freebsd) license.\n",
    "\n",
    "\n",
    "<span style=\"font-size:0.75em;\">\n",
    "Copyright (c) , All rights reserved.</span>\n",
    "\n",
    "<span style=\"font-size:0.75em;\">\n",
    "Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</span>\n",
    "\n",
    "<span style=\"font-size:0.75em;\">\n",
    "Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f17701",
   "metadata": {},
   "source": [
    "# Visual data discovery\n",
    "\n",
    "# STAC Browser\n",
    "\n",
    "The first thing to do is find some data. Initially we will be using the current Catalogue User Interface which is an implementation of the STAC Browser (**Note**: a replacement user interface is in development, as demonstrated in the Workshop). When visiting the Catalogue you should see a page not too dissimilar to the following screenshot.\n",
    "\n",
    "![](images/07a.png \"Data Catalogue\")\n",
    "\n",
    "Click on the `Search` button in the top left of the page (next to *Browse*) and start to enter some details under `search for items`. We will look for data between 12 Nov and 19 Nov 2023, in the Thetford area, in the sentinel2_ard collection. The details are shown in the next screenshot. \n",
    "\n",
    "![](images/08a.png \"Data search\")\n",
    "\n",
    "Once you click `Submit` the the search should return a series of image items to the right of the page, as shown below. \n",
    "\n",
    "![](images/09a.png \"Search result\")\n",
    "\n",
    "\n",
    "We are looking for the following item (S2A_20231117_latn527lone0008_T30UYD_ORB137_20231117131218_utm30n_osgb) and the reference will be as shown here:\n",
    "\n",
    "![](images/10a.png \"Item information\")\n",
    "\n",
    "Click on the relevant item to find the assets within it. There are a number of assets (data layers, metadata, thumbnail etc.) within the item. Take some time to investigate what exists. The two we are interested in here are `thumbnail` and `cog` (the cog holds the image data). The image below shows how to copy the URL to the COG data: either using the button on the left or copying the path in the text box on the right.\n",
    "\n",
    "Check that you have found the datset we are interested in:\n",
    "\n",
    "* Thumbnail: https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lone0008_T30UYD_ORB137_20231117131218_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_thumbnail.jpg (you can open this in a web browser and it should look like the image below)\n",
    "* Dataset: https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lone0008_T30UYD_ORB137_20231117131218_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref.tif\n",
    "\n",
    "![](images/10.png \"Item thumbnail\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68f904f",
   "metadata": {},
   "source": [
    "Take some time to click around the listed datasets to see what is included and accessible. \n",
    "\n",
    "**Note** that **not all collections contain accessible items**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bba48e2",
   "metadata": {},
   "source": [
    "# Coded data discovery\n",
    "\n",
    "There are a number of API endpoints that are exposed by the EODH. Oxidian have developed a Python API Client, `pyeodh`, that makes the Hub's API endpoints available to Python users. `pyeodh` is available on PyPi (https://pypi.org/project/pyeodh/) and can be installed using `pip`. Documentation for the API Client is available at: https://pyeodh.readthedocs.io/en/latest/api.html\n",
    "\n",
    "We will use `pyeodh` throughout this workshop."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c4310b",
   "metadata": {},
   "source": [
    "## Presentation set up\n",
    "\n",
    "The following cell only needs to be run on the EODH AppHub.  If you have a local Python environment running, please install the required packages as you would normally e.g. using `mamba`, `poetry` etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a304de62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If needed you can install a package in the current AppHub Jupyter environment using pip\n",
    "# For instance, we will need at least the following libraries\n",
    "\n",
    "import sys\n",
    "!{sys.executable} -m pip install --upgrade pyeodh geopandas shapely matplotlib numpy pillow folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a1f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pyeodh\n",
    "\n",
    "import shapely as sh \n",
    "import geopandas as gpd\n",
    "import folium\n",
    "\n",
    "import urllib.request\n",
    "from requests.exceptions import HTTPError\n",
    "\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d99ae0",
   "metadata": {},
   "source": [
    "Having imported the necessary libraries the next task is to set up the locations of the areas of interest.\n",
    "Having created the AOI points the user needs to connect to the Resource Catalogue so that they can start to find some data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5ce9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Areas of Interest\n",
    "thet_pnt = sh.Point(0.6715892933273722, 52.414471075812315) # a site near Thetford"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d3bc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional cell\n",
    "# If you want to see these points on a map run this cell\n",
    "# You may need to run the notebook through a service such as nbviewer: https://nbviewer.org/\n",
    "\n",
    "# Create a map (m) centered on the point\n",
    "center_lat = (thet_pnt.y)\n",
    "center_lon = (thet_pnt.x)\n",
    "\n",
    "m = folium.Map(location=[center_lat, center_lon], zoom_start=10)\n",
    "\n",
    "# Add markers for the point\n",
    "folium.Marker([thet_pnt.y, thet_pnt.x], popup=\"Thetford Site\", icon=folium.Icon(color=\"green\")).add_to(m)\n",
    "\n",
    "# Step 4: Display the map\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c25257",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Hub\n",
    "# base_url can be changed to optionally specify a different server, such as test.eodatahub\n",
    "\n",
    "client = pyeodh.Client(\n",
    "    base_url=\"https://staging.eodatahub.org.uk\"\n",
    ").get_catalog_service()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b87e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print a list of the collections held in the Resource Catalogue (their id and description).\n",
    "# As the Resource Catalogue fills and development continues, the number of collections and the richness of their descriptions will increase\n",
    "\n",
    "for index, collect in enumerate(client.get_collections(), start=1):\n",
    "    print(f\"{index} -- {collect.id}: {collect.description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6ff28d",
   "metadata": {},
   "source": [
    "The dataset that we are interested in for the purposes of this workshop is `sentinel2_ard`. As seen from the output from the previous cell, we can see that the description of the dataset is as follows:\n",
    "\n",
    "_These data have been created by the Department for Environment, Food and Rural Affairs (Defra) and Joint Nature Conservation Committee (JNCC) in order to cost-effectively provide high quality, Analysis Ready Data (ARD) for a wide range of applications. The dataset contains modified Copernicus Sentinel-2 (Level 1C data processed into a surface reflectance product using ARCSI software (Level 2))._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9dc811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The next thing to do is find some open data\n",
    "# For this workshop we want to find Sentinel-2 analysis ready (ARD) imagery near Thetford\n",
    "\n",
    "# First we just want to understand the timespan of the dataset which is reported from the STAC collection record\n",
    "sentinel2_ard = client.get_catalog(\"supported-datasets/catalogs/ceda-stac-catalogue\").get_collection('sentinel2_ard')\n",
    "sentinel2_ard.get_items()\n",
    "\n",
    "print('DATASET TEMPORAL EXTENT: ', [str(d) for d in sentinel2_ard.extent.temporal.intervals[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b9c6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to access the first few items and see what they are called, when the image was collected and how much cloud there is  \n",
    "\n",
    "lim = 10\n",
    "\n",
    "for i, item in enumerate(sentinel2_ard.get_items()):\n",
    "    if i >= lim:\n",
    "        break\n",
    "    print(item.id, item.properties['datetime'], item.properties['eo:cloud_cover'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83a60ea",
   "metadata": {},
   "source": [
    "The previous cell shows us that we are able to access Sentinel 2 ARD data and find out a number of bits of information about the item. If you are interested in seeing what other information is accessible, have a look at the \n",
    "\n",
    "* collection endpoint: https://staging.eodatahub.org.uk/api/catalogue/stac/catalogs/supported-datasets/catalogs/ceda-stac-catalogue/collections/sentinel2_ard\n",
    "* items endpoint: https://staging.eodatahub.org.uk/api/catalogue/stac/catalogs/supported-datasets/catalogs/ceda-stac-catalogue/collections/sentinel2_ard/items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba67740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To find specific imagery for the Thetford site we need to add the intersects parameter. We set this to be our AOI point.\n",
    "\n",
    "items = client.search(\n",
    "    collections=['sentinel2_ard'],\n",
    "    catalog_paths=[\"supported-datasets/catalogs/ceda-stac-catalogue\"],\n",
    "    intersects=thet_pnt,\n",
    "    query=[\n",
    "        'start_datetime>=2023-11-01',\n",
    "        'end_datetime<=2023-11-30', \n",
    "    ],\n",
    ")\n",
    "\n",
    "# We can then count the number of items returned by the search \n",
    "#print('Number of items found: ', items.total_count)\n",
    "\n",
    "total_items = sum(1 for _ in items)\n",
    "print(f\"Total items: {total_items}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a830d3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can print out the item names so that we understand which images we are looking at\n",
    "\n",
    "for item in items:\n",
    "    print(f\"Item ID: {item.id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce13932",
   "metadata": {},
   "source": [
    "Once we have found the intersecting images and know their names we can choose the image item that we are interested. For the purposes of this exercise this is T31UCU. Now we need to know what assets are held for that item. The following code prints out all the STAC information linked to that item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74efdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in items[:1]:  # Process only the first item\n",
    "    print(f\"Item ID: {item.id}\")\n",
    "    print(\"Assets:\")\n",
    "    \n",
    "    if not item.assets:\n",
    "        print(\"  No assets available.\")\n",
    "    else:\n",
    "        for asset_key, asset in item.assets.items():\n",
    "            print(f\"  - {asset_key}: {asset.to_dict()}\")  # Convert asset to dict for readable output\n",
    "            print(\"-\" * 40)  # Separator for better readability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a694cfa8",
   "metadata": {},
   "source": [
    "From this we can see that there is a thumbnail. Before we do anything with the full image data or associated assets it would be good to understand the image. We can extract the URL to the thumbnail and view the attached image file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e83599",
   "metadata": {},
   "outputs": [],
   "source": [
    "tn_url = None\n",
    "\n",
    "for item in items[:1]:  # Process only the first item\n",
    "    #print(f\"Item ID: {item.id}\")\n",
    "    #print(\"Assets:\")\n",
    "    \n",
    "    if not item.assets:\n",
    "        print(\"  No assets available.\")\n",
    "    else:\n",
    "        for asset_key, asset in item.assets.items():\n",
    "            #print(f\"  - {asset_key}: {asset.to_dict()}\")  # Convert asset to dict for readable output\n",
    "            if asset_key == \"thumbnail\":\n",
    "                tn_url = asset.href  # Directly access the href attribute\n",
    "    \n",
    "    #print(\"-\" * 40)  # Separator for better readability\n",
    "print(tn_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386c2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use this information to view the image thumbnail\n",
    "\n",
    "# Here we open the remote URL, read the data and dislay the thumbnail \n",
    "with urllib.request.urlopen(tn_url) as url:\n",
    "    img = Image.open(BytesIO(url.read()))\n",
    "\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7261b520",
   "metadata": {},
   "source": [
    "This shows that we can relatively easily interrogate the Resource Catalogue and filter the results so that we can find the data we require in the EODH. With a bit of tweaking of the code the user could also generate a list of assets and accompanying URLs to the datasets (for this and other datasets). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a46583bf",
   "metadata": {},
   "source": [
    "Now we want to see what commercial data exists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eae423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find some Airbus commercial data: SPOT\n",
    "\n",
    "count = 0\n",
    "lim = 15\n",
    "\n",
    "for i in client.search(\n",
    "    catalog_paths=[\"supported-datasets/catalogs/airbus\"],\n",
    "    collections=[\"airbus_spot_data\"],\n",
    "):\n",
    "    if count >= lim:\n",
    "        break\n",
    "    print(i.id)\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad94a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find some Planet commercial data: Planetscope Scene\n",
    "count = 0\n",
    "try:\n",
    "    cat = client.get_catalog(\"supported-datasets/catalogs/planet\")\n",
    "    for i in cat.search(collections=[\"PSScene\"]):\n",
    "        if count >= lim:\n",
    "            break\n",
    "        print(i.id)\n",
    "        count+= 1\n",
    "except HTTPError as e:\n",
    "    if \"422 Client Error: Unprocessable Entity\" in str(e):\n",
    "        print(\"Skipping E422\")\n",
    "    else:\n",
    "        raise  # Re-raise other errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8e85cd6",
   "metadata": {},
   "source": [
    "The final step would be to use the ordering service integrated into the EODH resource catalogue to purchase the required commercial imagery. This would be stored in a users workspace and could then be used in specific workflows or for data analytics (depending on licence restrictions).\n",
    "\n",
    "For the purposes of this workshop we looked at the different commercial datasets offline in QGIS. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workshop",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
