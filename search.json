[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EODH Training Materials",
    "section": "",
    "text": "Welcome\nThis site is in heavy development.\nWelcome to the eodh-training repository! This repository aims to provide a live set of documents to demonstrate how to use the EODH (Earth Observation Data Hub) and associated tools such as the pyeodh Python API client, workflow generator and QGIS plugin. Other training materials may be added to this repository in future.\nWhether you’re a user looking to explore the project or a developer wanting to contribute, you’ll find all the information you need here.\n\n\nContent\nYou’ll be able to find the content you require by navidating through this website using the sidebar to the left.\n\n\nAdditional Support\nWe have set up an accessible Discussion Group as a location that users can interact with other users, as well as the Hub owners and developers. Please use this resource to build a vibrant community around the EODH platform. It is also accessible via the GitHub icon at the top of every page.\nIf you require specific development information on the API client then please check out the ReadTheDocs page for the client.\n\nThis website is made using Quarto.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "workflows/1_workflows.html",
    "href": "workflows/1_workflows.html",
    "title": "What is a Workflow",
    "section": "",
    "text": "What is CWL?\n\n\nWhat is the Workflow Runner?\n\n\nWhat is the Workflow generator?",
    "crumbs": [
      "Workflows",
      "Workflow Introduction"
    ]
  },
  {
    "objectID": "api-client/planet-stac-proxy.html",
    "href": "api-client/planet-stac-proxy.html",
    "title": "Planet STAC Example",
    "section": "",
    "text": "Demo of retrieving data from Planet via their STAC proxy api using the PySTAC Client. Requires an api-key saved in as .planet.json which has the content {\"key\": \"API_KEY\"}.\n\nimport base64\nfrom pystac_client import Client\nimport requests\nfrom shapely import Point\nimport planet\nfrom IPython.display import Image\n\napi_key = planet.Auth.from_file().value\n\nuserpass = f\"{api_key}:\"\n\nheaders = {\n    \"Authorization\": f\"Basic {base64.b64encode(userpass.encode()).decode()}\"\n}\n\n\nclient = Client.open(\n    url=\"https://api.planet.com/x/data/\",\n    headers=headers\n)\n\nitem_search = client.search(\n    collections=['PSScene'],\n    datetime='2024-06-01/2024-08-01',\n    intersects=Point(-111, 45.68),\n    filter={\n        \"op\": \"&gt;=\",\n        \"args\": [{\"property\": \"clear_percent\"}, 50]\n    }\n)\n\nitem = next(item_search.items())\nthumbnail = requests.get(item.assets[\"thumbnail\"].href, headers=headers)\nImage(data=thumbnail.content)\n\n\n\n\n\n\n\n\n\nimport pyeodh\nimport base64\nfrom io import BytesIO\nfrom pystac_client import Client\nimport requests\nfrom shapely import Point\nimport planet\nfrom IPython.display import Image\n\napi_key = planet.Auth.from_file().value\n\nuserpass = f\"{api_key}:\"\n\nheaders = {\n    \"Authorization\": f\"Basic {base64.b64encode(userpass.encode()).decode()}\"\n}\n\nclient = pyeodh.Client(username=api_key).get_catalog_service()\nitem_search = client.search(\n    collections=['PSScene'],\n    datetime='2024-06-01/2024-08-01',\n    intersects=Point(-111, 45.68),\n    filter={\n        \"op\": \"&gt;=\",\n        \"args\": [{\"property\": \"clear_percent\"}, 50]\n    }\n)\n\nitem = item_search[0]\nthumbnail = requests.get(item.assets[\"thumbnail\"].href, headers=headers)\nImage(data=thumbnail.content)\n\n\n---------------------------------------------------------------------------\nHTTPError                                 Traceback (most recent call last)\nCell In[10], line 29\n     18 client = pyeodh.Client(username=api_key).get_catalog_service()\n     19 item_search = client.search(\n     20     collections=['PSScene'],\n     21     datetime='2024-06-01/2024-08-01',\n   (...)\n     26     }\n     27 )\n---&gt; 29 item = item_search[0]\n     30 thumbnail = requests.get(item.assets[\"thumbnail\"].href, headers=headers)\n     31 Image(data=thumbnail.content)\n\nFile ~/.local/lib/python3.11/site-packages/pyeodh/pagination.py:82, in PaginatedList.__getitem__(self, index)\n     80 def __getitem__(self, index: int) -&gt; T:\n     81     assert isinstance(index, int)\n---&gt; 82     self._fetch_to_index(index)\n     83     return self._elements[index]\n\nFile ~/.local/lib/python3.11/site-packages/pyeodh/pagination.py:87, in PaginatedList._fetch_to_index(self, index)\n     85 def _fetch_to_index(self, index: int) -&gt; None:\n     86     while len(self._elements) &lt;= index and self._has_next():\n---&gt; 87         new_elements = self._fetch_next()\n     88         self._elements += new_elements\n\nFile ~/.local/lib/python3.11/site-packages/pyeodh/pagination.py:96, in PaginatedList._fetch_next(self)\n     94 if not self._next_url:\n     95     raise RuntimeError(\"Next url not specified!\")\n---&gt; 96 headers, resp_data = self._client._request_json(\n     97     self._method,\n     98     self._next_url,\n     99     headers=self._headers,\n    100     params=self._params,\n    101     data=self._data,\n    102 )\n    103 next_link = next(\n    104     filter(lambda ln: ln.get(\"rel\") == \"next\", resp_data.get(\"links\", {})), {}\n    105 )\n    106 self._next_url = next_link.get(\"href\")\n\nFile ~/.local/lib/python3.11/site-packages/pyeodh/client.py:102, in Client._request_json(self, method, url, headers, params, data, encode)\n     93 def _request_json(\n     94     self,\n     95     method: RequestMethod,\n   (...)\n    100     encode: Callable[[Any], tuple[str, Any]] = _encode_json,\n    101 ) -&gt; tuple[Headers, Any]:\n--&gt; 102     status, resp_headers, resp_data = self._request_json_raw(\n    103         method, url, headers, params, data, encode\n    104     )\n    106     if not len(resp_data):\n    107         return resp_headers, None\n\nFile ~/.local/lib/python3.11/site-packages/pyeodh/client.py:89, in Client._request_json_raw(self, method, url, headers, params, data, encode)\n     82 logger.debug(\n     83     f\"Received response {response.status_code}\\nheaders: {response.headers}\"\n     84     f\"\\ncontent: {response.text}\"\n     85 )\n     86 # TODO consider moving this to _requst_json() and raise own exceptions\n     87 # so that we can user _raw in e.g. delete methods where we expect a 409 and\n     88 # want to recover\n---&gt; 89 response.raise_for_status()\n     91 return response.status_code, response.headers, response.text\n\nFile /opt/jaspy/lib/python3.11/site-packages/requests/models.py:1024, in Response.raise_for_status(self)\n   1019     http_error_msg = (\n   1020         f\"{self.status_code} Server Error: {reason} for url: {self.url}\"\n   1021     )\n   1023 if http_error_msg:\n-&gt; 1024     raise HTTPError(http_error_msg, response=self)\n\nHTTPError: 400 Client Error: Bad Request for url: https://test.eodatahub.org.uk/api/catalogue/stac/search"
  },
  {
    "objectID": "api-client/2_ResourceCatalog.html",
    "href": "api-client/2_ResourceCatalog.html",
    "title": "Resource Catalog",
    "section": "",
    "text": "This notebook demostrates usage of the EODH resource catalog API using pyeodh\n\n\n\na clear description of purpose,\nintended audience and/or use case\nlinkages between notebooks and other training resources (if required)\n\n\n\n\n\nTechnical dependencies,\nPlatform and Service Dependencies,\nPython Language versions,\nlibraries, additional scripts and files.\n\n\n\n\n“When Jupyter notebooks are used in an educational context, they should not only be conceptualized to teach a specific topic but should also set a good example by following and implementing best practices for scientific computing”\n\nNeed in-order execution of notebook cells\nGood-quality code\nNo code duplication\nImports at the beginning of a notebook\nConsistent code style and formatting\nMeaningful names for variables\nLicence for code and training resources\n\n\nDescription & purpose:\nAuthor(s):\nDate created:\nDate last modified:\nLicence: This notebook is released under Creative Commons …. The code is released using …\nFirst we need to create an instance of the Client, which is our entrypoint to EODH APIs.\n\nimport pyeodh\n\nclient = pyeodh.Client(base_url=\"https://test.eodatahub.org.uk\") # Optionally specify a different server\n\nFetch the resource catalog object.\n\n# GET /stac-fastapi/catalogs\nservice = client.get_catalog_service()\ncatalogs = service.get_catalogs()\nceda_cat = service.get_catalog(\"supported-datasets/ceda-stac-fastapi\")\n\nAll attributes are mapped to properties, e.g.\n\nprint(\"id: \", catalogs.id)\n#print(\"title: \", rc.title)\n#print(\"description: \", rc.description)\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 print(\"id: \", catalogs.id)\n      2 #print(\"title: \", rc.title)\n      3 #print(\"description: \", rc.description)\n\nAttributeError: 'list' object has no attribute 'id'\n\n\n\nAPI endpoints are wrapped in methods and are structured into classes following the same logic as the API. E.g. to fetch a collection item, I first need to get the collection from the resource catalog.\n\n# GET /stac-fastapi/collections/{collection_id}/items/{item_id}\ncmip6 = rc.get_collection(\"cmip6\")\nitem = cmip6.get_item(\"CMIP6.ScenarioMIP.THU.CIESM.ssp585.r1i1p1f1.Amon.rsus.gr.v20200806\")\nprint(item.id)\n\nSome API responses are paginated (e.g. collection items), and you can simply iterate over them.\n\n# GET /stac-fastapi/collections/cmip6/items\nitems = cmip6.get_items()\nfor item in items:\n    print(item.id)\n\nAttempting to create a collection with id that already exists will result in 409 error code. To see the example in action delete the test collection first by running the cell below.\nDelete a colletion\n\nrc.get_collection(\"test1\").delete()\n\nCreate new collection example\n\ntest1 = rc.create_collection(id=\"test1\", title=\"Test\", description=\"Test collection\")\nprint(test1.description)\n\nUpdate a collection\n\ntest1.update(description=\"Different description\")\nprint(test1.description)\n\nCreate an item\n\ntestitem1 = test1.create_item(id=\"test1.testitem1\")\nprint(f\"Created {testitem1.id} in collection {testitem1.collection}\")\n\nUpdate an item\n\ntestitem1.update(properties={\"foo\": \"bar\"})\nprint(testitem1.properties)\n\nDelete an item\n\ntestitem1.delete()\n\nFind out more about the Resource Catalog\n\nprint(f\"Livecheck: PING-{rc.ping()}\")\nprint(\"\\nAPI conforms to:\", *rc.get_conformance(), sep=\"\\n\")\n\nSearch the Catalog\n\nfor result in rc.search(collections=['cmip6']):\n    print(result.id)",
    "crumbs": [
      "API Client (pyeodh)",
      "Searching the Resource Catalogue"
    ]
  },
  {
    "objectID": "api-client/2_ResourceCatalog.html#remove-in-production-release",
    "href": "api-client/2_ResourceCatalog.html#remove-in-production-release",
    "title": "Resource Catalog",
    "section": "",
    "text": "This notebook demostrates usage of the EODH resource catalog API using pyeodh\n\n\n\na clear description of purpose,\nintended audience and/or use case\nlinkages between notebooks and other training resources (if required)\n\n\n\n\n\nTechnical dependencies,\nPlatform and Service Dependencies,\nPython Language versions,\nlibraries, additional scripts and files.\n\n\n\n\n“When Jupyter notebooks are used in an educational context, they should not only be conceptualized to teach a specific topic but should also set a good example by following and implementing best practices for scientific computing”\n\nNeed in-order execution of notebook cells\nGood-quality code\nNo code duplication\nImports at the beginning of a notebook\nConsistent code style and formatting\nMeaningful names for variables\nLicence for code and training resources\n\n\nDescription & purpose:\nAuthor(s):\nDate created:\nDate last modified:\nLicence: This notebook is released under Creative Commons …. The code is released using …\nFirst we need to create an instance of the Client, which is our entrypoint to EODH APIs.\n\nimport pyeodh\n\nclient = pyeodh.Client(base_url=\"https://test.eodatahub.org.uk\") # Optionally specify a different server\n\nFetch the resource catalog object.\n\n# GET /stac-fastapi/catalogs\nservice = client.get_catalog_service()\ncatalogs = service.get_catalogs()\nceda_cat = service.get_catalog(\"supported-datasets/ceda-stac-fastapi\")\n\nAll attributes are mapped to properties, e.g.\n\nprint(\"id: \", catalogs.id)\n#print(\"title: \", rc.title)\n#print(\"description: \", rc.description)\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 print(\"id: \", catalogs.id)\n      2 #print(\"title: \", rc.title)\n      3 #print(\"description: \", rc.description)\n\nAttributeError: 'list' object has no attribute 'id'\n\n\n\nAPI endpoints are wrapped in methods and are structured into classes following the same logic as the API. E.g. to fetch a collection item, I first need to get the collection from the resource catalog.\n\n# GET /stac-fastapi/collections/{collection_id}/items/{item_id}\ncmip6 = rc.get_collection(\"cmip6\")\nitem = cmip6.get_item(\"CMIP6.ScenarioMIP.THU.CIESM.ssp585.r1i1p1f1.Amon.rsus.gr.v20200806\")\nprint(item.id)\n\nSome API responses are paginated (e.g. collection items), and you can simply iterate over them.\n\n# GET /stac-fastapi/collections/cmip6/items\nitems = cmip6.get_items()\nfor item in items:\n    print(item.id)\n\nAttempting to create a collection with id that already exists will result in 409 error code. To see the example in action delete the test collection first by running the cell below.\nDelete a colletion\n\nrc.get_collection(\"test1\").delete()\n\nCreate new collection example\n\ntest1 = rc.create_collection(id=\"test1\", title=\"Test\", description=\"Test collection\")\nprint(test1.description)\n\nUpdate a collection\n\ntest1.update(description=\"Different description\")\nprint(test1.description)\n\nCreate an item\n\ntestitem1 = test1.create_item(id=\"test1.testitem1\")\nprint(f\"Created {testitem1.id} in collection {testitem1.collection}\")\n\nUpdate an item\n\ntestitem1.update(properties={\"foo\": \"bar\"})\nprint(testitem1.properties)\n\nDelete an item\n\ntestitem1.delete()\n\nFind out more about the Resource Catalog\n\nprint(f\"Livecheck: PING-{rc.ping()}\")\nprint(\"\\nAPI conforms to:\", *rc.get_conformance(), sep=\"\\n\")\n\nSearch the Catalog\n\nfor result in rc.search(collections=['cmip6']):\n    print(result.id)",
    "crumbs": [
      "API Client (pyeodh)",
      "Searching the Resource Catalogue"
    ]
  },
  {
    "objectID": "presentations/DEFRA/202409_Defra.html",
    "href": "presentations/DEFRA/202409_Defra.html",
    "title": "Demonstration for DEFRA",
    "section": "",
    "text": "Description & purpose: This Notebook is designed to showcase the initial functionality of the Earth Observation Data Hub. It provides a snapshot of the Hub, the pyeodh API client and the various datasets as of September 2024. The Notebook “user” would like to understand more about the satellite data available for their test areas. This user is also interested in obtaining a cloud free dataset and ultimately creating a data cube. The Notebook is designed in such a way that it can be run on the EODH AppHub (Notebook Service) or from a local environment.\nAuthor(s): Alastair Graham, Dusan Figala, Phil Kershaw\nDate created: 2024-09-05\nDate last modified: 2024-09-18\nLicence: This notebook is licensed under Creative Commons Attribution-ShareAlike 4.0 International. The code is released using the BSD-2-Clause license.\n Copyright (c) , All rights reserved.\n Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nLinks: * Oxidian: https://www.oxidian.com/ * CEDA: https://www.ceda.ac.uk/ * EO Data Hub: https://eodatahub.org.uk/\n\nWhat is the EODH?\nThe Earth Observation Data Hub is:\n“A UK Pathfinder project delivering access to Earth Observation (EO) data for effective decisionmaking across government, business and academia. The Earth Observation DataHub (EODH) brings together an expert project delivery team and industrial partners in an ambitious project… Users of the Hub will be able to explore areas of interest in the UK and across the globe… It will also enable selected users to support their own analyses, services and tools using the Hub’s workflow and compute environments.”\nMore details can be found online at https://eodatahub.org.uk/\nComponents of the Hub include: * A Resource Catalogue - a STAC compliant catalogue of open and commercial satellite imagery, climate data, model results, workflows and more * A Workflow Runner - a dedicated piece of cloud infrastructure to horizontally scale workflow requirements * A Web Presence - an intuitive user interface to allow account management, data discovery and mapping * An App Hub - a science portal providing access to a Jupyter lab environment\n\nPresentation set up\nThe following cell only needs to be run on the EODH AppHub. If you have a local Python environment running, please install the required packages as you would normally.\n\n# If needed you can install a package in the current AppHub Jupyter environment using pip\n# For instance, we will need the following libraries\nimport sys\n!{sys.executable} -m pip install --upgrade pyeodh pandas matplotlib numpy pillow folium\n\n\n\n\nEODH: it’s data discovery\nThere are a number of API endpoints that are exposed by the EODH. Oxidian have developed a Python API Client, pyeodh, that makes the Hub’s API endpoints available to Python users. pyeodh is available on PyPi (https://pypi.org/project/pyeodh/) and can be installed using pip. Documentation for the API Client is available at: https://pyeodh.readthedocs.io/en/latest/api.html\nWe will use pyeodh throughout this presentation.\n\n# Imports\nimport pyeodh\n\nimport os\n\nimport shapely \nimport geopandas as gpd\nimport folium\n\nimport requests\nfrom requests import HTTPError\n\nimport urllib.request\nfrom io import BytesIO \nfrom PIL import Image\n\nHaving imported the necessary libraries the next task is to set up the locations of the areas of interest. Having created the AOI points the user needs to connect to the Resource Catalogue so that they can start to find some data.\n\n# Areas of Interest\nrut_pnt = shapely.Point(-0.683261054299237, 52.672193937442586) # a site near Rutland\nthet_pnt = shapely.Point(0.6715892933273722, 52.414471075812315) # a site near Thetford\n\n\n# Optional cell\n# If you want to see these points on a map run this cell\n\n# Create a map (m) centered between the two points\ncenter_lat = (rut_pnt.y + thet_pnt.y) / 2\ncenter_lon = (rut_pnt.x + thet_pnt.x) / 2\n\nm = folium.Map(location=[center_lat, center_lon], zoom_start=8)\n\n# Add markers for each point\nfolium.Marker([rut_pnt.y, rut_pnt.x], popup=\"Rutland Site\", icon=folium.Icon(color=\"blue\")).add_to(m)\nfolium.Marker([thet_pnt.y, thet_pnt.x], popup=\"Thetford Site\", icon=folium.Icon(color=\"green\")).add_to(m)\n\n# Step 4: Display the map\nm\n\n\n# Connect to the Hub\nclient = pyeodh.Client().get_catalog_service()\n\n# Print a list of the collections held in the Resource Catalogue (their id and description).\n# As the Resource Catalogue fills and development continues, the number of collections and the richness of their descriptions will increase\nfor collect in client.get_collections():\n    print(f\"{collect.id}: {collect.description}\")\n\ncmip6: CMIP6\ncordex: CORDEX\nukcp: UKCP\ndefra-planet: A collection of Planet data for the DEFRA use case.\nairbus_sar_data: The German TerraSAR-X / TanDEM-X satellite formation and the Spanish PAZ satellite (managed by Hisdesat Servicios Estratégicos S.A.) are being operated in the same orbit tube and feature identical ground swaths and imaging modes - allowing Airbus and Hisdesat to establish a unique commercial Radar Constellation. The satellites carry a high frequency X-band Synthetic Aperture Radar (SAR) sensor in order to acquire datasets ranging from very high-resolution imagery to wide area coverage.\nairbus_data_example: Airbus data\nsentinel2_ard: sentinel 2 ARD\nsentinel1: Sentinel 1\nnaip: The [National Agriculture Imagery Program](https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/) (NAIP) provides U.S.-wide, high-resolution aerial imagery, with four spectral bands (R, G, B, IR).  NAIP is administered by the [Aerial Field Photography Office](https://www.fsa.usda.gov/programs-and-services/aerial-photography/) (AFPO) within the [US Department of Agriculture](https://www.usda.gov/) (USDA).  Data are captured at least once every three years for each state.  This dataset represents NAIP data from 2010-present, in [cloud-optimized GeoTIFF](https://www.cogeo.org/) format.\n\ncop-dem-glo-90: The Copernicus DEM is a Digital Surface Model (DSM) which represents the surface of the Earth including buildings, infrastructure and vegetation. GLO-90 provides worldwide coverage at 90 meters.\n\n\n\n# The next thing to do is find some open data\n# For this presentation we want to find Sentinel-2 analysis ready (ARD) imagery near Rutland\n\n# First we just want to understand some of the parameters linked to the data collection\n# We will just print the first 5 records and the dataset temporal extent   \nsentinel2_ard = client.get_catalog(\"supported-datasets/ceda-stac-fastapi\").get_collection('sentinel2_ard')\nsentinel2_ard.get_items()\n\nlim = 5\ni = 0\n\nfor item in sentinel2_ard.get_items():\n    if i &lt; lim:\n        print(item.id)\n        i += 1\n\nprint('DATASET TEMPORAL EXTENT: ', [str(d) for d in sentinel2_ard.extent.temporal.intervals[0]])\n\nneodc.sentinel_ard.data.sentinel_2.2023.11.21.S2B_20231121_latn536lonw0052_T30UUE_ORB123_20231121122846_utm30n_TM65\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn563lonw0037_T30VVH_ORB037_20231120132420_utm30n_osgb\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn546lonw0037_T30UVF_ORB037_20231120132420_utm30n_osgb\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn536lonw0007_T30UXE_ORB037_20231120132420_utm30n_osgb\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn528lonw0022_T30UWD_ORB037_20231120132420_utm30n_osgb\nDATASET TEMPORAL EXTENT:  ['2023-01-01 11:14:51+00:00', '2023-11-01 11:43:49+00:00']\n\n\n\n# To find out information about all the imagery in the collection then use this cell\n# It undertakes a search for specific date ranges (November 2023) and limits the pagination return to 10\nitem_search = client.search(\n    collections=['sentinel2_ard'],\n    catalog_paths=[\"supported-datasets/ceda-stac-fastapi\"],\n    query=[\n        'start_datetime&gt;=2023-11-01',\n        'end_datetime&lt;=2023-11-30', \n    ],\n    limit=10,\n)\n\n# The item id and start time of image capture can be printed\n# If end time is also required, add the following code to the print statement: item.properties[\"end_datetime\"]  \nfor item in item_search:\n    print(item.id, item.properties[\"start_datetime\"])\n\nneodc.sentinel_ard.data.sentinel_2.2023.11.21.S2B_20231121_latn536lonw0052_T30UUE_ORB123_20231121122846_utm30n_TM65 2023-11-21T11:43:49+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn563lonw0037_T30VVH_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn546lonw0037_T30UVF_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn536lonw0007_T30UXE_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn528lonw0022_T30UWD_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn527lonw0007_T30UXD_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn519lonw0037_T30UVC_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn519lonw0022_T30UWC_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn518lonw0008_T30UXC_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn510lonw0036_T30UVB_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.18.S2B_20231118_latn554lonw0053_T30UUG_ORB080_20231118122250_utm30n_osgb 2023-11-18T11:33:19+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.17.S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb 2023-11-17T11:13:31+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.17.S2A_20231117_latn519lone0023_T31UDT_ORB137_20231117131218_utm31n_osgb 2023-11-17T11:13:31+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.17.S2A_20231117_latn509lone0009_T31UCS_ORB137_20231117131218_utm31n_osgb 2023-11-17T11:13:31+00:00\n\n\n\n# To find specific imagery for the Rutland site we need to add the intersects parameter. We set this to be our AOI point.\n# We can also filter the search by cloud cover, in this case limiting our search to images with less than 50% cloud in them\n\nitems = client.search(\n    collections=['sentinel2_ard'],\n    catalog_paths=[\"supported-datasets/ceda-stac-fastapi\"],\n    intersects=rut_pnt,\n    query=[\n        'start_datetime&gt;=2023-11-01',\n        'end_datetime&lt;=2023-11-30', \n        'Cloud Coverage Assessment&lt;=50.0'\n    ],\n    limit=10,\n)\n\n# We can then count the number of items returned by the search \nprint('Number of items found: ', items.total_count)\n\nNumber of items found:  2\n\n\n\n# For the purposes of this presentation we will look at the second record ([1]) in more detail\n# First we need to understand what information we can access\n\na = items[1].to_dict()\nprint(a.keys())\n\ndict_keys(['type', 'stac_version', 'id', 'properties', 'geometry', 'links', 'assets', 'bbox', 'stac_extensions', 'collection'])\n\n\n\n# It seems likely that the image data we want to access is stored under the 'assets' key. But what information is held in that? \nfor key in (a['assets']):\n    print(key)\n\ncloud\ncloud_probability\ncog\nmetadata\nsaturated_pixels\nthumbnail\ntopographic_shadow\nvalid_pixels\n\n\n\n# Now we can get the link to each of the different assets\nfor key, value in items[1].assets.items():\n    print(key, value.href)\n\ncloud https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_clouds.tif\ncloud_probability https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_clouds_prob.tif\ncog https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref.tif\nmetadata https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_meta.xml\nsaturated_pixels https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_sat.tif\nthumbnail https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_thumbnail.jpg\ntopographic_shadow https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_toposhad.tif\nvalid_pixels https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_valid.tif\n\n\n\n# We can use this information to view the image thumbnail\n\nasset_dict = items[1].assets\n\n# Get the url as a string\nthumbnail_assets = [v for k, v in asset_dict.items() if 'thumbnail' in k]\nthumbnail_url = thumbnail_assets[0].href\n\n# Here we open the remote URL, read the data and dislay the thumbnail \nwith urllib.request.urlopen(thumbnail_url) as url:\n    img = Image.open(BytesIO(url.read()))\n\ndisplay(img)\n\n\n\n\n\n\n\n\nThis shows that we can relatively easily interrogate the Resource Catalogue and filter the results so that we can find the data we require in the EODH. With a bit of tweaking of the code the user could also generate a list of assets and accompanying URLs to the datasets (for this and other datasets).\n\n# Find some commercial data\n# ToDo\n\nfor collect in client.get_collections():\n    print(f\"{collect.id}: {collect.description}\")\n\ncmip6: CMIP6\ncordex: CORDEX\nukcp: UKCP\ndefra-planet: A collection of Planet data for the DEFRA use case.\nairbus_sar_data: The German TerraSAR-X / TanDEM-X satellite formation and the Spanish PAZ satellite (managed by Hisdesat Servicios Estratégicos S.A.) are being operated in the same orbit tube and feature identical ground swaths and imaging modes - allowing Airbus and Hisdesat to establish a unique commercial Radar Constellation. The satellites carry a high frequency X-band Synthetic Aperture Radar (SAR) sensor in order to acquire datasets ranging from very high-resolution imagery to wide area coverage.\nairbus_data_example: Airbus data\nsentinel2_ard: sentinel 2 ARD\nsentinel1: Sentinel 1\nnaip: The [National Agriculture Imagery Program](https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/) (NAIP) provides U.S.-wide, high-resolution aerial imagery, with four spectral bands (R, G, B, IR).  NAIP is administered by the [Aerial Field Photography Office](https://www.fsa.usda.gov/programs-and-services/aerial-photography/) (AFPO) within the [US Department of Agriculture](https://www.usda.gov/) (USDA).  Data are captured at least once every three years for each state.  This dataset represents NAIP data from 2010-present, in [cloud-optimized GeoTIFF](https://www.cogeo.org/) format.\n\ncop-dem-glo-90: The Copernicus DEM is a Digital Surface Model (DSM) which represents the surface of the Earth including buildings, infrastructure and vegetation. GLO-90 provides worldwide coverage at 90 meters.\n\n\n\n# The next thing to do is find some open data\n# For this presentation we want to find Sentinel-2 analysis ready (ARD) imagery near Rutland\n\n# First we just want to understand some of the parameters linked to the data collection\n# We will just print the first 5 records and the dataset temporal extent   \nplanet = client.get_catalog(\"supported-datasets/defra\").get_collection('defra-planet')\nplanet.get_items()\n\nlim = 5\ni = 0\n\nfor item in planet.get_items():\n    if i &lt; lim:\n        print(item.id)\n        i += 1\n\nprint('DATASET TEMPORAL EXTENT: ', [str(d) for d in planet.extent.temporal.intervals[0]])\n\n2024-08-23_strip_7527622_composite\n2024-08-23_strip_7527462_composite\nDATASET TEMPORAL EXTENT:  ['2024-08-23 11:09:19.358417+00:00', '2024-08-23 11:24:40.991786+00:00']\n\n\n\n# To find specific imagery for the Thetford site we need to add the intersects parameter. We set this to be our AOI point.\n# We can also filter the search by cloud cover, in this case limiting our search to images with less than 50% cloud in them\n\nitems = client.search(\n    collections=['defra-planet'],\n    catalog_paths=[\"supported-datasets/defra\"],\n    intersects=thet_pnt,\n    limit=10,\n)\n\n# We can then count the number of items returned by the search \nprint('Number of items found: ', items.total_count)\n\nNumber of items found:  1\n\n\n\nfor key, value in items[0].assets.items():\n    print(key, value.href)\n\ndata 2024-08-23_strip_7527462_composite_file_format.tif\nudm2 2024-08-23_strip_7527462_composite_udm2_file_format.tif\n\n\n\n\nEODH: it’s massive compute\nThe EODH compute architecture is built around a new OGC standard called EO Application Packages (EOAP). These are complex constructions of code and data, and at their core is the concept of a Common Workflow Language (CWL) workflow. To run CWL workflows you need a CWL runner, and the EODH Workflow Runner provides that. The EOAPs require a workflow description in CWL, a Docker container, bespoke scripts and links to the data. In the case of EODH, the data inputs and outputs are to be provided as STAC catalogues. Oxidian, as part of our work developing integrations for the Hub, have created a generator tool eoap-gen that abstracts away much of the complexity (check out the training materials repository and website for more details).\nOxidian have also developed a QGIS plugin to allow desktop users to discover, parameterise and execute workflows on the Hub.\n\n# First the user needs to connect to the Workflow Runner\n# Currently this is done by obtaining a user account and API key from the core development team. Here, those details have been saved in secrets.txt\n\nwith open('secrets.txt', 'r') as file:\n    lines = file.readlines()\n    username = lines[0].strip().split('=')[1].strip('\"')\n    token = lines[1].strip().split('=')[1].strip('\"')\n\nclient = pyeodh.Client(username=username, token=token, s3_token=token)\nwfr = client.get_ades()\n\nOur user wants to know what workflows they have access to in their workspace on the Hub.\n\n# List the workflows available in the user workspace\nfor p in wfr.get_processes():\n    print(p.id)\n\ndisplay\necho\nresize-collection\n\n\nAs development continues the number of demonstration workflows available to users will increase. With uptake of the generator tool users will also be able to create their own bespoke workflows. In time, the Hub will contain organisational accounts and the ability to share workflow files.\nOur user wants to deploy a workflow that they have found online. They can do so for compliant CWL files by submitting the URl.\n\n# Deploy a workflow using a URL to a .cwl file hosted online\nconvert_url_proc = wfr.deploy_process(\n    cwl_url=\"https://raw.githubusercontent.com/EOEPCA/deployment-guide/main/deploy/samples/requests/processing/convert-url-app.cwl\"\n)\nprint(convert_url_proc.id, convert_url_proc.description, \": Deployed\")\nprint('')\n# List the available workflows\nfor p in wfr.get_processes():\n    print(p.id)\n\nconvert-url Convert URL : Deployed\n\ndisplay\necho\nresize-collection\nconvert-url\n\n\n\n# If a user wants to tidy their workspace or no longer wants access to a workflow they can remove it\ntry:\n    wfr.get_process(\"convert-url\").delete()\n    print(\"Process removed\")\nexcept HTTPError:\n    print(\"Process not found\")\n\nProcess removed\n\n\nThe user is interested in the ARD files, but they are too large for the task that they want to undertake. The workflow file linked to here (and shown below) takes a series of data from the Sentinel 2 ARD collection and resizes the imagery using gdal_translate. The CWL file needs to be submitted to the Workflow Runner and parameterised, before it can then be run.\n\ncwl_yaml = \"\"\"cwlVersion: v1.0\n$namespaces:\n  s: https://schema.org/\ns:softwareVersion: 1.0.0\nschemas:\n  - http://schema.org/version/9.0/schemaorg-current-http.rdf\n$graph:\n  - class: Workflow\n    id: r-col\n    label: Resize collection cogs\n    doc: Resize collection cogs\n    requirements:\n      - class: ScatterFeatureRequirement\n    inputs:\n      catalog:\n        label: catalog\n        doc: full catalog path\n        type: string\n        default: \"supported-datasets/ceda-stac-fastapi\"\n      collection:\n        label: collection\n        doc: collection id\n        type: string\n        default: \"sentinel2_ard\"\n    outputs:\n      - id: stac_output\n        outputSource:\n          - stac_step/stac_catalog\n        type: Directory\n    steps:\n      get_urls_step:\n        run: \"#get_urls_cmd\"\n        in:\n          catalog: catalog\n          collection: collection\n        out:\n          - urls\n          - ids\n      resize_step:\n        run: \"#resize_cmd\"\n        in:\n          url: get_urls_step/urls\n          id: get_urls_step/ids\n        scatter:\n          - url\n          - id\n        scatterMethod: dotproduct\n        out:\n          - resized\n      stac_step:\n        run: \"#stac_cmd\"\n        in:\n          items: resize_step/resized\n        out:\n          - stac_catalog\n\n  - class: CommandLineTool\n    id: get_urls_cmd\n    requirements:\n      InlineJavascriptRequirement: {}\n      ResourceRequirement:\n        coresMax: 1\n        ramMax: 512\n    hints:\n      DockerRequirement:\n        dockerPull: ghcr.io/figi44/eoap/get_urls:main\n    baseCommand:\n      - python\n      - /app/app.py\n    inputs:\n      catalog:\n        type: string\n        inputBinding:\n          prefix: --catalog\n      collection:\n        type: string\n        inputBinding:\n          prefix: --collection\n    outputs:\n      urls:\n        type: string[]\n        outputBinding:\n          loadContents: true\n          glob: urls.txt\n          outputEval: $(self[0].contents.split('\\n'))\n      ids:\n        type: string[]\n        outputBinding:\n          loadContents: true\n          glob: ids.txt\n          outputEval: $(self[0].contents.split('\\n'))\n\n  - class: CommandLineTool\n    id: resize_cmd\n    requirements:\n      InlineJavascriptRequirement: {}\n      ResourceRequirement:\n        coresMax: 1\n        ramMax: 512\n    hints:\n      DockerRequirement:\n        dockerPull: ghcr.io/osgeo/gdal:ubuntu-small-latest\n    baseCommand: gdal_translate\n    inputs:\n      url:\n        type: string\n        inputBinding:\n          position: 1\n          prefix: /vsicurl/\n          separate: false\n      id:\n        type: string\n        inputBinding:\n          position: 2\n          valueFrom: $(self + \"_resized.tif\")\n      outsize_x:\n        type: string\n        inputBinding:\n          position: 3\n          prefix: -outsize\n        default: 5%\n      outsize_y:\n        type: string\n        inputBinding:\n          position: 4\n        default: 5%\n    outputs:\n      resized:\n        type: File\n        outputBinding:\n          glob: \"*.tif\"\n\n  - class: CommandLineTool\n    id: stac_cmd\n    requirements:\n      InlineJavascriptRequirement: {}\n      ResourceRequirement:\n        coresMax: 1\n        ramMax: 512\n    hints:\n      DockerRequirement:\n        dockerPull: ghcr.io/figi44/eoap/make_stac:main\n    baseCommand:\n      - python\n      - /app/app.py\n    inputs:\n      items:\n        type: File[]\n        inputBinding: {}\n    outputs:\n      stac_catalog:\n        outputBinding:\n          glob: .\n        type: Directory\n\"\"\"\n\n\n# Deploy the workflow\n# Remove an existing nstance of the workflow\ntry:\n    wfr.get_process(\"resize-collection\").delete()\n    print(\"Process removed\")\nexcept HTTPError:\n    print(\"Process not found\")\n\n# Deploy from a URL to a .cwl file hosted online\nrsz_proc = wfr.deploy_process(cwl_yaml=cwl_yaml)\n\nprint(rsz_proc.id, rsz_proc.description, \": Deployed\")\nprint('')\n# List the available workflows\nfor p in wfr.get_processes():\n    print(p.id)\n\nDEBUG: _request_json_raw received {'self': &lt;pyeodh.client.Client object at 0x7b81fc993380&gt;, 'method': 'GET', 'url': 'https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/processes/resize-collection', 'headers': None, 'params': None, 'data': None, 'encode': &lt;function _encode_json at 0x7b8218d285e0&gt;}\nDEBUG: Making request: GET https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/processes/resize-collection\n       headers: {}\n       params: None\n       body: None\nDEBUG: Received response 404\n       headers: {'Content-Type': 'application/json;charset=UTF-8', 'Content-Length': '199', 'Connection': 'keep-alive', 'Server': 'nginx/1.27.0', 'Date': 'Wed, 18 Sep 2024 12:33:02 GMT', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Credentials': 'true', 'Access-Control-Allow-Methods': 'GET, PUT, POST, DELETE, PATCH, OPTIONS', 'Access-Control-Allow-Headers': 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization,Prefer', 'X-Cache': 'Error from cloudfront', 'Via': '1.1 f546fae491a152f9c1396e6d0a62bb42.cloudfront.net (CloudFront)', 'X-Amz-Cf-Pop': 'LHR50-P1', 'X-Amz-Cf-Id': 'ow12inJohY7CNtq4eutcqtFpnUbJubxAPpYmuVfgQG5uSXCF6e8Owg=='}\n       content: {\n         \"title\": \"NoSuchProcess\",\n         \"type\": \"http://www.opengis.net/def/rel/ogc/1.0/exception/no-such-process\",\n         \"detail\": \"Unable to parse the ZCFG file: resize-collection.zcfg (No message provided)\"\n       }\nDEBUG: _request_json_raw received {'self': &lt;pyeodh.client.Client object at 0x7b81fc993380&gt;, 'method': 'POST', 'url': 'https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/processes', 'headers': None, 'params': None, 'data': 'cwlVersion: v1.0\\n$namespaces:\\n  s: https://schema.org/\\ns:softwareVersion: 1.0.0\\nschemas:\\n  - http://schema.org/version/9.0/schemaorg-current-http.rdf\\n$graph:\\n  - class: Workflow\\n    id: r-col\\n    label: Resize collection cogs\\n    doc: Resize collection cogs\\n    requirements:\\n      - class: ScatterFeatureRequirement\\n    inputs:\\n      catalog:\\n        label: catalog\\n        doc: full catalog path\\n        type: string\\n        default: \"supported-datasets/ceda-stac-fastapi\"\\n      collection:\\n        label: collection\\n        doc: collection id\\n        type: string\\n        default: \"sentinel2_ard\"\\n    outputs:\\n      - id: stac_output\\n        outputSource:\\n          - stac_step/stac_catalog\\n        type: Directory\\n    steps:\\n      get_urls_step:\\n        run: \"#get_urls_cmd\"\\n        in:\\n          catalog: catalog\\n          collection: collection\\n        out:\\n          - urls\\n          - ids\\n      resize_step:\\n        run: \"#resize_cmd\"\\n        in:\\n          url: get_urls_step/urls\\n          id: get_urls_step/ids\\n        scatter:\\n          - url\\n          - id\\n        scatterMethod: dotproduct\\n        out:\\n          - resized\\n      stac_step:\\n        run: \"#stac_cmd\"\\n        in:\\n          items: resize_step/resized\\n        out:\\n          - stac_catalog\\n\\n  - class: CommandLineTool\\n    id: get_urls_cmd\\n    requirements:\\n      InlineJavascriptRequirement: {}\\n      ResourceRequirement:\\n        coresMax: 1\\n        ramMax: 512\\n    hints:\\n      DockerRequirement:\\n        dockerPull: ghcr.io/figi44/eoap/get_urls:main\\n    baseCommand:\\n      - python\\n      - /app/app.py\\n    inputs:\\n      catalog:\\n        type: string\\n        inputBinding:\\n          prefix: --catalog\\n      collection:\\n        type: string\\n        inputBinding:\\n          prefix: --collection\\n    outputs:\\n      urls:\\n        type: string[]\\n        outputBinding:\\n          loadContents: true\\n          glob: urls.txt\\n          outputEval: $(self[0].contents.split(\\'\\n\\'))\\n      ids:\\n        type: string[]\\n        outputBinding:\\n          loadContents: true\\n          glob: ids.txt\\n          outputEval: $(self[0].contents.split(\\'\\n\\'))\\n\\n  - class: CommandLineTool\\n    id: resize_cmd\\n    requirements:\\n      InlineJavascriptRequirement: {}\\n      ResourceRequirement:\\n        coresMax: 1\\n        ramMax: 512\\n    hints:\\n      DockerRequirement:\\n        dockerPull: ghcr.io/osgeo/gdal:ubuntu-small-latest\\n    baseCommand: gdal_translate\\n    inputs:\\n      url:\\n        type: string\\n        inputBinding:\\n          position: 1\\n          prefix: /vsicurl/\\n          separate: false\\n      id:\\n        type: string\\n        inputBinding:\\n          position: 2\\n          valueFrom: $(self + \"_resized.tif\")\\n      outsize_x:\\n        type: string\\n        inputBinding:\\n          position: 3\\n          prefix: -outsize\\n        default: 5%\\n      outsize_y:\\n        type: string\\n        inputBinding:\\n          position: 4\\n        default: 5%\\n    outputs:\\n      resized:\\n        type: File\\n        outputBinding:\\n          glob: \"*.tif\"\\n\\n  - class: CommandLineTool\\n    id: stac_cmd\\n    requirements:\\n      InlineJavascriptRequirement: {}\\n      ResourceRequirement:\\n        coresMax: 1\\n        ramMax: 512\\n    hints:\\n      DockerRequirement:\\n        dockerPull: ghcr.io/figi44/eoap/make_stac:main\\n    baseCommand:\\n      - python\\n      - /app/app.py\\n    inputs:\\n      items:\\n        type: File[]\\n        inputBinding: {}\\n    outputs:\\n      stac_catalog:\\n        outputBinding:\\n          glob: .\\n        type: Directory\\n', 'encode': &lt;function Ades.deploy_process.&lt;locals&gt;.encode at 0x7b81bfc51c60&gt;}\nDEBUG: Making request: POST https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/processes\n       headers: {'Content-Type': 'application/cwl+yaml'}\n       params: None\n       body: cwlVersion: v1.0\n       $namespaces:\n         s: https://schema.org/\n       s:softwareVersion: 1.0.0\n       schemas:\n         - http://schema.org/version/9.0/schemaorg-current-http.rdf\n       $graph:\n         - class: Workflow\n           id: r-col\n           label: Resize collection cogs\n           doc: Resize collection cogs\n           requirements:\n             - class: ScatterFeatureRequirement\n           inputs:\n             catalog:\n               label: catalog\n               doc: full catalog path\n               type: string\n               default: \"supported-datasets/ceda-stac-fastapi\"\n             collection:\n               label: collection\n               doc: collection id\n               type: string\n               default: \"sentinel2_ard\"\n           outputs:\n             - id: stac_output\n               outputSource:\n                 - stac_step/stac_catalog\n               type: Directory\n           steps:\n             get_urls_step:\n               run: \"#get_urls_cmd\"\n               in:\n                 catalog: catalog\n                 collection: collection\n               out:\n                 - urls\n                 - ids\n             resize_step:\n               run: \"#resize_cmd\"\n               in:\n                 url: get_urls_step/urls\n                 id: get_urls_step/ids\n               scatter:\n                 - url\n                 - id\n               scatterMethod: dotproduct\n               out:\n                 - resized\n             stac_step:\n               run: \"#stac_cmd\"\n               in:\n                 items: resize_step/resized\n               out:\n                 - stac_catalog\n\n         - class: CommandLineTool\n           id: get_urls_cmd\n           requirements:\n             InlineJavascriptRequirement: {}\n             ResourceRequirement:\n               coresMax: 1\n               ramMax: 512\n           hints:\n             DockerRequirement:\n               dockerPull: ghcr.io/figi44/eoap/get_urls:main\n           baseCommand:\n             - python\n             - /app/app.py\n           inputs:\n             catalog:\n               type: string\n               inputBinding:\n                 prefix: --catalog\n             collection:\n               type: string\n               inputBinding:\n                 prefix: --collection\n           outputs:\n             urls:\n               type: string[]\n               outputBinding:\n                 loadContents: true\n                 glob: urls.txt\n                 outputEval: $(self[0].contents.split('\n       '))\n             ids:\n               type: string[]\n               outputBinding:\n                 loadContents: true\n                 glob: ids.txt\n                 outputEval: $(self[0].contents.split('\n       '))\n\n         - class: CommandLineTool\n           id: resize_cmd\n           requirements:\n             InlineJavascriptRequirement: {}\n             ResourceRequirement:\n               coresMax: 1\n               ramMax: 512\n           hints:\n             DockerRequirement:\n               dockerPull: ghcr.io/osgeo/gdal:ubuntu-small-latest\n           baseCommand: gdal_translate\n           inputs:\n             url:\n               type: string\n               inputBinding:\n                 position: 1\n                 prefix: /vsicurl/\n                 separate: false\n             id:\n               type: string\n               inputBinding:\n                 position: 2\n                 valueFrom: $(self + \"_resized.tif\")\n             outsize_x:\n               type: string\n               inputBinding:\n                 position: 3\n                 prefix: -outsize\n               default: 5%\n             outsize_y:\n               type: string\n               inputBinding:\n                 position: 4\n               default: 5%\n           outputs:\n             resized:\n               type: File\n               outputBinding:\n                 glob: \"*.tif\"\n\n         - class: CommandLineTool\n           id: stac_cmd\n           requirements:\n             InlineJavascriptRequirement: {}\n             ResourceRequirement:\n               coresMax: 1\n               ramMax: 512\n           hints:\n             DockerRequirement:\n               dockerPull: ghcr.io/figi44/eoap/make_stac:main\n           baseCommand:\n             - python\n             - /app/app.py\n           inputs:\n             items:\n               type: File[]\n               inputBinding: {}\n           outputs:\n             stac_catalog:\n               outputBinding:\n                 glob: .\n               type: Directory\n\nDEBUG: Received response 500\n       headers: {'Content-Type': 'text/plain; charset=utf-8', 'Content-Length': '21', 'Connection': 'keep-alive', 'Server': 'nginx/1.27.0', 'Date': 'Wed, 18 Sep 2024 12:33:02 GMT', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Credentials': 'true', 'Access-Control-Allow-Methods': 'GET, PUT, POST, DELETE, PATCH, OPTIONS', 'Access-Control-Allow-Headers': 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization,Prefer', 'X-Cache': 'Error from cloudfront', 'Via': '1.1 f546fae491a152f9c1396e6d0a62bb42.cloudfront.net (CloudFront)', 'X-Amz-Cf-Pop': 'LHR50-P1', 'X-Amz-Cf-Id': 'KKDPNndL64jsAHzIeE27uXkIL3zFi4nCvd7Kw11v776EeQD0l4sg-A=='}\n       content: Internal Server Error\n\n\nProcess not found\n\n\n\n---------------------------------------------------------------------------\nHTTPError                                 Traceback (most recent call last)\nCell In[27], line 10\n      7     print(\"Process not found\")\n      9 # Deploy from a URL to a .cwl file hosted online\n---&gt; 10 rsz_proc = wfr.deploy_process(cwl_yaml=cwl_yaml)\n     12 print(rsz_proc.id, rsz_proc.description, \": Deployed\")\n     13 print('')\n\nFile ~/miniforge3/envs/eodh/lib/python3.12/site-packages/pyeodh/ades.py:411, in Ades.deploy_process(self, cwl_url, cwl_yaml)\n    409 headers = None\n    410 if cwl_yaml is not None:\n--&gt; 411     headers, response = self._client._request_json(\n    412         \"POST\", self.processes_href, data=cwl_yaml, encode=encode\n    413     )\n    415 if cwl_url is not None:\n    416     data = {\n    417         \"executionUnit\": {\n    418             \"href\": cwl_url,\n    419             \"type\": \"application/cwl\",\n    420         }\n    421     }\n\nFile ~/miniforge3/envs/eodh/lib/python3.12/site-packages/pyeodh/client.py:102, in Client._request_json(self, method, url, headers, params, data, encode)\n     93 def _request_json(\n     94     self,\n     95     method: RequestMethod,\n   (...)\n    100     encode: Callable[[Any], tuple[str, Any]] = _encode_json,\n    101 ) -&gt; tuple[Headers, Any]:\n--&gt; 102     status, resp_headers, resp_data = self._request_json_raw(\n    103         method, url, headers, params, data, encode\n    104     )\n    106     if not len(resp_data):\n    107         return resp_headers, None\n\nFile ~/miniforge3/envs/eodh/lib/python3.12/site-packages/pyeodh/client.py:89, in Client._request_json_raw(self, method, url, headers, params, data, encode)\n     82 logger.debug(\n     83     f\"Received response {response.status_code}\\nheaders: {response.headers}\"\n     84     f\"\\ncontent: {response.text}\"\n     85 )\n     86 # TODO consider moving this to _requst_json() and raise own exceptions\n     87 # so that we can user _raw in e.g. delete methods where we expect a 409 and\n     88 # want to recover\n---&gt; 89 response.raise_for_status()\n     91 return response.status_code, response.headers, response.text\n\nFile ~/miniforge3/envs/eodh/lib/python3.12/site-packages/requests/models.py:1021, in Response.raise_for_status(self)\n   1016     http_error_msg = (\n   1017         f\"{self.status_code} Server Error: {reason} for url: {self.url}\"\n   1018     )\n   1020 if http_error_msg:\n-&gt; 1021     raise HTTPError(http_error_msg, response=self)\n\nHTTPError: 500 Server Error: Internal Server Error for url: https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/processes\n\n\n\nOnce the CWL file has been submitted and\n\n\n\nimage.png\n\n\n\n# Choose and parameterise a workflow\n\n\n\n\nimage.png\n\n\n\n# Run the workflow\npyeodh.set_log_level(10)\n\nresize_job = rsz_proc.execute(\n    {\n        \"catalog\": \"supported-datasets/ceda-stac-fastapi\",\n        \"collection\": \"sentinel2_ard\"\n    }\n)\n\nprint(resize_job.id, resize_job.status, resize_job.message)\n\nDEBUG: _request_json_raw received {'self': &lt;pyeodh.client.Client object at 0x7b81fc993380&gt;, 'method': 'POST', 'url': 'https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/processes/resize-collection/execution', 'headers': {'Prefer': 'respond-async'}, 'params': None, 'data': {'inputs': {'catalog': 'supported-datasets/ceda-stac-fastapi', 'collection': 'sentinel2_ard', 'workspace': 'ajgwords'}}, 'encode': &lt;function _encode_json at 0x7b8218d285e0&gt;}\nDEBUG: Making request: POST https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/processes/resize-collection/execution\n       headers: {'Prefer': 'respond-async', 'Content-Type': 'application/json'}\n       params: None\n       body: {\"inputs\": {\"catalog\": \"supported-datasets/ceda-stac-fastapi\", \"collection\": \"sentinel2_ard\", \"workspace\": \"ajgwords\"}}\nDEBUG: Received response 201\n       headers: {'Content-Type': 'application/json;charset=UTF-8', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Server': 'nginx/1.27.0', 'Date': 'Wed, 18 Sep 2024 12:19:52 GMT', 'x-powered-by': 'ZOO-Project-DRU', 'x-also-powered-by': 'jwt.securityIn', 'x-also-also-powered-by': 'dru.securityIn', 'preference-applied': 'respond-async', 'x-also-also-also-powered-by': 'dru.securityOut', 'location': 'https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/jobs/4e3ab192-75b8-11ef-9355-4e9264aaf6f3', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Credentials': 'true', 'Access-Control-Allow-Methods': 'GET, PUT, POST, DELETE, PATCH, OPTIONS', 'Access-Control-Allow-Headers': 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization,Prefer', 'Access-Control-Max-Age': '1728000', 'X-Cache': 'Miss from cloudfront', 'Via': '1.1 728b6476f3e2317ec8044d22806d4f94.cloudfront.net (CloudFront)', 'X-Amz-Cf-Pop': 'LHR50-P1', 'X-Amz-Cf-Id': 'k-X2KUW-gidZppUMI8nW6tMO1axKLEmQyl0PIZx3BzSIrzcG5zKn4A=='}\n       content: {\n         \"jobID\": \"4e3ab192-75b8-11ef-9355-4e9264aaf6f3\",\n         \"type\": \"process\",\n         \"processID\": \"resize-collection\",\n         \"created\": \"2024-09-18T12:19:52.145Z\",\n         \"started\": \"2024-09-18T12:19:52.145Z\",\n         \"updated\": \"2024-09-18T12:19:52.145Z\",\n         \"status\": \"running\",\n         \"message\": \"ZOO-Kernel accepted to run your service!\",\n         \"links\": [\n           {\n             \"title\": \"Status location\",\n             \"rel\": \"monitor\",\n             \"type\": \"application/json\",\n             \"href\": \"https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/jobs/4e3ab192-75b8-11ef-9355-4e9264aaf6f3\"\n           }\n         ]\n       }\n\n\n4e3ab192-75b8-11ef-9355-4e9264aaf6f3 running ZOO-Kernel accepted to run your service!\n\n\n\n# Find the outputs\n\n\n\nEODH: it’s data analysis\nNotebook service can be used with pyeodh and other libraries installed using pip to analyse data and outputs\n\nfrom localtileserver import TileClient\n\n#data_url = 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref.tif'\nmap = TileClient('S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_clip_rend.tif')\n#map = TileClient(data_url)\nmap\n\n/home/al/miniforge3/envs/eodh/lib/python3.12/site-packages/rio_tiler/io/rasterio.py:130: NoOverviewWarning: The dataset has no Overviews. rio-tiler performances might be impacted.\n  warnings.warn(\n\n\n\n\n\n\nprint(a['assets']['cog']['href'])\nprint()\nfor key in (a['assets']['cog']['eo:bands']):\n    print(key)\n\ns2url = (a['assets']['cog']['href'])\n\nhttps://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref.tif\n\n{'central_wavelength': 496.6, 'common_name': 'blue', 'description': 'Blue', 'full_width_half_max': 0.07, 'name': 'B02'}\n{'central_wavelength': 560, 'common_name': 'green', 'description': 'Green', 'full_width_half_max': 0.04, 'name': 'B03'}\n{'central_wavelength': 664.5, 'common_name': 'red', 'description': 'Red', 'full_width_half_max': 0.03, 'name': 'B04'}\n{'central_wavelength': 703.9, 'common_name': 'rededge', 'description': 'Visible and Near Infrared', 'full_width_half_max': 0.02, 'name': 'B05'}\n{'central_wavelength': 740.2, 'common_name': 'rededge', 'description': 'Visible and Near Infrared', 'full_width_half_max': 0.02, 'name': 'B06'}\n{'central_wavelength': 782.5, 'common_name': 'rededge', 'description': 'Visible and Near Infrared', 'full_width_half_max': 0.02, 'name': 'B07'}\n{'central_wavelength': 835.1, 'common_name': 'nir', 'description': 'Visible and Near Infrared', 'full_width_half_max': 0.11, 'name': 'B08'}\n{'central_wavelength': 864.8, 'common_name': 'nir08', 'description': 'Visible and Near Infrared', 'full_width_half_max': 0.02, 'name': 'B08a'}\n{'central_wavelength': 1613.7, 'common_name': 'swir16', 'description': 'Short Wave Infrared', 'full_width_half_max': 0.09, 'name': 'B11'}\n{'central_wavelength': 2202.4, 'common_name': 'swir22', 'description': 'Short Wave Infrared', 'full_width_half_max': 0.18, 'name': 'B12'}\n\n\n\n\n# Step 1: Define the URL of the Cloud Optimized GeoTIFF (COG)\ncog_path = \"https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref.tif\"\n\nimport rioxarray\nimport numpy as np\nfrom shapely.geometry import box\nimport geopandas as gpd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n\n# Read the image as an xarray dataset\ndata = rioxarray.open_rasterio(cog_path)\n\n# Step 2: Define the clipping area (bounding box) in the same CRS as the image\n# Adjust the minx, miny, maxx, maxy to your area of interest\nminx, miny, maxx, maxy = 481682, 296841, 512343, 313344  # Example bounds in UTM\nbbox = box(minx, miny, maxx, maxy)\n\n# Convert the bounding box into a GeoDataFrame\ngeo_df = gpd.GeoDataFrame({'geometry': [bbox]}, crs=data.rio.crs)\n\n# Step 3: Clip the data using the bounding box (rioxarray will handle the masking)\nclipped_data = data.rio.clip(geo_df.geometry.apply(lambda x: x.__geo_interface__), geo_df.crs)\n\n\n\n\n# Step 4: Select three bands for RGB visualization\n# Assuming band 1 = Blue, band 2 = Green, band 3 = Red\n# Check the specific band indexes based on your data\nred_band = clipped_data.sel(band=3)  # Select the Red band (band index 3)\ngreen_band = clipped_data.sel(band=2)  # Select the Green band (band index 2)\nblue_band = clipped_data.sel(band=1)  # Select the Blue band (band index 1)\n\n# Step 5: Normalize the bands for display (values between 0 and 255)\ndef normalize_band(band):\n    band_min, band_max = band.min(), band.max()\n    return ((band - band_min) / (band_max - band_min) * 255).astype(np.uint8)\n\n# Normalize the selected bands\nred_norm = normalize_band(red_band)\ngreen_norm = normalize_band(green_band)\nblue_norm = normalize_band(blue_band)\n\n# Step 6: Stack the three bands into an RGB image\nrgb_image = np.dstack([red_norm, green_norm, blue_norm])\n\n# Step 7: Convert the NumPy array to a PIL image\npil_image = Image.fromarray(rgb_image)\n\n# Step 8: Display the image using PIL or matplotlib\npil_image.show()\n\n# Alternatively, display with matplotlib\nplt.imshow(rgb_image)\nplt.title(\"Clipped RGB Satellite Image\")\nplt.axis('off')\nplt.show()\n\n\nTowards a data cube?\nFollowing https://odc-stac.readthedocs.io/en/latest/notebooks/stac-load-e84-aws.html\nREWORK TO USE EODH IF POSSIBLE\n\nimport dask.distributed\nimport folium\n#import folium.plugins # Not sure what this does\nimport geopandas as gpd\nimport shapely.geometry\nfrom IPython.display import display\nfrom pystac_client import Client\n\nfrom odc.stac import configure_rio, stac_load # the data cube bit\n\n\ndef convert_bounds(bbox, invert_y=False):\n    \"\"\"\n    Helper method for changing bounding box representation to leaflet notation\n\n    ``(lon1, lat1, lon2, lat2) -&gt; ((lat1, lon1), (lat2, lon2))``\n    \"\"\"\n    x1, y1, x2, y2 = bbox\n    if invert_y:\n        y1, y2 = y2, y1\n    return ((y1, x1), (y2, x2))\n\n\n# FIND STAC ITEMS\n\n#km2deg = 1.0 / 111\n#x, y = (113.887, -25.843)  # Center point of a query\n#r = 100 * km2deg\n#bbox = (x - r, y - r, x + r, y + r)\n\nurl = \"https://api.stac.ceda.ac.uk/\"\n\n#catalog = Client.open(\"https://earth-search.aws.element84.com/v1/\")\nclient = Client.open(url)\nfor coll in client.get_collections():\n    print(f\"{coll.id}: {coll.description}\")\n\ncmip6: CMIP6\ncordex: CORDEX\nsentinel1: Sentinel 1\nsentinel2_ard: sentinel 2 ARD\nsst-cdrv3-collection: collection of EOCIS SST CDR V3\nukcp: UKCP\n\n\n\nsentinel2_ard = client.get_collection('sentinel2_ard')\n\nsentinel2_ard.get_items()\n\n# check the spatial and temporal extent of the collection\n\nprint(\"spatial extent:\", sentinel2_ard.extent.spatial.bboxes)\nprint(\"data range:\", [str(d) for d in sentinel2_ard.extent.temporal.intervals[0]])\n\n\n\n#items = list(query.items())\n#print(f\"Found: {len(items):d} datasets\")\n\n# Convert STAC items into a GeoJSON FeatureCollection\n#stac_json = query.item_collection_as_dict()\n\nspatial extent: [[-9.00034454651177, 49.48562028352171, 3.1494256015866995, 61.33444247301668]]\ndata range: ['2023-01-01 11:14:51+00:00', '2023-11-01 11:43:49+00:00']\n\n\n\n# SEARCH\nitem_search = client.search(\n    collections=['sentinel2_ard'],\n    query=[\n        'start_datetime&gt;=2023-01-01',\n        'end_datetime&lt;=2023-02-28', \n    ],\n    max_items=100,\n)\n\n\nitems = list(item_search.items())\nlen(items)\n\n100\n\n\n\nfrom shapely import Point\npoint = Point(-1.3144835766058023, 51.57555380377267) # Atlas building at RAL\n\nitem_search = client.search(\n    collections=['sentinel2_ard'],\n    intersects=point,\n    query=[\n        'start_datetime&gt;=2023-01-01',\n        'end_datetime&lt;=2023-02-28', \n      ],\n    max_items=10,\n)\n\nitems = list(item_search.items())\nitems\n\n[&lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.25.S2B_20230225_lat52lon075_T30UXC_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.23.S2A_20230223_lat52lon075_T30UXC_ORB037_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.20.S2A_20230220_lat52lon075_T30UXC_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.15.S2B_20230215_lat52lon075_T30UXC_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.13.S2A_20230213_lat52lon075_T30UXC_ORB037_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.08.S2B_20230208_lat52lon075_T30UXC_ORB037_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.31.S2A_20230131_lat52lon075_T30UXC_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.24.S2A_20230124_lat52lon075_T30UXC_ORB037_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.21.S2A_20230121_lat52lon075_T30UXC_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.19.S2B_20230119_lat52lon075_T30UXC_ORB037_utm30n_osgb&gt;]\n\n\n\nitems[0].to_dict()\n\n{'type': 'Feature',\n 'stac_version': '1.0.0',\n 'id': 'neodc.sentinel_ard.data.sentinel_2.2023.02.25.S2B_20230225_lat52lon075_T30UXC_ORB137_utm30n_osgb',\n 'properties': {'file_count': 7,\n  'start_datetime': '2023-02-25T11:09:39Z',\n  'end_datetime': '2023-02-25T11:09:39Z',\n  'NSSDC Identifier': '2015-000A',\n  'created': '2024-02-07T11:36:30.012295Z',\n  'Instrument Family Name': 'Multi-Spectral Instrument',\n  'Platform Number': '2B',\n  'Datatake Type': 'INS-NOBS',\n  'esa_file_name': 'S2B_MSIL1C_20230225T110939_N0509_R137_T30UXC_20230225T115203',\n  'Ground Tracking Direction': 'descending',\n  'datetime': '2023-02-25T11:09:39Z',\n  'instance_id': 'neodc.sentinel_ard.data.sentinel_2.2023.02.25.S2B_20230225_lat52lon075_T30UXC_ORB137_utm30n_osgb',\n  'size': 1949488461,\n  'Product Type': 'S2MSI1C',\n  'Instrument Family Name Abbreviation': 'MSI',\n  'Start Orbit Number': '031194',\n  'eo:cloud_cover': '74.4384424736481',\n  'Start Relative Orbit Number': '137',\n  'updated': '2024-02-07T11:36:30.012295Z',\n  'Instrument Mode': None,\n  'EPSG': '27700'},\n 'geometry': {'coordinates': [[[-1.5321045, 52.34135509726958],\n    [0.077757925309447, 52.31036691499413],\n    [0.011254122594852, 51.32452335478603],\n    [-1.5638733, 51.354439390266904],\n    [-1.5321045, 52.34135509726958]]],\n  'type': 'Polygon'},\n 'links': [{'rel': 'self',\n   'href': 'https://api.stac.ceda.ac.uk/collections/sentinel2_ard/items/neodc.sentinel_ard.data.sentinel_2.2023.02.25.S2B_20230225_lat52lon075_T30UXC_ORB137_utm30n_osgb',\n   'type': 'application/geo+json'},\n  {'rel': 'parent',\n   'href': 'https://api.stac.ceda.ac.uk/collections/sentinel2_ard',\n   'type': 'application/json'},\n  {'rel': 'collection',\n   'href': 'https://api.stac.ceda.ac.uk/collections/sentinel2_ard',\n   'type': 'application/json'},\n  {'rel': 'root',\n   'href': 'https://api.stac.ceda.ac.uk/',\n   'type': 'application/json',\n   'title': 'stac-fastapi-elasticsearch'}],\n 'assets': {'cloud': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/25/S2B_20230225_lat52lon075_T30UXC_ORB137_utm30n_osgb_clouds.tif',\n   'size': 1900764,\n   'location': 'on_disk',\n   'roles': ['data']},\n  'metadata': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/25/S2B_20230225_lat52lon075_T30UXC_ORB137_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_meta.xml',\n   'size': 18360,\n   'location': 'on_disk',\n   'roles': ['metadata']},\n  'thumbnail': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/25/S2B_20230225_lat52lon075_T30UXC_ORB137_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_thumbnail.jpg',\n   'size': 85207,\n   'location': 'on_disk',\n   'roles': ['thumbnail']},\n  'topographic_shadow': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/25/S2B_20230225_lat52lon075_T30UXC_ORB137_utm30n_osgb_toposhad.tif',\n   'size': 250612,\n   'location': 'on_disk',\n   'roles': ['data']},\n  'cog': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/25/S2B_20230225_lat52lon075_T30UXC_ORB137_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref.tif',\n   'size': 1945239489,\n   'eo:bands': [{'full_width_half_max': 0.07,\n     'central_wavelength': 492.1,\n     'name': 'B02',\n     'description': 'Blue',\n     'common_name': 'blue'},\n    {'full_width_half_max': 0.04,\n     'central_wavelength': 559,\n     'name': 'B03',\n     'description': 'Green',\n     'common_name': 'green'},\n    {'full_width_half_max': 0.03,\n     'central_wavelength': 665,\n     'name': 'B04',\n     'description': 'Red',\n     'common_name': 'red'},\n    {'full_width_half_max': 0.02,\n     'central_wavelength': 703.8,\n     'name': 'B05',\n     'description': 'Visible and Near Infrared',\n     'common_name': 'rededge'},\n    {'full_width_half_max': 0.02,\n     'central_wavelength': 739.1,\n     'name': 'B06',\n     'description': 'Visible and Near Infrared',\n     'common_name': 'rededge'},\n    {'full_width_half_max': 0.02,\n     'central_wavelength': 779.7,\n     'name': 'B07',\n     'description': 'Visible and Near Infrared',\n     'common_name': 'rededge'},\n    {'full_width_half_max': 0.11,\n     'central_wavelength': 833,\n     'name': 'B08',\n     'description': 'Visible and Near Infrared',\n     'common_name': 'nir'},\n    {'full_width_half_max': 0.02,\n     'central_wavelength': 864,\n     'name': 'B08a',\n     'description': 'Visible and Near Infrared',\n     'common_name': 'nir08'},\n    {'full_width_half_max': 0.09,\n     'central_wavelength': 1610.4,\n     'name': 'B11',\n     'description': 'Short Wave Infrared',\n     'common_name': 'swir16'},\n    {'full_width_half_max': 0.19,\n     'central_wavelength': 2185.7,\n     'name': 'B12',\n     'description': 'Short Wave Infrared',\n     'common_name': 'swir22'}],\n   'location': 'on_disk',\n   'roles': ['data']},\n  'valid_pixels': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/25/S2B_20230225_lat52lon075_T30UXC_ORB137_utm30n_osgb_valid.tif',\n   'size': 288670,\n   'location': 'on_disk',\n   'roles': ['data']},\n  'saturated_pixels': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/25/S2B_20230225_lat52lon075_T30UXC_ORB137_utm30n_osgb_sat.tif',\n   'size': 1705359,\n   'location': 'on_disk',\n   'roles': ['data']}},\n 'bbox': [-1.5638733, 51.32452335478603, 0.077757925309447, 52.34135509726958],\n 'stac_extensions': ['https://stac-extensions.github.io/eo/v1.1.0/schema.json'],\n 'collection': 'sentinel2_ard'}\n\n\n\nitem_search = client.search(\n    collections=['sentinel2_ard'],\n    intersects=point,\n    query=[\n        'start_datetime&gt;=2023-01-01',\n        'end_datetime&lt;=2023-02-28', \n        'eo:cloud_cover&lt;=50.0'\n      ],\n    max_items=10,\n)\n\nitems = list(item_search.items())\nitems\n\n[&lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.20.S2A_20230220_lat52lon075_T30UXC_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.15.S2B_20230215_lat52lon075_T30UXC_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.13.S2A_20230213_lat52lon075_T30UXC_ORB037_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.08.S2B_20230208_lat52lon075_T30UXC_ORB037_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.31.S2A_20230131_lat52lon075_T30UXC_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.24.S2A_20230124_lat52lon075_T30UXC_ORB037_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.21.S2A_20230121_lat52lon075_T30UXC_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.19.S2B_20230119_lat52lon075_T30UXC_ORB037_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.11.S2A_20230111_lat52lon075_T30UXC_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.09.S2B_20230109_lat52lon075_T30UXC_ORB037_utm30n_osgb&gt;]\n\n\n\nitems[0].to_dict()\n\n{'type': 'Feature',\n 'stac_version': '1.0.0',\n 'id': 'neodc.sentinel_ard.data.sentinel_2.2023.02.20.S2A_20230220_lat52lon075_T30UXC_ORB137_utm30n_osgb',\n 'properties': {'file_count': 7,\n  'start_datetime': '2023-02-20T11:11:01Z',\n  'end_datetime': '2023-02-20T11:11:01Z',\n  'NSSDC Identifier': '2015-000A',\n  'created': '2024-02-07T11:34:51.269363Z',\n  'Instrument Family Name': 'Multi-Spectral Instrument',\n  'Platform Number': '2A',\n  'Datatake Type': 'INS-NOBS',\n  'esa_file_name': 'S2A_MSIL1C_20230220T111101_N0509_R137_T30UXC_20230220T131022',\n  'Ground Tracking Direction': 'descending',\n  'datetime': '2023-02-20T11:11:01Z',\n  'instance_id': 'neodc.sentinel_ard.data.sentinel_2.2023.02.20.S2A_20230220_lat52lon075_T30UXC_ORB137_utm30n_osgb',\n  'size': 2086211720,\n  'Product Type': 'S2MSI1C',\n  'Instrument Family Name Abbreviation': 'MSI',\n  'Start Orbit Number': '040031',\n  'eo:cloud_cover': '26.2055898951895',\n  'Start Relative Orbit Number': '137',\n  'updated': '2024-02-07T11:34:51.269363Z',\n  'Instrument Mode': None,\n  'EPSG': '27700'},\n 'geometry': {'coordinates': [[[-1.5321045, 52.34135509726958],\n    [0.077757925309447, 52.31036691499413],\n    [0.011254122594852, 51.32452335478603],\n    [-1.5638733, 51.354439390266904],\n    [-1.5321045, 52.34135509726958]]],\n  'type': 'Polygon'},\n 'links': [{'rel': 'self',\n   'href': 'https://api.stac.ceda.ac.uk/collections/sentinel2_ard/items/neodc.sentinel_ard.data.sentinel_2.2023.02.20.S2A_20230220_lat52lon075_T30UXC_ORB137_utm30n_osgb',\n   'type': 'application/geo+json'},\n  {'rel': 'parent',\n   'href': 'https://api.stac.ceda.ac.uk/collections/sentinel2_ard',\n   'type': 'application/json'},\n  {'rel': 'collection',\n   'href': 'https://api.stac.ceda.ac.uk/collections/sentinel2_ard',\n   'type': 'application/json'},\n  {'rel': 'root',\n   'href': 'https://api.stac.ceda.ac.uk/',\n   'type': 'application/json',\n   'title': 'stac-fastapi-elasticsearch'}],\n 'assets': {'cloud': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/20/S2A_20230220_lat52lon075_T30UXC_ORB137_utm30n_osgb_clouds.tif',\n   'size': 3144692,\n   'location': 'on_disk',\n   'roles': ['data']},\n  'metadata': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/20/S2A_20230220_lat52lon075_T30UXC_ORB137_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_meta.xml',\n   'size': 18363,\n   'location': 'on_disk',\n   'roles': ['metadata']},\n  'thumbnail': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/20/S2A_20230220_lat52lon075_T30UXC_ORB137_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_thumbnail.jpg',\n   'size': 118722,\n   'location': 'on_disk',\n   'roles': ['thumbnail']},\n  'topographic_shadow': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/20/S2A_20230220_lat52lon075_T30UXC_ORB137_utm30n_osgb_toposhad.tif',\n   'size': 262653,\n   'location': 'on_disk',\n   'roles': ['data']},\n  'cog': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/20/S2A_20230220_lat52lon075_T30UXC_ORB137_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref.tif',\n   'size': 2080673323,\n   'eo:bands': [{'full_width_half_max': 0.07,\n     'central_wavelength': 496.6,\n     'name': 'B02',\n     'description': 'Blue',\n     'common_name': 'blue'},\n    {'full_width_half_max': 0.04,\n     'central_wavelength': 560,\n     'name': 'B03',\n     'description': 'Green',\n     'common_name': 'green'},\n    {'full_width_half_max': 0.03,\n     'central_wavelength': 664.5,\n     'name': 'B04',\n     'description': 'Red',\n     'common_name': 'red'},\n    {'full_width_half_max': 0.02,\n     'central_wavelength': 703.9,\n     'name': 'B05',\n     'description': 'Visible and Near Infrared',\n     'common_name': 'rededge'},\n    {'full_width_half_max': 0.02,\n     'central_wavelength': 740.2,\n     'name': 'B06',\n     'description': 'Visible and Near Infrared',\n     'common_name': 'rededge'},\n    {'full_width_half_max': 0.02,\n     'central_wavelength': 782.5,\n     'name': 'B07',\n     'description': 'Visible and Near Infrared',\n     'common_name': 'rededge'},\n    {'full_width_half_max': 0.11,\n     'central_wavelength': 835.1,\n     'name': 'B08',\n     'description': 'Visible and Near Infrared',\n     'common_name': 'nir'},\n    {'full_width_half_max': 0.02,\n     'central_wavelength': 864.8,\n     'name': 'B08a',\n     'description': 'Visible and Near Infrared',\n     'common_name': 'nir08'},\n    {'full_width_half_max': 0.09,\n     'central_wavelength': 1613.7,\n     'name': 'B11',\n     'description': 'Short Wave Infrared',\n     'common_name': 'swir16'},\n    {'full_width_half_max': 0.18,\n     'central_wavelength': 2202.4,\n     'name': 'B12',\n     'description': 'Short Wave Infrared',\n     'common_name': 'swir22'}],\n   'location': 'on_disk',\n   'roles': ['data']},\n  'valid_pixels': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/20/S2A_20230220_lat52lon075_T30UXC_ORB137_utm30n_osgb_valid.tif',\n   'size': 288608,\n   'location': 'on_disk',\n   'roles': ['data']},\n  'saturated_pixels': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/20/S2A_20230220_lat52lon075_T30UXC_ORB137_utm30n_osgb_sat.tif',\n   'size': 1705359,\n   'location': 'on_disk',\n   'roles': ['data']}},\n 'bbox': [-1.5638733, 51.32452335478603, 0.077757925309447, 52.34135509726958],\n 'stac_extensions': ['https://stac-extensions.github.io/eo/v1.1.0/schema.json'],\n 'collection': 'sentinel2_ard'}\n\n\n\nfor key, value in items[1].assets.items():\n    print(key, value.href)\n\ncloud https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/15/S2B_20230215_lat52lon075_T30UXC_ORB137_utm30n_osgb_clouds.tif\nmetadata https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/15/S2B_20230215_lat52lon075_T30UXC_ORB137_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_meta.xml\nthumbnail https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/15/S2B_20230215_lat52lon075_T30UXC_ORB137_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_thumbnail.jpg\ntopographic_shadow https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/15/S2B_20230215_lat52lon075_T30UXC_ORB137_utm30n_osgb_toposhad.tif\ncog https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/15/S2B_20230215_lat52lon075_T30UXC_ORB137_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref.tif\nvalid_pixels https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/15/S2B_20230215_lat52lon075_T30UXC_ORB137_utm30n_osgb_valid.tif\nsaturated_pixels https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/15/S2B_20230215_lat52lon075_T30UXC_ORB137_utm30n_osgb_sat.tif\n\n\n\nitems\n\n[&lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.20.S2A_20230220_lat52lon075_T30UXC_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.15.S2B_20230215_lat52lon075_T30UXC_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.13.S2A_20230213_lat52lon075_T30UXC_ORB037_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.08.S2B_20230208_lat52lon075_T30UXC_ORB037_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.31.S2A_20230131_lat52lon075_T30UXC_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.24.S2A_20230124_lat52lon075_T30UXC_ORB037_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.21.S2A_20230121_lat52lon075_T30UXC_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.19.S2B_20230119_lat52lon075_T30UXC_ORB037_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.11.S2A_20230111_lat52lon075_T30UXC_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.09.S2B_20230109_lat52lon075_T30UXC_ORB037_utm30n_osgb&gt;]\n\n\n\n# SET UP DASK CLIENT\n\nclient = dask.distributed.Client()\nconfigure_rio(cloud_defaults=True, aws={\"aws_unsigned\": True}, client=client) # sets up gdal for cloud use\ndisplay(client)\n\n/home/al/miniforge3/envs/odc/lib/python3.12/site-packages/distributed/node.py:182: UserWarning: Port 8787 is already in use.\nPerhaps you already have a cluster running?\nHosting the HTTP server on port 36089 instead\n  warnings.warn(\n\n\n\n     \n    \n        Client\n        Client-18464180-69fc-11ef-adda-f40669402fbd\n        \n\n\n\nConnection method: Cluster object\nCluster type: distributed.LocalCluster\n\n\nDashboard: http://127.0.0.1:36089/status\n\n\n\n\n\n\n        \n\n        \n            \n            Cluster Info\n            \n    \n    \n    \n        LocalCluster\n        ebba7415\n        \n\n\n\nDashboard: http://127.0.0.1:36089/status\nWorkers: 4\n\n\nTotal threads: 4\nTotal memory: 15.48 GiB\n\n\nStatus: running\nUsing processes: True\n\n\n\n\n\n        \n            \n                Scheduler Info\n            \n\n            \n    \n         \n        \n            Scheduler\n            Scheduler-cc47dd57-ce18-4acc-8b44-2cfe14ee1b6d\n            \n\n\n\nComm: tcp://127.0.0.1:43071\nWorkers: 4\n\n\nDashboard: http://127.0.0.1:36089/status\nTotal threads: 4\n\n\nStarted: Just now\nTotal memory: 15.48 GiB\n\n\n\n\n        \n    \n\n    \n        \n            Workers\n        \n\n        \n        \n             \n            \n            \n                \n                    Worker: 0\n                \n                \n\n\n\nComm: tcp://127.0.0.1:37851\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:45891/status\nMemory: 3.87 GiB\n\n\nNanny: tcp://127.0.0.1:44451\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-07pluzp_\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 1\n                \n                \n\n\n\nComm: tcp://127.0.0.1:44127\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:38617/status\nMemory: 3.87 GiB\n\n\nNanny: tcp://127.0.0.1:46581\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-j1euk6hp\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 2\n                \n                \n\n\n\nComm: tcp://127.0.0.1:35695\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:43975/status\nMemory: 3.87 GiB\n\n\nNanny: tcp://127.0.0.1:46341\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-guemqotg\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 3\n                \n                \n\n\n\nComm: tcp://127.0.0.1:45491\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:40249/status\nMemory: 3.87 GiB\n\n\nNanny: tcp://127.0.0.1:45605\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-_dnsv6m3\n\n\n\n\n            \n            \n        \n        \n\n    \n\n\n        \n    \n\n            \n        \n\n    \n\n\n\n\nprint(f\"Found: {len(items):d} datasets\")\n\n# Convert STAC items into a GeoJSON FeatureCollection\nstac_json = item_search.item_collection_as_dict()\n\nFound: 10 datasets\n\n\n\n# REVIEW SEARCH RESULTS\n\ngdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n\n# Compute granule id from components\n#gdf[\"granule\"] = (\n#    gdf[\"esa_file_name\"].apply(lambda x: f\"{x:02d}\")\n#    + gdf[\"mgrs:latitude_band\"]\n#    + gdf[\"mgrs:grid_square\"]\n#)\n\nfig = gdf.plot(\n    \"esa_file_name\",\n    edgecolor=\"black\",\n    categorical=True,\n    aspect=\"equal\",\n    alpha=0.5,\n    figsize=(6, 12),\n    legend=True,\n    legend_kwds={\"loc\": \"upper left\", \"frameon\": False, \"ncol\": 1},\n)\n_ = fig.set_title(\"STAC Query Results\")\n\n\n\n\n\n\n\n\n\n# PLOT THE SAME, but using FOLIUM\n\n# https://github.com/python-visualization/folium/issues/1501\n#from branca.element import Figure\n\nimport folium\nf = folium.Figure(width=600, height=400)\nm = folium.Map(location=[52, 2], zoom_start=5).add_to(f)\n\n\n\n\n\n#fig = Figure(width=\"400px\", height=\"500px\")\n#map1 = folium.Map()\n#fig.add_child(map1)\n\n#folium.GeoJson(\n#    shapely.geometry.box(*bbox),\n#    style_function=lambda x: dict(fill=False, weight=1, opacity=0.7, color=\"olive\"),\n#    name=\"Query\",\n#).add_to(m)\n\n\ngdf.explore(\n    \"esa_file_name\",\n    categorical=True,\n    tooltip=[\n        \"esa_file_name\",\n#        \"datetime\",\n#        \"eo:cloud_cover\",\n    ],\n    popup=False,\n#    style_kwds=dict(fillOpacity=0.1, width=2),\n    name=\"STAC\",\n    m=m,\n)\n\n#map1.fit_bounds(bounds=convert_bounds(gdf.unary_union.bounds))\n#display(fig)\n\n\n\n\n\n# CONSTRUCT DASK DATASET\n# Note: there are 9 STAC Items on input, and only one timeslice on output. \n# Due to groupby=\"solar_day\" (all items that occured on the same day added to one image plane).\n\n# Since we will plot it on a map we need to use `EPSG:3857` projection\ncrs = \"epsg:3857\"\nzoom = 2**5  # overview level 5\n\n#xx = stac_load(\n#    items,\n#    bands=(\"B04\", \"B03\", \"B02\"),\n#    crs=crs,\n#    resolution=10 * zoom)#,\n#    chunks={},  # &lt;-- use Dask\n#    groupby=\"solar_day\",\n#)\n#display(xx)\n\n\n#xx = stac_load(\n#    items,\n#    chunks={\"x\": 2048, \"y\": 2048},\n#    patch_url=pc.sign,\n#    resolution=resolution,\n#    # force dtype and nodata\n#    dtype=\"uint16\",\n#    nodata=0,\n#)\n\nxx = stac_load(\n    items,\n    crs=crs,\n    resolution=10 * zoom,\n    chunks={\"x\": 2048, \"y\": 2048},  # &lt;-- use Dask\n)\n\nprint(f\"Bands: {','.join(list(xx.data_vars))}\")\ndisplay(xx)\n\nBands: cloud,thumbnail,topographic_shadow,cog,valid_pixels,saturated_pixels\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 79MB\nDimensions:             (y: 574, x: 573, time: 10)\nCoordinates:\n  * y                   (y) float64 5kB 6.862e+06 6.862e+06 ... 6.679e+06\n  * x                   (x) float64 5kB -1.742e+05 -1.739e+05 ... 8.8e+03\n    spatial_ref         int32 4B 3857\n  * time                (time) datetime64[ns] 80B 2023-01-09T11:23:39 ... 202...\nData variables:\n    cloud               (time, y, x) float32 13MB dask.array&lt;chunksize=(1, 574, 573), meta=np.ndarray&gt;\n    thumbnail           (time, y, x) float32 13MB dask.array&lt;chunksize=(1, 574, 573), meta=np.ndarray&gt;\n    topographic_shadow  (time, y, x) float32 13MB dask.array&lt;chunksize=(1, 574, 573), meta=np.ndarray&gt;\n    cog                 (time, y, x) float32 13MB dask.array&lt;chunksize=(1, 574, 573), meta=np.ndarray&gt;\n    valid_pixels        (time, y, x) float32 13MB dask.array&lt;chunksize=(1, 574, 573), meta=np.ndarray&gt;\n    saturated_pixels    (time, y, x) float32 13MB dask.array&lt;chunksize=(1, 574, 573), meta=np.ndarray&gt;xarray.DatasetDimensions:y: 574x: 573time: 10Coordinates: (4)y(y)float646.862e+06 6.862e+06 ... 6.679e+06units :metreresolution :-320.0crs :EPSG:3857array([6862240., 6861920., 6861600., ..., 6679520., 6679200., 6678880.])x(x)float64-1.742e+05 -1.739e+05 ... 8.8e+03units :metreresolution :320.0crs :EPSG:3857array([-174240., -173920., -173600., ...,    8160.,    8480.,    8800.])spatial_ref()int323857spatial_ref :PROJCRS[\"WGS 84 / Pseudo-Mercator\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"Popular Visualisation Pseudo-Mercator\",METHOD[\"Popular Visualisation Pseudo Mercator\",ID[\"EPSG\",1024]],PARAMETER[\"Latitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"easting (X)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"northing (Y)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Web mapping and visualisation.\"],AREA[\"World between 85.06°S and 85.06°N.\"],BBOX[-85.06,-180,85.06,180]],ID[\"EPSG\",3857]]crs_wkt :PROJCRS[\"WGS 84 / Pseudo-Mercator\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],MEMBER[\"World Geodetic System 1984 (G2296)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"Popular Visualisation Pseudo-Mercator\",METHOD[\"Popular Visualisation Pseudo Mercator\",ID[\"EPSG\",1024]],PARAMETER[\"Latitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"easting (X)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"northing (Y)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Web mapping and visualisation.\"],AREA[\"World between 85.06°S and 85.06°N.\"],BBOX[-85.06,-180,85.06,180]],ID[\"EPSG\",3857]]GeoTransform :-174400 320 0 6862400 0 -320array(3857, dtype=int32)time(time)datetime64[ns]2023-01-09T11:23:39 ... 2023-02-...array(['2023-01-09T11:23:39.000000000', '2023-01-11T11:14:31.000000000',\n       '2023-01-19T11:23:09.000000000', '2023-01-21T11:13:51.000000000',\n       '2023-01-24T11:23:41.000000000', '2023-01-31T11:13:11.000000000',\n       '2023-02-08T11:21:29.000000000', '2023-02-13T11:21:51.000000000',\n       '2023-02-15T11:10:49.000000000', '2023-02-20T11:11:01.000000000'],\n      dtype='datetime64[ns]')Data variables: (6)cloud(time, y, x)float32dask.array&lt;chunksize=(1, 574, 573), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.55 MiB\n1.25 MiB\n\n\nShape\n(10, 574, 573)\n(1, 574, 573)\n\n\nDask graph\n10 chunks in 3 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                           573 574 10\n\n\n\n\nthumbnail(time, y, x)float32dask.array&lt;chunksize=(1, 574, 573), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.55 MiB\n1.25 MiB\n\n\nShape\n(10, 574, 573)\n(1, 574, 573)\n\n\nDask graph\n10 chunks in 3 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                           573 574 10\n\n\n\n\ntopographic_shadow(time, y, x)float32dask.array&lt;chunksize=(1, 574, 573), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.55 MiB\n1.25 MiB\n\n\nShape\n(10, 574, 573)\n(1, 574, 573)\n\n\nDask graph\n10 chunks in 3 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                           573 574 10\n\n\n\n\ncog(time, y, x)float32dask.array&lt;chunksize=(1, 574, 573), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.55 MiB\n1.25 MiB\n\n\nShape\n(10, 574, 573)\n(1, 574, 573)\n\n\nDask graph\n10 chunks in 3 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                           573 574 10\n\n\n\n\nvalid_pixels(time, y, x)float32dask.array&lt;chunksize=(1, 574, 573), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.55 MiB\n1.25 MiB\n\n\nShape\n(10, 574, 573)\n(1, 574, 573)\n\n\nDask graph\n10 chunks in 3 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                           573 574 10\n\n\n\n\nsaturated_pixels(time, y, x)float32dask.array&lt;chunksize=(1, 574, 573), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n12.55 MiB\n1.25 MiB\n\n\nShape\n(10, 574, 573)\n(1, 574, 573)\n\n\nDask graph\n10 chunks in 3 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                           573 574 10\n\n\n\n\nIndexes: (3)yPandasIndexPandasIndex(Index([6862240.0, 6861920.0, 6861600.0, 6861280.0, 6860960.0, 6860640.0,\n       6860320.0, 6860000.0, 6859680.0, 6859360.0,\n       ...\n       6681760.0, 6681440.0, 6681120.0, 6680800.0, 6680480.0, 6680160.0,\n       6679840.0, 6679520.0, 6679200.0, 6678880.0],\n      dtype='float64', name='y', length=574))xPandasIndexPandasIndex(Index([-174240.0, -173920.0, -173600.0, -173280.0, -172960.0, -172640.0,\n       -172320.0, -172000.0, -171680.0, -171360.0,\n       ...\n          5920.0,    6240.0,    6560.0,    6880.0,    7200.0,    7520.0,\n          7840.0,    8160.0,    8480.0,    8800.0],\n      dtype='float64', name='x', length=573))timePandasIndexPandasIndex(DatetimeIndex(['2023-01-09 11:23:39', '2023-01-11 11:14:31',\n               '2023-01-19 11:23:09', '2023-01-21 11:13:51',\n               '2023-01-24 11:23:41', '2023-01-31 11:13:11',\n               '2023-02-08 11:21:29', '2023-02-13 11:21:51',\n               '2023-02-15 11:10:49', '2023-02-20 11:11:01'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (0)\n\n\n\n# DATA FOOTPRINT\n#xx.odc.geobox\n\n# TEST\nxx.data_vars[cog]\n\n\n%%time\nxx = xx.compute() # LOAD INTO LOCAL MEMORY",
    "crumbs": [
      "Presentations",
      "DEFRA 2024-09"
    ]
  },
  {
    "objectID": "website/about.html",
    "href": "website/about.html",
    "title": "About",
    "section": "",
    "text": "What is EODH\n\n\nResources on this website",
    "crumbs": [
      "About"
    ]
  }
]