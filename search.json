[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "EODH Training Materials",
    "section": "",
    "text": "Welcome\nThis site is in heavy development.\nWelcome to the eodh-training repository! This repository aims to provide a live set of documents to demonstrate how to use the EODH (Earth Observation Data Hub) and associated tools such as the pyeodh Python API client, workflow generator and QGIS plugin. Other training materials may be added to this repository in future.\nWhether you’re a user looking to explore the project or a developer wanting to contribute, you’ll find all the information you need here.\n\n\nContent\nYou’ll be able to find the content you require by navidating through this website using the sidebar to the left.\n\n\nAdditional Support\nWe have set up an accessible Discussion Group as a location that users can interact with other users, as well as the Hub owners and developers. Please use this resource to build a vibrant community around the EODH platform. It is also accessible via the GitHub icon at the top of every page.\nIf you require specific development information on the API client then please check out the ReadTheDocs page for the client.\n\nThis website is made using Quarto.",
    "crumbs": [
      "Home"
    ]
  },
  {
    "objectID": "workflows/1_workflows.html",
    "href": "workflows/1_workflows.html",
    "title": "What is a Workflow",
    "section": "",
    "text": "What is CWL?\n\n\nWhat is the Workflow Runner?\n\n\nWhat is the Workflow generator?",
    "crumbs": [
      "Workflows",
      "Workflow Introduction"
    ]
  },
  {
    "objectID": "presentations/DEFRA/2_202409_Defra_DataProcessing.html",
    "href": "presentations/DEFRA/2_202409_Defra_DataProcessing.html",
    "title": "Demonstration for DEFRA",
    "section": "",
    "text": "Description & purpose: This Notebook is designed to showcase the initial functionality of the Earth Observation Data Hub. It provides a snapshot of the Hub, the pyeodh API client and the various datasets as of September 2024. The Notebook “user” would like to understand more about the satellite data available for their test areas. This user is also interested in obtaining a series of smaller images and ultimately creating a data cube. The Notebook series (of 3) is designed in such a way that it can be run on the EODH AppHub (Notebook Service) or from a local environment.\nAuthor(s): Alastair Graham, Dusan Figala, Phil Kershaw\nDate created: 2024-09-05\nDate last modified: 2024-09-18\nLicence: This notebook is licensed under Creative Commons Attribution-ShareAlike 4.0 International. The code is released using the BSD-2-Clause license.\n Copyright (c) , All rights reserved.\n Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nLinks: * Oxidian: https://www.oxidian.com/ * CEDA: https://www.ceda.ac.uk/ * EO Data Hub: https://eodatahub.org.uk/\n\nWhat is the EODH?\nThe Earth Observation Data Hub is:\n“A UK Pathfinder project delivering access to Earth Observation (EO) data for effective decisionmaking across government, business and academia. The Earth Observation DataHub (EODH) brings together an expert project delivery team and industrial partners in an ambitious project… Users of the Hub will be able to explore areas of interest in the UK and across the globe… It will also enable selected users to support their own analyses, services and tools using the Hub’s workflow and compute environments.”\nMore details can be found online at https://eodatahub.org.uk/\nComponents of the Hub include: * A Resource Catalogue - a STAC compliant catalogue of open and commercial satellite imagery, climate data, model results, workflows and more * A Workflow Runner - a dedicated piece of cloud infrastructure to horizontally scale workflow requirements * A Web Presence - an intuitive user interface to allow account management, data discovery and mapping * An App Hub - a science portal providing access to a Jupyter lab environment\n\nPresentation set up\nThe following cell only needs to be run on the EODH AppHub. If you have a local Python environment running, please install the required packages as you would normally.\n\n# If needed you can install a package in the current AppHub Jupyter environment using pip\n# For instance, we will need at least the following libraries\nimport sys\n!{sys.executable} -m pip install --upgrade pyeodh pandas matplotlib numpy pillow folium\n\n\n\n\nEODH: it’s massive compute\nThe EODH compute architecture is built around a new OGC standard called EO Application Packages (EOAP). These are complex constructions of code and data, and at their core is the concept of a Common Workflow Language (CWL) workflow. To run CWL workflows you need a CWL runner, and the EODH Workflow Runner provides that. The EOAPs require a workflow description in CWL, a Docker container, bespoke scripts and links to the data. In the case of EODH, the data inputs and outputs are to be provided as STAC catalogues. Oxidian, as part of our work developing integrations for the Hub, have created a generator tool eoap-gen that abstracts away much of the complexity (check out the training materials repository and website for more details).\nOxidian have also developed a QGIS plugin to allow desktop users to discover, parameterise and execute workflows on the Hub.\n\n# Imports\nimport pyeodh\n\nimport os\nfrom requests import HTTPError\n\n\n# First the user needs to connect to the Workflow Runner\n# Currently this is done by obtaining a user account and API key from the core development team. Here, those details have been saved in secrets.txt\n# secrets.txt should contain the two lines below where USERNAME and API_KEY are specific to the user:\n# USER=\"USERNAME\"\n# PSWD=\"API_KEY\" \n\nwith open('secrets.txt', 'r') as file:\n    lines = file.readlines()\n    username = lines[0].strip().split('=')[1].strip('\"')\n    token = lines[1].strip().split('=')[1].strip('\"')\n\nclientwfr = pyeodh.Client(username=username, token=token, s3_token=token)\nwfr = clientwfr.get_ades()\n\nOur user wants to know what workflows they have access to in their workspace on the Hub.\n\n# List the workflows available in the user workspace\nfor p in wfr.get_processes():\n    print(p.id)\n\ndisplay\necho\nconvert-img\n\n\nAs development continues the number of demonstration workflows available to users will increase. With uptake of the generator tool users will also be able to create their own bespoke workflows. In time, the Hub will contain organisational accounts and the ability to share workflow files.\nOur user wants to deploy a workflow that they have found online. They can do so for compliant CWL files by submitting the URl.\n\n# Deploy a workflow using a URL to a .cwl file hosted online\nconvert_url_proc = wfr.deploy_process(\n    cwl_url=\"https://raw.githubusercontent.com/EOEPCA/deployment-guide/main/deploy/samples/requests/processing/convert-url-app.cwl\"\n)\nprint(convert_url_proc.id, convert_url_proc.description, \": Deployed\")\nprint('')\n# List the available workflows\nfor p in wfr.get_processes():\n    print(p.id)\n\nconvert-url Convert URL : Deployed\n\ndisplay\necho\nconvert-img\nconvert-url\n\n\n\n# If a user wants to tidy their workspace or no longer wants access to a workflow they can remove it\ntry:\n    wfr.get_process(\"convert-url\").delete()\n    print(\"Process removed\")\nexcept HTTPError:\n    print(\"Process not found\")\n\nProcess removed\n\n\nThe user is interested in the ARD files, but they are too large for the task that they want to undertake. The workflow file linked to here takes a series of data from the Sentinel 2 ARD collection and resizes the imagery using gdal_translate. The CWL file needs to be submitted to the Workflow Runner and parameterised, before it can then be run.\n\n# Deploy the workflow\n# Remove an existing nstance of the workflow\ntry:\n    wfr.get_process(\"convert-img\").delete()\n    print(\"Process removed\")\nexcept HTTPError:\n    print(\"Process not found\")\n\n# Deploy from a URL to a .cwl file hosted online\n#img_proc = wfr.deploy_process(cwl_yaml=cwl_yaml)\nimg_proc = wfr.deploy_process(cwl_url='https://raw.githubusercontent.com/ajgwords/eodh-tests/main/resize-col.cwl')\n\nprint(img_proc.id, img_proc.description, \": Deployed\")\nprint('')\n# List the available workflows\nfor p in wfr.get_processes():\n    print(p.id)\n\nProcess not found\nresize-col Resize collection cogs : Deployed\n\ndisplay\necho\nresize-col\n\n\nAs part of the presentation we looked at the plugin offline. Screenshots are provided here for those who do not have the plugin installed.\nOnce the CWL file has been submitted then it is possible for users with suitable permissions to also view the list of available workflows through the QGIS plugin.\n\n\n\nimage.png\n\n\nThe user can choose and parameterise a workflow using the QGIS plugin as shown in this screenshot. A series of defaults are provided with all workflow files so a user can run the workflow straight away using those. To do so in code, the user provides an empty dictionary.\n\n\n\nimage.png\n\n\n\n# Run the workflow using the defaults\npyeodh.set_log_level(10) # set the logging to be verbose\n\nresize_job = img_proc.execute(\n    {\n    }\n)\n\nprint(resize_job.id, resize_job.status, resize_job.message)\n\nDEBUG: _request_json_raw received {'self': &lt;pyeodh.client.Client object at 0x7d35e47e45c0&gt;, 'method': 'POST', 'url': 'https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/processes/resize-col/execution', 'headers': {'Prefer': 'respond-async'}, 'params': None, 'data': {'inputs': {'workspace': 'ajgwords'}}, 'encode': &lt;function _encode_json at 0x7d3635f30540&gt;}\nDEBUG: Making request: POST https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/processes/resize-col/execution\n       headers: {'Prefer': 'respond-async', 'Content-Type': 'application/json'}\n       params: None\n       body: {\"inputs\": {\"workspace\": \"ajgwords\"}}\nDEBUG: Received response 201\n       headers: {'Content-Type': 'application/json;charset=UTF-8', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Server': 'nginx/1.27.0', 'Date': 'Wed, 18 Sep 2024 14:05:46 GMT', 'x-powered-by': 'ZOO-Project-DRU', 'x-also-powered-by': 'jwt.securityIn', 'x-also-also-powered-by': 'dru.securityIn', 'preference-applied': 'respond-async', 'x-also-also-also-powered-by': 'dru.securityOut', 'location': 'https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/jobs/19efd624-75c7-11ef-9849-4e9264aaf6f3', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Credentials': 'true', 'Access-Control-Allow-Methods': 'GET, PUT, POST, DELETE, PATCH, OPTIONS', 'Access-Control-Allow-Headers': 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization,Prefer', 'Access-Control-Max-Age': '1728000', 'X-Cache': 'Miss from cloudfront', 'Via': '1.1 a6a1a17bbe377bf7c4423397c71959da.cloudfront.net (CloudFront)', 'X-Amz-Cf-Pop': 'LHR50-P1', 'X-Amz-Cf-Id': 'RtavU9ppINxjxyCvlYOnhxdNqGnDtX-HNJmyLlCbtYPf3Dcd5MgLsg=='}\n       content: {\n         \"jobID\": \"19efd624-75c7-11ef-9849-4e9264aaf6f3\",\n         \"type\": \"process\",\n         \"processID\": \"resize-col\",\n         \"created\": \"2024-09-18T14:05:46.805Z\",\n         \"started\": \"2024-09-18T14:05:46.805Z\",\n         \"updated\": \"2024-09-18T14:05:46.805Z\",\n         \"status\": \"running\",\n         \"message\": \"ZOO-Kernel accepted to run your service!\",\n         \"links\": [\n           {\n             \"title\": \"Status location\",\n             \"rel\": \"monitor\",\n             \"type\": \"application/json\",\n             \"href\": \"https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/jobs/19efd624-75c7-11ef-9849-4e9264aaf6f3\"\n           }\n         ]\n       }\n\n\n19efd624-75c7-11ef-9849-4e9264aaf6f3 running ZOO-Kernel accepted to run your service!\n\n\n\nresize_job.refresh()\nprint(resize_job.id, resize_job.status, resize_job.message)\n\nDEBUG: _request_json_raw received {'self': &lt;pyeodh.client.Client object at 0x7d35e47e45c0&gt;, 'method': 'GET', 'url': 'https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/jobs/19efd624-75c7-11ef-9849-4e9264aaf6f3', 'headers': None, 'params': None, 'data': None, 'encode': &lt;function _encode_json at 0x7d3635f30540&gt;}\nDEBUG: Making request: GET https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/jobs/19efd624-75c7-11ef-9849-4e9264aaf6f3\n       headers: {}\n       params: None\n       body: None\nDEBUG: Received response 200\n       headers: {'Content-Type': 'application/json;charset=UTF-8', 'Content-Length': '507', 'Connection': 'keep-alive', 'Server': 'nginx/1.27.0', 'Date': 'Wed, 18 Sep 2024 14:05:54 GMT', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Credentials': 'true', 'Access-Control-Allow-Methods': 'GET, PUT, POST, DELETE, PATCH, OPTIONS', 'Access-Control-Allow-Headers': 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization,Prefer', 'Access-Control-Max-Age': '1728000', 'X-Cache': 'Miss from cloudfront', 'Via': '1.1 a6a1a17bbe377bf7c4423397c71959da.cloudfront.net (CloudFront)', 'X-Amz-Cf-Pop': 'LHR50-P1', 'X-Amz-Cf-Id': 'IakHOzKo8AnbmuIW_lFytmYjofpvygKjKotlpOjxhGiQ-a5G6RH22A=='}\n       content: {\"progress\": 15, \"jobID\": \"19efd624-75c7-11ef-9849-4e9264aaf6f3\", \"type\": \"process\", \"processID\": \"resize-col\", \"created\": \"2024-09-18T14:05:46.805Z\", \"started\": \"2024-09-18T14:05:46.805Z\", \"updated\": \"2024-09-18T14:05:48.804Z\", \"status\": \"running\", \"message\": \"processing environment created, preparing execution\", \"links\": [{\"title\": \"Status location\", \"rel\": \"monitor\", \"type\": \"application/json\", \"href\": \"https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/jobs/19efd624-75c7-11ef-9849-4e9264aaf6f3\"}]}\n\n\n19efd624-75c7-11ef-9849-4e9264aaf6f3 running processing environment created, preparing execution\n\n\nThe outputs above show the status of the running job: \"status\": \"running\". The job status can also be monitored using the QGIS plugin.\n\n\n\nimage.png\n\n\n\n\n\nimage-2.png\n\n\nThe outputs are accessible and loadable from the QGIS plugin.\nOriginal image: \nResampled image: \nThe workflow outputs are available in a users’s workspace and are attached to the job id presented through the QGIS plugin. A user can open any output from within the plugin to be displayed in the QGIS map window.",
    "crumbs": [
      "Presentations",
      "DEFRA Data Processing"
    ]
  },
  {
    "objectID": "api-client/planet-stac-proxy.html",
    "href": "api-client/planet-stac-proxy.html",
    "title": "Planet STAC Example",
    "section": "",
    "text": "Demo of retrieving data from Planet via their STAC proxy api using the PySTAC Client. Requires an api-key saved in as .planet.json which has the content {\"key\": \"API_KEY\"}.\n\nimport base64\nfrom pystac_client import Client\nimport requests\nfrom shapely import Point\nimport planet\nfrom IPython.display import Image\n\napi_key = planet.Auth.from_file().value\n\nuserpass = f\"{api_key}:\"\n\nheaders = {\n    \"Authorization\": f\"Basic {base64.b64encode(userpass.encode()).decode()}\"\n}\n\n\nclient = Client.open(\n    url=\"https://api.planet.com/x/data/\",\n    headers=headers\n)\n\nitem_search = client.search(\n    collections=['PSScene'],\n    datetime='2024-06-01/2024-08-01',\n    intersects=Point(-111, 45.68),\n    filter={\n        \"op\": \"&gt;=\",\n        \"args\": [{\"property\": \"clear_percent\"}, 50]\n    }\n)\n\nitem = next(item_search.items())\nthumbnail = requests.get(item.assets[\"thumbnail\"].href, headers=headers)\nImage(data=thumbnail.content)\n\n\n\n\n\n\n\n\n\nimport pyeodh\nimport base64\nfrom io import BytesIO\nfrom pystac_client import Client\nimport requests\nfrom shapely import Point\nimport planet\nfrom IPython.display import Image\n\napi_key = planet.Auth.from_file().value\n\nuserpass = f\"{api_key}:\"\n\nheaders = {\n    \"Authorization\": f\"Basic {base64.b64encode(userpass.encode()).decode()}\"\n}\n\nclient = pyeodh.Client(username=api_key).get_catalog_service()\nitem_search = client.search(\n    collections=['PSScene'],\n    datetime='2024-06-01/2024-08-01',\n    intersects=Point(-111, 45.68),\n    filter={\n        \"op\": \"&gt;=\",\n        \"args\": [{\"property\": \"clear_percent\"}, 50]\n    }\n)\n\nitem = item_search[0]\nthumbnail = requests.get(item.assets[\"thumbnail\"].href, headers=headers)\nImage(data=thumbnail.content)\n\n\n---------------------------------------------------------------------------\nHTTPError                                 Traceback (most recent call last)\nCell In[10], line 29\n     18 client = pyeodh.Client(username=api_key).get_catalog_service()\n     19 item_search = client.search(\n     20     collections=['PSScene'],\n     21     datetime='2024-06-01/2024-08-01',\n   (...)\n     26     }\n     27 )\n---&gt; 29 item = item_search[0]\n     30 thumbnail = requests.get(item.assets[\"thumbnail\"].href, headers=headers)\n     31 Image(data=thumbnail.content)\n\nFile ~/.local/lib/python3.11/site-packages/pyeodh/pagination.py:82, in PaginatedList.__getitem__(self, index)\n     80 def __getitem__(self, index: int) -&gt; T:\n     81     assert isinstance(index, int)\n---&gt; 82     self._fetch_to_index(index)\n     83     return self._elements[index]\n\nFile ~/.local/lib/python3.11/site-packages/pyeodh/pagination.py:87, in PaginatedList._fetch_to_index(self, index)\n     85 def _fetch_to_index(self, index: int) -&gt; None:\n     86     while len(self._elements) &lt;= index and self._has_next():\n---&gt; 87         new_elements = self._fetch_next()\n     88         self._elements += new_elements\n\nFile ~/.local/lib/python3.11/site-packages/pyeodh/pagination.py:96, in PaginatedList._fetch_next(self)\n     94 if not self._next_url:\n     95     raise RuntimeError(\"Next url not specified!\")\n---&gt; 96 headers, resp_data = self._client._request_json(\n     97     self._method,\n     98     self._next_url,\n     99     headers=self._headers,\n    100     params=self._params,\n    101     data=self._data,\n    102 )\n    103 next_link = next(\n    104     filter(lambda ln: ln.get(\"rel\") == \"next\", resp_data.get(\"links\", {})), {}\n    105 )\n    106 self._next_url = next_link.get(\"href\")\n\nFile ~/.local/lib/python3.11/site-packages/pyeodh/client.py:102, in Client._request_json(self, method, url, headers, params, data, encode)\n     93 def _request_json(\n     94     self,\n     95     method: RequestMethod,\n   (...)\n    100     encode: Callable[[Any], tuple[str, Any]] = _encode_json,\n    101 ) -&gt; tuple[Headers, Any]:\n--&gt; 102     status, resp_headers, resp_data = self._request_json_raw(\n    103         method, url, headers, params, data, encode\n    104     )\n    106     if not len(resp_data):\n    107         return resp_headers, None\n\nFile ~/.local/lib/python3.11/site-packages/pyeodh/client.py:89, in Client._request_json_raw(self, method, url, headers, params, data, encode)\n     82 logger.debug(\n     83     f\"Received response {response.status_code}\\nheaders: {response.headers}\"\n     84     f\"\\ncontent: {response.text}\"\n     85 )\n     86 # TODO consider moving this to _requst_json() and raise own exceptions\n     87 # so that we can user _raw in e.g. delete methods where we expect a 409 and\n     88 # want to recover\n---&gt; 89 response.raise_for_status()\n     91 return response.status_code, response.headers, response.text\n\nFile /opt/jaspy/lib/python3.11/site-packages/requests/models.py:1024, in Response.raise_for_status(self)\n   1019     http_error_msg = (\n   1020         f\"{self.status_code} Server Error: {reason} for url: {self.url}\"\n   1021     )\n   1023 if http_error_msg:\n-&gt; 1024     raise HTTPError(http_error_msg, response=self)\n\nHTTPError: 400 Client Error: Bad Request for url: https://test.eodatahub.org.uk/api/catalogue/stac/search"
  },
  {
    "objectID": "api-client/2_ResourceCatalog.html",
    "href": "api-client/2_ResourceCatalog.html",
    "title": "Resource Catalog",
    "section": "",
    "text": "This notebook demostrates usage of the EODH resource catalog API using pyeodh\n\n\n\na clear description of purpose,\nintended audience and/or use case\nlinkages between notebooks and other training resources (if required)\n\n\n\n\n\nTechnical dependencies,\nPlatform and Service Dependencies,\nPython Language versions,\nlibraries, additional scripts and files.\n\n\n\n\n“When Jupyter notebooks are used in an educational context, they should not only be conceptualized to teach a specific topic but should also set a good example by following and implementing best practices for scientific computing”\n\nNeed in-order execution of notebook cells\nGood-quality code\nNo code duplication\nImports at the beginning of a notebook\nConsistent code style and formatting\nMeaningful names for variables\nLicence for code and training resources\n\n\nDescription & purpose:\nAuthor(s):\nDate created:\nDate last modified:\nLicence: This notebook is released under Creative Commons …. The code is released using …\nFirst we need to create an instance of the Client, which is our entrypoint to EODH APIs.\n\nimport pyeodh\n\nclient = pyeodh.Client(base_url=\"https://test.eodatahub.org.uk\") # Optionally specify a different server\n\nFetch the resource catalog object.\n\n# GET /stac-fastapi/catalogs\nservice = client.get_catalog_service()\ncatalogs = service.get_catalogs()\nceda_cat = service.get_catalog(\"supported-datasets/ceda-stac-fastapi\")\n\nAll attributes are mapped to properties, e.g.\n\nprint(\"id: \", catalogs.id)\n#print(\"title: \", rc.title)\n#print(\"description: \", rc.description)\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 print(\"id: \", catalogs.id)\n      2 #print(\"title: \", rc.title)\n      3 #print(\"description: \", rc.description)\n\nAttributeError: 'list' object has no attribute 'id'\n\n\n\nAPI endpoints are wrapped in methods and are structured into classes following the same logic as the API. E.g. to fetch a collection item, I first need to get the collection from the resource catalog.\n\n# GET /stac-fastapi/collections/{collection_id}/items/{item_id}\ncmip6 = rc.get_collection(\"cmip6\")\nitem = cmip6.get_item(\"CMIP6.ScenarioMIP.THU.CIESM.ssp585.r1i1p1f1.Amon.rsus.gr.v20200806\")\nprint(item.id)\n\nSome API responses are paginated (e.g. collection items), and you can simply iterate over them.\n\n# GET /stac-fastapi/collections/cmip6/items\nitems = cmip6.get_items()\nfor item in items:\n    print(item.id)\n\nAttempting to create a collection with id that already exists will result in 409 error code. To see the example in action delete the test collection first by running the cell below.\nDelete a colletion\n\nrc.get_collection(\"test1\").delete()\n\nCreate new collection example\n\ntest1 = rc.create_collection(id=\"test1\", title=\"Test\", description=\"Test collection\")\nprint(test1.description)\n\nUpdate a collection\n\ntest1.update(description=\"Different description\")\nprint(test1.description)\n\nCreate an item\n\ntestitem1 = test1.create_item(id=\"test1.testitem1\")\nprint(f\"Created {testitem1.id} in collection {testitem1.collection}\")\n\nUpdate an item\n\ntestitem1.update(properties={\"foo\": \"bar\"})\nprint(testitem1.properties)\n\nDelete an item\n\ntestitem1.delete()\n\nFind out more about the Resource Catalog\n\nprint(f\"Livecheck: PING-{rc.ping()}\")\nprint(\"\\nAPI conforms to:\", *rc.get_conformance(), sep=\"\\n\")\n\nSearch the Catalog\n\nfor result in rc.search(collections=['cmip6']):\n    print(result.id)",
    "crumbs": [
      "API Client (pyeodh)",
      "Searching the Resource Catalogue"
    ]
  },
  {
    "objectID": "api-client/2_ResourceCatalog.html#remove-in-production-release",
    "href": "api-client/2_ResourceCatalog.html#remove-in-production-release",
    "title": "Resource Catalog",
    "section": "",
    "text": "This notebook demostrates usage of the EODH resource catalog API using pyeodh\n\n\n\na clear description of purpose,\nintended audience and/or use case\nlinkages between notebooks and other training resources (if required)\n\n\n\n\n\nTechnical dependencies,\nPlatform and Service Dependencies,\nPython Language versions,\nlibraries, additional scripts and files.\n\n\n\n\n“When Jupyter notebooks are used in an educational context, they should not only be conceptualized to teach a specific topic but should also set a good example by following and implementing best practices for scientific computing”\n\nNeed in-order execution of notebook cells\nGood-quality code\nNo code duplication\nImports at the beginning of a notebook\nConsistent code style and formatting\nMeaningful names for variables\nLicence for code and training resources\n\n\nDescription & purpose:\nAuthor(s):\nDate created:\nDate last modified:\nLicence: This notebook is released under Creative Commons …. The code is released using …\nFirst we need to create an instance of the Client, which is our entrypoint to EODH APIs.\n\nimport pyeodh\n\nclient = pyeodh.Client(base_url=\"https://test.eodatahub.org.uk\") # Optionally specify a different server\n\nFetch the resource catalog object.\n\n# GET /stac-fastapi/catalogs\nservice = client.get_catalog_service()\ncatalogs = service.get_catalogs()\nceda_cat = service.get_catalog(\"supported-datasets/ceda-stac-fastapi\")\n\nAll attributes are mapped to properties, e.g.\n\nprint(\"id: \", catalogs.id)\n#print(\"title: \", rc.title)\n#print(\"description: \", rc.description)\n\n\n---------------------------------------------------------------------------\nAttributeError                            Traceback (most recent call last)\nCell In[3], line 1\n----&gt; 1 print(\"id: \", catalogs.id)\n      2 #print(\"title: \", rc.title)\n      3 #print(\"description: \", rc.description)\n\nAttributeError: 'list' object has no attribute 'id'\n\n\n\nAPI endpoints are wrapped in methods and are structured into classes following the same logic as the API. E.g. to fetch a collection item, I first need to get the collection from the resource catalog.\n\n# GET /stac-fastapi/collections/{collection_id}/items/{item_id}\ncmip6 = rc.get_collection(\"cmip6\")\nitem = cmip6.get_item(\"CMIP6.ScenarioMIP.THU.CIESM.ssp585.r1i1p1f1.Amon.rsus.gr.v20200806\")\nprint(item.id)\n\nSome API responses are paginated (e.g. collection items), and you can simply iterate over them.\n\n# GET /stac-fastapi/collections/cmip6/items\nitems = cmip6.get_items()\nfor item in items:\n    print(item.id)\n\nAttempting to create a collection with id that already exists will result in 409 error code. To see the example in action delete the test collection first by running the cell below.\nDelete a colletion\n\nrc.get_collection(\"test1\").delete()\n\nCreate new collection example\n\ntest1 = rc.create_collection(id=\"test1\", title=\"Test\", description=\"Test collection\")\nprint(test1.description)\n\nUpdate a collection\n\ntest1.update(description=\"Different description\")\nprint(test1.description)\n\nCreate an item\n\ntestitem1 = test1.create_item(id=\"test1.testitem1\")\nprint(f\"Created {testitem1.id} in collection {testitem1.collection}\")\n\nUpdate an item\n\ntestitem1.update(properties={\"foo\": \"bar\"})\nprint(testitem1.properties)\n\nDelete an item\n\ntestitem1.delete()\n\nFind out more about the Resource Catalog\n\nprint(f\"Livecheck: PING-{rc.ping()}\")\nprint(\"\\nAPI conforms to:\", *rc.get_conformance(), sep=\"\\n\")\n\nSearch the Catalog\n\nfor result in rc.search(collections=['cmip6']):\n    print(result.id)",
    "crumbs": [
      "API Client (pyeodh)",
      "Searching the Resource Catalogue"
    ]
  },
  {
    "objectID": "presentations/DEFRA/1_202409_Defra_DataDiscovery.html",
    "href": "presentations/DEFRA/1_202409_Defra_DataDiscovery.html",
    "title": "Demonstration for DEFRA",
    "section": "",
    "text": "Description & purpose: This Notebook is designed to showcase the initial functionality of the Earth Observation Data Hub. It provides a snapshot of the Hub, the pyeodh API client and the various datasets as of September 2024. The Notebook “user” would like to understand more about the satellite data available for their test areas. This user is also interested in obtaining a series of smaller images and ultimately creating a data cube. The Notebook series (of 3) is designed in such a way that it can be run on the EODH AppHub (Notebook Service) or from a local environment.\nAuthor(s): Alastair Graham, Dusan Figala, Phil Kershaw\nDate created: 2024-09-05\nDate last modified: 2024-09-18\nLicence: This notebook is licensed under Creative Commons Attribution-ShareAlike 4.0 International. The code is released using the BSD-2-Clause license.\n Copyright (c) , All rights reserved.\n Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nLinks: * Oxidian: https://www.oxidian.com/ * CEDA: https://www.ceda.ac.uk/ * EO Data Hub: https://eodatahub.org.uk/\n\nWhat is the EODH?\nThe Earth Observation Data Hub is:\n“A UK Pathfinder project delivering access to Earth Observation (EO) data for effective decisionmaking across government, business and academia. The Earth Observation DataHub (EODH) brings together an expert project delivery team and industrial partners in an ambitious project… Users of the Hub will be able to explore areas of interest in the UK and across the globe… It will also enable selected users to support their own analyses, services and tools using the Hub’s workflow and compute environments.”\nMore details can be found online at https://eodatahub.org.uk/\nComponents of the Hub include: * A Resource Catalogue - a STAC compliant catalogue of open and commercial satellite imagery, climate data, model results, workflows and more * A Workflow Runner - a dedicated piece of cloud infrastructure to horizontally scale workflow requirements * A Web Presence - an intuitive user interface to allow account management, data discovery and mapping * An App Hub - a science portal providing access to a Jupyter lab environment\n\nPresentation set up\nThe following cell only needs to be run on the EODH AppHub. If you have a local Python environment running, please install the required packages as you would normally.\n\n# If needed you can install a package in the current AppHub Jupyter environment using pip\n# For instance, we will need at least the following libraries\nimport sys\n!{sys.executable} -m pip install --upgrade pyeodh geopandas matplotlib numpy pillow folium\n\n\n\n\nEODH: it’s data discovery\nThere are a number of API endpoints that are exposed by the EODH. Oxidian have developed a Python API Client, pyeodh, that makes the Hub’s API endpoints available to Python users. pyeodh is available on PyPi (https://pypi.org/project/pyeodh/) and can be installed using pip. Documentation for the API Client is available at: https://pyeodh.readthedocs.io/en/latest/api.html\nWe will use pyeodh throughout this presentation.\n\n# Imports\nimport pyeodh\n\nimport os\n\nimport shapely \nimport geopandas as gpd\nimport folium\n\nimport urllib.request\nfrom io import BytesIO \nfrom PIL import Image\n\nHaving imported the necessary libraries the next task is to set up the locations of the areas of interest. Having created the AOI points the user needs to connect to the Resource Catalogue so that they can start to find some data.\n\n# Areas of Interest\nrut_pnt = shapely.Point(-0.683261054299237, 52.672193937442586) # a site near Rutland\nthet_pnt = shapely.Point(0.6715892933273722, 52.414471075812315) # a site near Thetford\n\n\n# Optional cell\n# If you want to see these points on a map run this cell\n\n# Create a map (m) centered between the two points\ncenter_lat = (rut_pnt.y + thet_pnt.y) / 2\ncenter_lon = (rut_pnt.x + thet_pnt.x) / 2\n\nm = folium.Map(location=[center_lat, center_lon], zoom_start=8)\n\n# Add markers for each point\nfolium.Marker([rut_pnt.y, rut_pnt.x], popup=\"Rutland Site\", icon=folium.Icon(color=\"blue\")).add_to(m)\nfolium.Marker([thet_pnt.y, thet_pnt.x], popup=\"Thetford Site\", icon=folium.Icon(color=\"green\")).add_to(m)\n\n# Step 4: Display the map\nm\n\n\n# Connect to the Hub\nclient = pyeodh.Client().get_catalog_service()\n\n# Print a list of the collections held in the Resource Catalogue (their id and description).\n# As the Resource Catalogue fills and development continues, the number of collections and the richness of their descriptions will increase\nfor collect in client.get_collections():\n    print(f\"{collect.id}: {collect.description}\")\n\ncmip6: CMIP6\ncordex: CORDEX\nukcp: UKCP\ndefra-airbus: A collection of Airbus data for the DEFRA use case.\ndefra-planet: A collection of Planet data for the DEFRA use case.\nairbus_sar_data: The German TerraSAR-X / TanDEM-X satellite formation and the Spanish PAZ satellite (managed by Hisdesat Servicios Estratégicos S.A.) are being operated in the same orbit tube and feature identical ground swaths and imaging modes - allowing Airbus and Hisdesat to establish a unique commercial Radar Constellation. The satellites carry a high frequency X-band Synthetic Aperture Radar (SAR) sensor in order to acquire datasets ranging from very high-resolution imagery to wide area coverage.\nairbus_data_example: Airbus data\nsentinel2_ard: sentinel 2 ARD\nsentinel1: Sentinel 1\nnaip: The [National Agriculture Imagery Program](https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/) (NAIP) provides U.S.-wide, high-resolution aerial imagery, with four spectral bands (R, G, B, IR).  NAIP is administered by the [Aerial Field Photography Office](https://www.fsa.usda.gov/programs-and-services/aerial-photography/) (AFPO) within the [US Department of Agriculture](https://www.usda.gov/) (USDA).  Data are captured at least once every three years for each state.  This dataset represents NAIP data from 2010-present, in [cloud-optimized GeoTIFF](https://www.cogeo.org/) format.\n\n\n\n\n# The next thing to do is find some open data\n# For this presentation we want to find Sentinel-2 analysis ready (ARD) imagery near Rutland\n\n# First we just want to understand some of the parameters linked to the data collection\n# We will just print the first 5 records and the dataset temporal extent   \nsentinel2_ard = client.get_catalog(\"supported-datasets/ceda-stac-fastapi\").get_collection('sentinel2_ard')\nsentinel2_ard.get_items()\n\nlim = 5\ni = 0\n\nfor item in sentinel2_ard.get_items():\n    if i &lt; lim:\n        print(item.id)\n        i += 1\n\nprint('DATASET TEMPORAL EXTENT: ', [str(d) for d in sentinel2_ard.extent.temporal.intervals[0]])\n\nneodc.sentinel_ard.data.sentinel_2.2023.11.21.S2B_20231121_latn536lonw0052_T30UUE_ORB123_20231121122846_utm30n_TM65\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn563lonw0037_T30VVH_ORB037_20231120132420_utm30n_osgb\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn546lonw0037_T30UVF_ORB037_20231120132420_utm30n_osgb\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn536lonw0007_T30UXE_ORB037_20231120132420_utm30n_osgb\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn528lonw0022_T30UWD_ORB037_20231120132420_utm30n_osgb\nDATASET TEMPORAL EXTENT:  ['2023-01-01 11:14:51+00:00', '2023-11-01 11:43:49+00:00']\n\n\n\n# To find out information about all the imagery in the collection then use this cell\n# It undertakes a search for specific date ranges (November 2023) and limits the pagination return to 10\nitem_search = client.search(\n    collections=['sentinel2_ard'],\n    catalog_paths=[\"supported-datasets/ceda-stac-fastapi\"],\n    query=[\n        'start_datetime&gt;=2023-11-01',\n        'end_datetime&lt;=2023-11-30', \n    ],\n    limit=10,\n)\n\n# The item id and start time of image capture can be printed\n# If end time is also required, add the following code to the print statement: item.properties[\"end_datetime\"]  \nfor item in item_search:\n    print(item.id, item.properties[\"start_datetime\"])\n\nneodc.sentinel_ard.data.sentinel_2.2023.11.21.S2B_20231121_latn536lonw0052_T30UUE_ORB123_20231121122846_utm30n_TM65 2023-11-21T11:43:49+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn563lonw0037_T30VVH_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn546lonw0037_T30UVF_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn536lonw0007_T30UXE_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn528lonw0022_T30UWD_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn527lonw0007_T30UXD_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn519lonw0037_T30UVC_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn519lonw0022_T30UWC_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn518lonw0008_T30UXC_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn510lonw0036_T30UVB_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.18.S2B_20231118_latn554lonw0053_T30UUG_ORB080_20231118122250_utm30n_osgb 2023-11-18T11:33:19+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.17.S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb 2023-11-17T11:13:31+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.17.S2A_20231117_latn519lone0023_T31UDT_ORB137_20231117131218_utm31n_osgb 2023-11-17T11:13:31+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.17.S2A_20231117_latn509lone0009_T31UCS_ORB137_20231117131218_utm31n_osgb 2023-11-17T11:13:31+00:00\n\n\n\n# To find specific imagery for the Rutland site we need to add the intersects parameter. We set this to be our AOI point.\n# We can also filter the search by cloud cover, in this case limiting our search to images with less than 50% cloud in them\n\nitems = client.search(\n    collections=['sentinel2_ard'],\n    catalog_paths=[\"supported-datasets/ceda-stac-fastapi\"],\n    intersects=rut_pnt,\n    query=[\n        'start_datetime&gt;=2023-11-01',\n        'end_datetime&lt;=2023-11-30', \n        'Cloud Coverage Assessment&lt;=50.0'\n    ],\n    limit=10,\n)\n\n# We can then count the number of items returned by the search \nprint('Number of items found: ', items.total_count)\n\nNumber of items found:  2\n\n\n\n# For the purposes of this presentation we will look at the second record ([1]) in more detail\n# First we need to understand what information we can access\n\na = items[1].to_dict()\nprint(a.keys())\n\ndict_keys(['type', 'stac_version', 'id', 'properties', 'geometry', 'links', 'assets', 'bbox', 'stac_extensions', 'collection'])\n\n\n\n# The data we want to access is stored under the 'assets' key. But what information is held in that? \nfor key in (a['assets']):\n    print(key)\n\ncloud\ncloud_probability\ncog\nmetadata\nsaturated_pixels\nthumbnail\ntopographic_shadow\nvalid_pixels\n\n\n\n# Now we can get the link to each of the different assets\nfor key, value in items[1].assets.items():\n    print(key, value.href)\n\ncloud https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_clouds.tif\ncloud_probability https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_clouds_prob.tif\ncog https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref.tif\nmetadata https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_meta.xml\nsaturated_pixels https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_sat.tif\nthumbnail https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_thumbnail.jpg\ntopographic_shadow https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_toposhad.tif\nvalid_pixels https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_valid.tif\n\n\n\n# We can use this information to view the image thumbnail\n\nasset_dict = items[1].assets\n\n# Get the url as a string\nthumbnail_assets = [v for k, v in asset_dict.items() if 'thumbnail' in k]\nthumbnail_url = thumbnail_assets[0].href\n\n# Here we open the remote URL, read the data and dislay the thumbnail \nwith urllib.request.urlopen(thumbnail_url) as url:\n    img = Image.open(BytesIO(url.read()))\n\ndisplay(img)\n\n\n\n\n\n\n\n\nThis shows that we can relatively easily interrogate the Resource Catalogue and filter the results so that we can find the data we require in the EODH. With a bit of tweaking of the code the user could also generate a list of assets and accompanying URLs to the datasets (for this and other datasets).\nNow our user wants to see what commercial data exists for the Thetford site.\n\n# Find some commercial data\n\nfor collect in client.get_collections():\n    if 'defra' in collect.id: \n        print(f\"{collect.id}: {collect.description}\")\n\ndefra-airbus: A collection of Airbus data for the DEFRA use case.\ndefra-planet: A collection of Planet data for the DEFRA use case.\n\n\n\n# Let's search for information on the Planet holdings  \nplanet = client.get_catalog(\"supported-datasets/defra\").get_collection('defra-planet')\nplanet.get_items()\n\nlim = 5\ni = 0\n\nfor item in planet.get_items():\n    if i &lt; lim:\n        print(item.id)\n        i += 1\n\nprint('PLANET DATASET TEMPORAL EXTENT: ', [str(d) for d in planet.extent.temporal.intervals[0]])\n\n2024-08-23_strip_7527622_composite\n2024-08-23_strip_7527462_composite\nPLANET DATASET TEMPORAL EXTENT:  ['2024-08-23 11:09:19.358417+00:00', '2024-08-23 11:24:40.991786+00:00']\n\n\n\n# To find specific imagery for the Thetford site we need to add the intersects parameter. We set this to be our AOI point.\nitems1 = client.search(\n    collections=['defra-planet'],\n    catalog_paths=[\"supported-datasets/defra\"],\n    intersects=thet_pnt,\n    limit=10,\n)\n\nitems2 = client.search(\n    collections=['defra-airbus'],\n    catalog_paths=[\"supported-datasets/defra\"],\n    intersects=thet_pnt,\n    limit=10,\n)\n\n# We can then count the number of items returned by the search \nprint('Number of Planet items found: ', items1.total_count)\nprint('Number of Airbus items found: ', items2.total_count)\n\nNumber of Planet items found:  1\nNumber of Airbus items found:  2\n\n\n\nfor key, value in items1[0].assets.items():\n    print('Planet: ', key, value)\n\nPlanet:  data &lt;Asset href=2024-08-23_strip_7527462_composite_file_format.tif&gt;\nPlanet:  udm2 &lt;Asset href=2024-08-23_strip_7527462_composite_udm2_file_format.tif&gt;\n\n\nThe final step would be to use the ordering service integrated into the EODH resource catalogue to purchase the required commercial imagery. This would be stored in a users workspace and could then be used in specific workflows or for data analytics (depending on licence restrictions).\nFor the purposes of this presentation we looked at the different commercial datasets offline in QGIS.",
    "crumbs": [
      "Presentations",
      "DEFRA Data Discovery"
    ]
  },
  {
    "objectID": "presentations/DEFRA/3_202409_Defra_DataAnalysis.html",
    "href": "presentations/DEFRA/3_202409_Defra_DataAnalysis.html",
    "title": "Demonstration for DEFRA",
    "section": "",
    "text": "Description & purpose: This Notebook is designed to showcase the initial functionality of the Earth Observation Data Hub. It provides a snapshot of the Hub, the pyeodh API client and the various datasets as of September 2024. The Notebook “user” would like to understand more about the satellite data available for their test areas. This user is also interested in obtaining a cloud free dataset and ultimately creating a data cube. The Notebook is designed in such a way that it can be run on the EODH AppHub (Notebook Service) or from a local environment.\nAuthor(s): Alastair Graham, Dusan Figala, Phil Kershaw\nDate created: 2024-09-05\nDate last modified: 2024-09-18\nLicence: This notebook is licensed under Creative Commons Attribution-ShareAlike 4.0 International. The code is released using the BSD-2-Clause license.\n Copyright (c) , All rights reserved.\n Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:\n Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS “AS IS” AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.\nLinks: * Oxidian: https://www.oxidian.com/ * CEDA: https://www.ceda.ac.uk/ * EO Data Hub: https://eodatahub.org.uk/\n\nWhat is the EODH?\nThe Earth Observation Data Hub is:\n“A UK Pathfinder project delivering access to Earth Observation (EO) data for effective decisionmaking across government, business and academia. The Earth Observation DataHub (EODH) brings together an expert project delivery team and industrial partners in an ambitious project… Users of the Hub will be able to explore areas of interest in the UK and across the globe… It will also enable selected users to support their own analyses, services and tools using the Hub’s workflow and compute environments.”\nMore details can be found online at https://eodatahub.org.uk/\nComponents of the Hub include: * A Resource Catalogue - a STAC compliant catalogue of open and commercial satellite imagery, climate data, model results, workflows and more * A Workflow Runner - a dedicated piece of cloud infrastructure to horizontally scale workflow requirements * A Web Presence - an intuitive user interface to allow account management, data discovery and mapping * An App Hub - a science portal providing access to a Jupyter lab environment\n\nPresentation set up\nThe following cell only needs to be run on the EODH AppHub. If you have a local Python environment running, please install the required packages as you would normally.\n\n# If needed you can install a package in the current AppHub Jupyter environment using pip\n# For instance, we will need the following libraries\nimport sys\n!{sys.executable} -m pip install --upgrade pyeodh pandas matplotlib numpy pillow folium\n\n\n\n\nEODH: it’s data discovery\nThere are a number of API endpoints that are exposed by the EODH. Oxidian have developed a Python API Client, pyeodh, that makes the Hub’s API endpoints available to Python users. pyeodh is available on PyPi (https://pypi.org/project/pyeodh/) and can be installed using pip. Documentation for the API Client is available at: https://pyeodh.readthedocs.io/en/latest/api.html\nWe will use pyeodh throughout this presentation.\n\n# Imports\nimport pyeodh\n\nimport os\n\nimport shapely \nimport geopandas as gpd\nimport folium\nfrom localtileserver import TileClient\nimport dask.distributed\nimport folium\n\nimport requests\nfrom requests import HTTPError\n\nimport urllib.request\nfrom io import BytesIO \nfrom PIL import Image\nfrom IPython.display import display\nfrom pystac_client import Client\nfrom odc.stac import configure_rio, stac_load # the data cube bit\n\n#import shapely.geometry\n\nHaving imported the necessary libraries the next task is to set up the locations of the areas of interest. Having created the AOI points the user needs to connect to the Resource Catalogue so that they can start to find some data.\n\n# Areas of Interest\nrut_pnt = shapely.Point(-0.683261054299237, 52.672193937442586) # a site near Rutland\nthet_pnt = shapely.Point(0.6715892933273722, 52.414471075812315) # a site near Thetford\n\n\n# Optional cell\n# If you want to see these points on a map run this cell\n\n# Create a map (m) centered between the two points\ncenter_lat = (rut_pnt.y + thet_pnt.y) / 2\ncenter_lon = (rut_pnt.x + thet_pnt.x) / 2\n\nm = folium.Map(location=[center_lat, center_lon], zoom_start=8)\n\n# Add markers for each point\nfolium.Marker([rut_pnt.y, rut_pnt.x], popup=\"Rutland Site\", icon=folium.Icon(color=\"blue\")).add_to(m)\nfolium.Marker([thet_pnt.y, thet_pnt.x], popup=\"Thetford Site\", icon=folium.Icon(color=\"green\")).add_to(m)\n\n# Step 4: Display the map\nm\n\n\n# Connect to the Hub\nclient = pyeodh.Client().get_catalog_service()\n\n# Print a list of the collections held in the Resource Catalogue (their id and description).\n# As the Resource Catalogue fills and development continues, the number of collections and the richness of their descriptions will increase\nfor collect in client.get_collections():\n    print(f\"{collect.id}: {collect.description}\")\n\ncmip6: CMIP6\ncordex: CORDEX\nukcp: UKCP\ndefra-airbus: A collection of Airbus data for the DEFRA use case.\ndefra-planet: A collection of Planet data for the DEFRA use case.\nairbus_sar_data: The German TerraSAR-X / TanDEM-X satellite formation and the Spanish PAZ satellite (managed by Hisdesat Servicios Estratégicos S.A.) are being operated in the same orbit tube and feature identical ground swaths and imaging modes - allowing Airbus and Hisdesat to establish a unique commercial Radar Constellation. The satellites carry a high frequency X-band Synthetic Aperture Radar (SAR) sensor in order to acquire datasets ranging from very high-resolution imagery to wide area coverage.\nairbus_data_example: Airbus data\nsentinel2_ard: sentinel 2 ARD\nsentinel1: Sentinel 1\nnaip: The [National Agriculture Imagery Program](https://www.fsa.usda.gov/programs-and-services/aerial-photography/imagery-programs/naip-imagery/) (NAIP) provides U.S.-wide, high-resolution aerial imagery, with four spectral bands (R, G, B, IR).  NAIP is administered by the [Aerial Field Photography Office](https://www.fsa.usda.gov/programs-and-services/aerial-photography/) (AFPO) within the [US Department of Agriculture](https://www.usda.gov/) (USDA).  Data are captured at least once every three years for each state.  This dataset represents NAIP data from 2010-present, in [cloud-optimized GeoTIFF](https://www.cogeo.org/) format.\n\n\n\n\n# The next thing to do is find some open data\n# For this presentation we want to find Sentinel-2 analysis ready (ARD) imagery near Rutland\n\n# First we just want to understand some of the parameters linked to the data collection\n# We will just print the first 5 records and the dataset temporal extent   \nsentinel2_ard = client.get_catalog(\"supported-datasets/ceda-stac-fastapi\").get_collection('sentinel2_ard')\nsentinel2_ard.get_items()\n\nlim = 5\ni = 0\n\nfor item in sentinel2_ard.get_items():\n    if i &lt; lim:\n        print(item.id)\n        i += 1\n\nprint('DATASET TEMPORAL EXTENT: ', [str(d) for d in sentinel2_ard.extent.temporal.intervals[0]])\n\nneodc.sentinel_ard.data.sentinel_2.2023.11.21.S2B_20231121_latn536lonw0052_T30UUE_ORB123_20231121122846_utm30n_TM65\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn563lonw0037_T30VVH_ORB037_20231120132420_utm30n_osgb\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn546lonw0037_T30UVF_ORB037_20231120132420_utm30n_osgb\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn536lonw0007_T30UXE_ORB037_20231120132420_utm30n_osgb\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn528lonw0022_T30UWD_ORB037_20231120132420_utm30n_osgb\nDATASET TEMPORAL EXTENT:  ['2023-01-01 11:14:51+00:00', '2023-11-01 11:43:49+00:00']\n\n\n\n# To find out information about all the imagery in the collection then use this cell\n# It undertakes a search for specific date ranges (November 2023) and limits the pagination return to 10\nitem_search = client.search(\n    collections=['sentinel2_ard'],\n    catalog_paths=[\"supported-datasets/ceda-stac-fastapi\"],\n    query=[\n        'start_datetime&gt;=2023-11-01',\n        'end_datetime&lt;=2023-11-30', \n    ],\n    limit=10,\n)\n\n# The item id and start time of image capture can be printed\n# If end time is also required, add the following code to the print statement: item.properties[\"end_datetime\"]  \nfor item in item_search:\n    print(item.id, item.properties[\"start_datetime\"])\n\nneodc.sentinel_ard.data.sentinel_2.2023.11.21.S2B_20231121_latn536lonw0052_T30UUE_ORB123_20231121122846_utm30n_TM65 2023-11-21T11:43:49+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn563lonw0037_T30VVH_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn546lonw0037_T30UVF_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn536lonw0007_T30UXE_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn528lonw0022_T30UWD_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn527lonw0007_T30UXD_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn519lonw0037_T30UVC_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn519lonw0022_T30UWC_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn518lonw0008_T30UXC_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.20.S2A_20231120_latn510lonw0036_T30UVB_ORB037_20231120132420_utm30n_osgb 2023-11-20T11:23:51+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.18.S2B_20231118_latn554lonw0053_T30UUG_ORB080_20231118122250_utm30n_osgb 2023-11-18T11:33:19+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.17.S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb 2023-11-17T11:13:31+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.17.S2A_20231117_latn519lone0023_T31UDT_ORB137_20231117131218_utm31n_osgb 2023-11-17T11:13:31+00:00\nneodc.sentinel_ard.data.sentinel_2.2023.11.17.S2A_20231117_latn509lone0009_T31UCS_ORB137_20231117131218_utm31n_osgb 2023-11-17T11:13:31+00:00\n\n\n\n# To find specific imagery for the Rutland site we need to add the intersects parameter. We set this to be our AOI point.\n# We can also filter the search by cloud cover, in this case limiting our search to images with less than 50% cloud in them\n\nitems = client.search(\n    collections=['sentinel2_ard'],\n    catalog_paths=[\"supported-datasets/ceda-stac-fastapi\"],\n    intersects=rut_pnt,\n    query=[\n        'start_datetime&gt;=2023-11-01',\n        'end_datetime&lt;=2023-11-30', \n        'Cloud Coverage Assessment&lt;=50.0'\n    ],\n    limit=10,\n)\n\n# We can then count the number of items returned by the search \nprint('Number of items found: ', items.total_count)\n\nNumber of items found:  2\n\n\n\n# For the purposes of this presentation we will look at the second record ([1]) in more detail\n# First we need to understand what information we can access\n\na = items[1].to_dict()\nprint(a.keys())\n\ndict_keys(['type', 'stac_version', 'id', 'properties', 'geometry', 'links', 'assets', 'bbox', 'stac_extensions', 'collection'])\n\n\n\n# The data we want to access is stored under the 'assets' key. But what information is held in that? \nfor key in (a['assets']):\n    print(key)\n\ncloud\ncloud_probability\ncog\nmetadata\nsaturated_pixels\nthumbnail\ntopographic_shadow\nvalid_pixels\n\n\n\n# Now we can get the link to each of the different assets\nfor key, value in items[1].assets.items():\n    print(key, value.href)\n\ncloud https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_clouds.tif\ncloud_probability https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_clouds_prob.tif\ncog https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref.tif\nmetadata https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_meta.xml\nsaturated_pixels https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_sat.tif\nthumbnail https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_thumbnail.jpg\ntopographic_shadow https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_toposhad.tif\nvalid_pixels https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_valid.tif\n\n\n\n# We can use this information to view the image thumbnail\n\nasset_dict = items[1].assets\n\n# Get the url as a string\nthumbnail_assets = [v for k, v in asset_dict.items() if 'thumbnail' in k]\nthumbnail_url = thumbnail_assets[0].href\n\n# Here we open the remote URL, read the data and dislay the thumbnail \nwith urllib.request.urlopen(thumbnail_url) as url:\n    img = Image.open(BytesIO(url.read()))\n\ndisplay(img)\n\n\n\n\n\n\n\n\nThis shows that we can relatively easily interrogate the Resource Catalogue and filter the results so that we can find the data we require in the EODH. With a bit of tweaking of the code the user could also generate a list of assets and accompanying URLs to the datasets (for this and other datasets).\nNow our use wants to see what commercial data exists for Thetford\n\n# Find some commercial data\n\nfor collect in client.get_collections():\n    if 'defra' in collect.id: \n        print(f\"{collect.id}: {collect.description}\")\n\ndefra-airbus: A collection of Airbus data for the DEFRA use case.\ndefra-planet: A collection of Planet data for the DEFRA use case.\n\n\n\n# Let's search for information on the Planet holdings  \nplanet = client.get_catalog(\"supported-datasets/defra\").get_collection('defra-planet')\nplanet.get_items()\n\nlim = 5\ni = 0\n\nfor item in planet.get_items():\n    if i &lt; lim:\n        print(item.id)\n        i += 1\n\nprint('PLANET DATASET TEMPORAL EXTENT: ', [str(d) for d in planet.extent.temporal.intervals[0]])\n\n\n2024-08-23_strip_7527622_composite\n2024-08-23_strip_7527462_composite\nPLANET DATASET TEMPORAL EXTENT:  ['2024-08-23 11:09:19.358417+00:00', '2024-08-23 11:24:40.991786+00:00']\n\n\n\n# To find specific imagery for the Thetford site we need to add the intersects parameter. We set this to be our AOI point.\nitems1 = client.search(\n    collections=['defra-planet'],\n    catalog_paths=[\"supported-datasets/defra\"],\n    intersects=thet_pnt,\n    limit=10,\n)\n\nitems2 = client.search(\n    collections=['defra-airbus'],\n    catalog_paths=[\"supported-datasets/defra\"],\n    intersects=thet_pnt,\n    limit=10,\n)\n\n# We can then count the number of items returned by the search \nprint('Number of Planet items found: ', items1.total_count)\nprint('Number of Airbus items found: ', items2.total_count)\n\nNumber of Planet items found:  1\nNumber of Airbus items found:  2\n\n\n\nfor key, value in items1[0].assets.items():\n    print('Planet: ', key, value)\n\nPlanet:  data &lt;Asset href=2024-08-23_strip_7527462_composite_file_format.tif&gt;\nPlanet:  udm2 &lt;Asset href=2024-08-23_strip_7527462_composite_udm2_file_format.tif&gt;\n\n\n\n\nTODO!!!!\n\n\nDISPLAY AN IMAGE\n\n\nEODH: it’s massive compute\nThe EODH compute architecture is built around a new OGC standard called EO Application Packages (EOAP). These are complex constructions of code and data, and at their core is the concept of a Common Workflow Language (CWL) workflow. To run CWL workflows you need a CWL runner, and the EODH Workflow Runner provides that. The EOAPs require a workflow description in CWL, a Docker container, bespoke scripts and links to the data. In the case of EODH, the data inputs and outputs are to be provided as STAC catalogues. Oxidian, as part of our work developing integrations for the Hub, have created a generator tool eoap-gen that abstracts away much of the complexity (check out the training materials repository and website for more details).\nOxidian have also developed a QGIS plugin to allow desktop users to discover, parameterise and execute workflows on the Hub.\n\n# First the user needs to connect to the Workflow Runner\n# Currently this is done by obtaining a user account and API key from the core development team. Here, those details have been saved in secrets.txt\n\nwith open('secrets.txt', 'r') as file:\n    lines = file.readlines()\n    username = lines[0].strip().split('=')[1].strip('\"')\n    token = lines[1].strip().split('=')[1].strip('\"')\n\nclientwfr = pyeodh.Client(username=username, token=token, s3_token=token)\nwfr = clientwfr.get_ades()\n\nOur user wants to know what workflows they have access to in their workspace on the Hub.\n\n# List the workflows available in the user workspace\nfor p in wfr.get_processes():\n    print(p.id)\n\ndisplay\necho\nconvert-img\n\n\nAs development continues the number of demonstration workflows available to users will increase. With uptake of the generator tool users will also be able to create their own bespoke workflows. In time, the Hub will contain organisational accounts and the ability to share workflow files.\nOur user wants to deploy a workflow that they have found online. They can do so for compliant CWL files by submitting the URl.\n\n# Deploy a workflow using a URL to a .cwl file hosted online\nconvert_url_proc = wfr.deploy_process(\n    cwl_url=\"https://raw.githubusercontent.com/EOEPCA/deployment-guide/main/deploy/samples/requests/processing/convert-url-app.cwl\"\n)\nprint(convert_url_proc.id, convert_url_proc.description, \": Deployed\")\nprint('')\n# List the available workflows\nfor p in wfr.get_processes():\n    print(p.id)\n\nconvert-url Convert URL : Deployed\n\ndisplay\necho\nconvert-img\nconvert-url\n\n\n\n# If a user wants to tidy their workspace or no longer wants access to a workflow they can remove it\ntry:\n    wfr.get_process(\"convert-url\").delete()\n    print(\"Process removed\")\nexcept HTTPError:\n    print(\"Process not found\")\n\nProcess removed\n\n\nThe user is interested in the ARD files, but they are too large for the task that they want to undertake. The workflow file linked to here takes a series of data from the Sentinel 2 ARD collection and resizes the imagery using gdal_translate. The CWL file needs to be submitted to the Workflow Runner and parameterised, before it can then be run.\n\n# Deploy the workflow\n# Remove an existing nstance of the workflow\ntry:\n    wfr.get_process(\"convert-img\").delete()\n    print(\"Process removed\")\nexcept HTTPError:\n    print(\"Process not found\")\n\n# Deploy from a URL to a .cwl file hosted online\n#img_proc = wfr.deploy_process(cwl_yaml=cwl_yaml)\nimg_proc = wfr.deploy_process(cwl_url='https://raw.githubusercontent.com/ajgwords/eodh-tests/main/resize-col.cwl')\n\nprint(img_proc.id, img_proc.description, \": Deployed\")\nprint('')\n# List the available workflows\nfor p in wfr.get_processes():\n    print(p.id)\n\nProcess not found\nresize-col Resize collection cogs : Deployed\n\ndisplay\necho\nresize-col\n\n\nOnce the CWL file has been submitted then it is possible for users with suitable permissions to also view the list of available workflows through the QGIS plugin.\n\n\n\nimage.png\n\n\nThe user can choose and parameterise a workflow using the QGIS plugin as shown in this screenshot. A series of defaults are provided with all workflow files so a user can run the workflow straight away using those. To do so in code, the user provides an empty dictionary.\n\n\n\nimage.png\n\n\n\n# Run the workflow using the defaults\npyeodh.set_log_level(10) # set the logging to be verbose\n\nresize_job = img_proc.execute(\n    {\n    }\n)\n\nprint(resize_job.id, resize_job.status, resize_job.message)\n\nDEBUG: _request_json_raw received {'self': &lt;pyeodh.client.Client object at 0x7d35e47e45c0&gt;, 'method': 'POST', 'url': 'https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/processes/resize-col/execution', 'headers': {'Prefer': 'respond-async'}, 'params': None, 'data': {'inputs': {'workspace': 'ajgwords'}}, 'encode': &lt;function _encode_json at 0x7d3635f30540&gt;}\nDEBUG: Making request: POST https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/processes/resize-col/execution\n       headers: {'Prefer': 'respond-async', 'Content-Type': 'application/json'}\n       params: None\n       body: {\"inputs\": {\"workspace\": \"ajgwords\"}}\nDEBUG: Received response 201\n       headers: {'Content-Type': 'application/json;charset=UTF-8', 'Transfer-Encoding': 'chunked', 'Connection': 'keep-alive', 'Server': 'nginx/1.27.0', 'Date': 'Wed, 18 Sep 2024 14:05:46 GMT', 'x-powered-by': 'ZOO-Project-DRU', 'x-also-powered-by': 'jwt.securityIn', 'x-also-also-powered-by': 'dru.securityIn', 'preference-applied': 'respond-async', 'x-also-also-also-powered-by': 'dru.securityOut', 'location': 'https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/jobs/19efd624-75c7-11ef-9849-4e9264aaf6f3', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Credentials': 'true', 'Access-Control-Allow-Methods': 'GET, PUT, POST, DELETE, PATCH, OPTIONS', 'Access-Control-Allow-Headers': 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization,Prefer', 'Access-Control-Max-Age': '1728000', 'X-Cache': 'Miss from cloudfront', 'Via': '1.1 a6a1a17bbe377bf7c4423397c71959da.cloudfront.net (CloudFront)', 'X-Amz-Cf-Pop': 'LHR50-P1', 'X-Amz-Cf-Id': 'RtavU9ppINxjxyCvlYOnhxdNqGnDtX-HNJmyLlCbtYPf3Dcd5MgLsg=='}\n       content: {\n         \"jobID\": \"19efd624-75c7-11ef-9849-4e9264aaf6f3\",\n         \"type\": \"process\",\n         \"processID\": \"resize-col\",\n         \"created\": \"2024-09-18T14:05:46.805Z\",\n         \"started\": \"2024-09-18T14:05:46.805Z\",\n         \"updated\": \"2024-09-18T14:05:46.805Z\",\n         \"status\": \"running\",\n         \"message\": \"ZOO-Kernel accepted to run your service!\",\n         \"links\": [\n           {\n             \"title\": \"Status location\",\n             \"rel\": \"monitor\",\n             \"type\": \"application/json\",\n             \"href\": \"https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/jobs/19efd624-75c7-11ef-9849-4e9264aaf6f3\"\n           }\n         ]\n       }\n\n\n19efd624-75c7-11ef-9849-4e9264aaf6f3 running ZOO-Kernel accepted to run your service!\n\n\n\nresize_job.refresh()\nprint(resize_job.id, resize_job.status, resize_job.message)\n\nDEBUG: _request_json_raw received {'self': &lt;pyeodh.client.Client object at 0x7d35e47e45c0&gt;, 'method': 'GET', 'url': 'https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/jobs/19efd624-75c7-11ef-9849-4e9264aaf6f3', 'headers': None, 'params': None, 'data': None, 'encode': &lt;function _encode_json at 0x7d3635f30540&gt;}\nDEBUG: Making request: GET https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/jobs/19efd624-75c7-11ef-9849-4e9264aaf6f3\n       headers: {}\n       params: None\n       body: None\nDEBUG: Received response 200\n       headers: {'Content-Type': 'application/json;charset=UTF-8', 'Content-Length': '507', 'Connection': 'keep-alive', 'Server': 'nginx/1.27.0', 'Date': 'Wed, 18 Sep 2024 14:05:54 GMT', 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Credentials': 'true', 'Access-Control-Allow-Methods': 'GET, PUT, POST, DELETE, PATCH, OPTIONS', 'Access-Control-Allow-Headers': 'DNT,User-Agent,X-Requested-With,If-Modified-Since,Cache-Control,Content-Type,Range,Authorization,Prefer', 'Access-Control-Max-Age': '1728000', 'X-Cache': 'Miss from cloudfront', 'Via': '1.1 a6a1a17bbe377bf7c4423397c71959da.cloudfront.net (CloudFront)', 'X-Amz-Cf-Pop': 'LHR50-P1', 'X-Amz-Cf-Id': 'IakHOzKo8AnbmuIW_lFytmYjofpvygKjKotlpOjxhGiQ-a5G6RH22A=='}\n       content: {\"progress\": 15, \"jobID\": \"19efd624-75c7-11ef-9849-4e9264aaf6f3\", \"type\": \"process\", \"processID\": \"resize-col\", \"created\": \"2024-09-18T14:05:46.805Z\", \"started\": \"2024-09-18T14:05:46.805Z\", \"updated\": \"2024-09-18T14:05:48.804Z\", \"status\": \"running\", \"message\": \"processing environment created, preparing execution\", \"links\": [{\"title\": \"Status location\", \"rel\": \"monitor\", \"type\": \"application/json\", \"href\": \"https://test.eodatahub.org.uk/ades/ajgwords/ogc-api/jobs/19efd624-75c7-11ef-9849-4e9264aaf6f3\"}]}\n\n\n19efd624-75c7-11ef-9849-4e9264aaf6f3 running processing environment created, preparing execution\n\n\nThe outputs above show the status of the running job: \"status\": \"running\". The job status can also be monitored using the QGIS plugin.\n\n\n\nimage.png\n\n\n\n\n\nimage-2.png\n\n\nThe outputs are accessible and loadable from the QGIS plugin.\nOriginal image:  Resampled image: \n\n\nEODH: it’s data analysis\nNotebook service can be used with pyeodh and other libraries installed using pip to analyse data and outputs\n\nfrom localtileserver import TileClient\n\n#data_url = 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref.tif'\nmap = TileClient('data/S2A_clip_rend.tif')\n#map = TileClient(data_url)\nmap\n\n/home/al/miniforge3/envs/eodh/lib/python3.12/site-packages/rio_tiler/io/rasterio.py:130: NoOverviewWarning: The dataset has no Overviews. rio-tiler performances might be impacted.\n  warnings.warn(\n\n\n\n\n\n\nprint(a['assets']['cog']['href'])\nprint()\nfor key in (a['assets']['cog']['eo:bands']):\n    print(key)\n\ns2url = (a['assets']['cog']['href'])\n\n\n\n# Step 1: Define the URL of the Cloud Optimized GeoTIFF (COG)\ncog_path = \"https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/11/17/S2A_20231117_latn527lonw0007_T30UXD_ORB137_20231117131218_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref.tif\"\n\nimport rioxarray\nimport numpy as np\nfrom shapely.geometry import box\nimport geopandas as gpd\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\n\n# Read the image as an xarray dataset\ndata = rioxarray.open_rasterio(cog_path)\n\n# Step 2: Define the clipping area (bounding box) in the same CRS as the image\n# Adjust the minx, miny, maxx, maxy to your area of interest\nminx, miny, maxx, maxy = 481682, 296841, 512343, 313344  # Example bounds in UTM\nbbox = box(minx, miny, maxx, maxy)\n\n# Convert the bounding box into a GeoDataFrame\ngeo_df = gpd.GeoDataFrame({'geometry': [bbox]}, crs=data.rio.crs)\n\n# Step 3: Clip the data using the bounding box (rioxarray will handle the masking)\nclipped_data = data.rio.clip(geo_df.geometry.apply(lambda x: x.__geo_interface__), geo_df.crs)\n\n\n\n\n# Step 4: Select three bands for RGB visualization\n# Assuming band 1 = Blue, band 2 = Green, band 3 = Red\n# Check the specific band indexes based on your data\nred_band = clipped_data.sel(band=3)  # Select the Red band (band index 3)\ngreen_band = clipped_data.sel(band=2)  # Select the Green band (band index 2)\nblue_band = clipped_data.sel(band=1)  # Select the Blue band (band index 1)\n\n# Step 5: Normalize the bands for display (values between 0 and 255)\ndef normalize_band(band):\n    band_min, band_max = band.min(), band.max()\n    return ((band - band_min) / (band_max - band_min) * 255).astype(np.uint8)\n\n# Normalize the selected bands\nred_norm = normalize_band(red_band)\ngreen_norm = normalize_band(green_band)\nblue_norm = normalize_band(blue_band)\n\n# Step 6: Stack the three bands into an RGB image\nrgb_image = np.dstack([red_norm, green_norm, blue_norm])\n\n# Step 7: Convert the NumPy array to a PIL image\npil_image = Image.fromarray(rgb_image)\n\n# Step 8: Display the image using PIL or matplotlib\npil_image.show()\n\n# Alternatively, display with matplotlib\nplt.imshow(rgb_image)\nplt.title(\"Clipped RGB Satellite Image\")\nplt.axis('off')\nplt.show()\n\n\nTowards a data cube?\nFollowing https://odc-stac.readthedocs.io/en/latest/notebooks/stac-load-e84-aws.html\n\n\n\n\ndef convert_bounds(bbox, invert_y=False):\n    \"\"\"\n    Helper method for changing bounding box representation to leaflet notation\n\n    ``(lon1, lat1, lon2, lat2) -&gt; ((lat1, lon1), (lat2, lon2))``\n    \"\"\"\n    x1, y1, x2, y2 = bbox\n    if invert_y:\n        y1, y2 = y2, y1\n    return ((y1, x1), (y2, x2))\n\n\n# FIND STAC ITEMS\n#catalog = Client.open(\"https://earth-search.aws.element84.com/v1/\")\n\nurl = \"https://api.stac.ceda.ac.uk/\"\n\nclient = Client.open(url)\nfor coll in client.get_collections():\n    print(f\"{coll.id}: {coll.description}\")\n\ncmip6: CMIP6\ncordex: CORDEX\nland_cover: land_cover\nsentinel1: Sentinel 1\nsentinel2_ard: sentinel 2 ARD\nsst-cdrv3-collection: collection of EOCIS SST CDR V3\nukcp: UKCP\n\n\n\nsentinel2_ard = client.get_collection('sentinel2_ard')\n\nsentinel2_ard.get_items()\n\n# check the spatial and temporal extent of the collection\n\nprint(\"spatial extent:\", sentinel2_ard.extent.spatial.bboxes)\nprint(\"data range:\", [str(d) for d in sentinel2_ard.extent.temporal.intervals[0]])\n\n\n\n#items = list(query.items())\n#print(f\"Found: {len(items):d} datasets\")\n\n# Convert STAC items into a GeoJSON FeatureCollection\n#stac_json = query.item_collection_as_dict()\n\nspatial extent: [[-9.00034454651177, 49.48562028352171, 3.1494256015866995, 61.33444247301668]]\ndata range: ['2023-01-01 11:14:51+00:00', '2023-11-01 11:43:49+00:00']\n\n\n\n# SEARCH\nitem_search = client.search(\n    collections=['sentinel2_ard'],\n    query=[\n        'start_datetime&gt;=2023-01-01',\n        'end_datetime&lt;=2023-02-28', \n    ],\n    max_items=100,\n)\n\n\nitems = list(item_search.items())\nlen(items)\n\n100\n\n\n\n#from shapely import Point\n#point = Point(-1.3144835766058023, 51.57555380377267) # Atlas building at RAL\n\nitem_search = client.search(\n    collections=['sentinel2_ard'],\n    intersects=rut_pnt,\n    query=[\n        'start_datetime&gt;=2023-01-01',\n        'end_datetime&lt;=2023-02-28', \n      ],\n    max_items=10,\n)\n\nitems = list(item_search.items())\nitems\n\n[&lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.25.S2B_20230225_lat53lon071_T30UXD_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.23.S2A_20230223_lat53lon071_T30UXD_ORB037_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.20.S2A_20230220_lat53lon071_T30UXD_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.15.S2B_20230215_lat53lon071_T30UXD_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.13.S2A_20230213_lat53lon071_T30UXD_ORB037_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.02.08.S2B_20230208_lat53lon071_T30UXD_ORB037_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.31.S2A_20230131_lat53lon071_T30UXD_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.29.S2B_20230129_lat53lon071_T30UXD_ORB037_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.26.S2B_20230126_lat53lon071_T30UXD_ORB137_utm30n_osgb&gt;,\n &lt;Item id=neodc.sentinel_ard.data.sentinel_2.2023.01.24.S2A_20230124_lat53lon071_T30UXD_ORB037_utm30n_osgb&gt;]\n\n\n\nitems[0].to_dict()\n\n\nitem_search = client.search(\n    collections=['sentinel2_ard'],\n    intersects=point,\n    query=[\n        'start_datetime&gt;=2023-01-01',\n        'end_datetime&lt;=2023-02-28', \n        'eo:cloud_cover&lt;=50.0'\n      ],\n    max_items=10,\n)\n\nitems = list(item_search.items())\nitems\n\n\nitems[0].to_dict()\n\n{'type': 'Feature',\n 'stac_version': '1.0.0',\n 'id': 'neodc.sentinel_ard.data.sentinel_2.2023.02.25.S2B_20230225_lat53lon071_T30UXD_ORB137_utm30n_osgb',\n 'properties': {'file_count': 7,\n  'start_datetime': '2023-02-25T11:09:39Z',\n  'end_datetime': '2023-02-25T11:09:39Z',\n  'NSSDC Identifier': '2015-000A',\n  'created': '2024-02-07T11:36:34.672255Z',\n  'Instrument Family Name': 'Multi-Spectral Instrument',\n  'Platform Number': '2B',\n  'Datatake Type': 'INS-NOBS',\n  'esa_file_name': 'S2B_MSIL1C_20230225T110939_N0509_R137_T30UXD_20230225T115203',\n  'Ground Tracking Direction': 'descending',\n  'datetime': '2023-02-25T11:09:39Z',\n  'instance_id': 'neodc.sentinel_ard.data.sentinel_2.2023.02.25.S2B_20230225_lat53lon071_T30UXD_ORB137_utm30n_osgb',\n  'size': 1960567691,\n  'Product Type': 'S2MSI1C',\n  'Instrument Family Name Abbreviation': 'MSI',\n  'Start Orbit Number': '031194',\n  'eo:cloud_cover': '84.3860969273493',\n  'Start Relative Orbit Number': '137',\n  'updated': '2024-02-07T11:36:34.672255Z',\n  'Instrument Mode': None,\n  'EPSG': '27700'},\n 'geometry': {'coordinates': [[[-1.5015259, 53.24020834947074],\n    [0.141769904481162, 53.20820137275637],\n    [0.071678487044592, 52.22256603361336],\n    [-1.5350342, 52.25345680664421],\n    [-1.5015259, 53.24020834947074]]],\n  'type': 'Polygon'},\n 'links': [{'rel': 'self',\n   'href': 'https://api.stac.ceda.ac.uk/collections/sentinel2_ard/items/neodc.sentinel_ard.data.sentinel_2.2023.02.25.S2B_20230225_lat53lon071_T30UXD_ORB137_utm30n_osgb',\n   'type': 'application/geo+json'},\n  {'rel': 'parent',\n   'href': 'https://api.stac.ceda.ac.uk/collections/sentinel2_ard',\n   'type': 'application/json'},\n  {'rel': 'collection',\n   'href': 'https://api.stac.ceda.ac.uk/collections/sentinel2_ard',\n   'type': 'application/json'},\n  {'rel': 'root',\n   'href': 'https://api.stac.ceda.ac.uk/',\n   'type': 'application/json',\n   'title': 'stac-fastapi-elasticsearch'}],\n 'assets': {'cloud': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/25/S2B_20230225_lat53lon071_T30UXD_ORB137_utm30n_osgb_clouds.tif',\n   'size': 1348575,\n   'location': 'on_disk',\n   'roles': ['data']},\n  'metadata': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/25/S2B_20230225_lat53lon071_T30UXD_ORB137_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_meta.xml',\n   'size': 18363,\n   'location': 'on_disk',\n   'roles': ['metadata']},\n  'thumbnail': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/25/S2B_20230225_lat53lon071_T30UXD_ORB137_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_thumbnail.jpg',\n   'size': 70539,\n   'location': 'on_disk',\n   'roles': ['thumbnail']},\n  'topographic_shadow': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/25/S2B_20230225_lat53lon071_T30UXD_ORB137_utm30n_osgb_toposhad.tif',\n   'size': 241186,\n   'location': 'on_disk',\n   'roles': ['data']},\n  'cog': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/25/S2B_20230225_lat53lon071_T30UXD_ORB137_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref.tif',\n   'size': 1956895150,\n   'eo:bands': [{'full_width_half_max': 0.07,\n     'central_wavelength': 492.1,\n     'name': 'B02',\n     'description': 'Blue',\n     'common_name': 'blue'},\n    {'full_width_half_max': 0.04,\n     'central_wavelength': 559,\n     'name': 'B03',\n     'description': 'Green',\n     'common_name': 'green'},\n    {'full_width_half_max': 0.03,\n     'central_wavelength': 665,\n     'name': 'B04',\n     'description': 'Red',\n     'common_name': 'red'},\n    {'full_width_half_max': 0.02,\n     'central_wavelength': 703.8,\n     'name': 'B05',\n     'description': 'Visible and Near Infrared',\n     'common_name': 'rededge'},\n    {'full_width_half_max': 0.02,\n     'central_wavelength': 739.1,\n     'name': 'B06',\n     'description': 'Visible and Near Infrared',\n     'common_name': 'rededge'},\n    {'full_width_half_max': 0.02,\n     'central_wavelength': 779.7,\n     'name': 'B07',\n     'description': 'Visible and Near Infrared',\n     'common_name': 'rededge'},\n    {'full_width_half_max': 0.11,\n     'central_wavelength': 833,\n     'name': 'B08',\n     'description': 'Visible and Near Infrared',\n     'common_name': 'nir'},\n    {'full_width_half_max': 0.02,\n     'central_wavelength': 864,\n     'name': 'B08a',\n     'description': 'Visible and Near Infrared',\n     'common_name': 'nir08'},\n    {'full_width_half_max': 0.09,\n     'central_wavelength': 1610.4,\n     'name': 'B11',\n     'description': 'Short Wave Infrared',\n     'common_name': 'swir16'},\n    {'full_width_half_max': 0.19,\n     'central_wavelength': 2185.7,\n     'name': 'B12',\n     'description': 'Short Wave Infrared',\n     'common_name': 'swir22'}],\n   'location': 'on_disk',\n   'roles': ['data']},\n  'valid_pixels': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/25/S2B_20230225_lat53lon071_T30UXD_ORB137_utm30n_osgb_valid.tif',\n   'size': 288519,\n   'location': 'on_disk',\n   'roles': ['data']},\n  'saturated_pixels': {'href': 'https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/25/S2B_20230225_lat53lon071_T30UXD_ORB137_utm30n_osgb_sat.tif',\n   'size': 1705359,\n   'location': 'on_disk',\n   'roles': ['data']}},\n 'bbox': [-1.5350342, 52.22256603361336, 0.141769904481162, 53.24020834947074],\n 'stac_extensions': ['https://stac-extensions.github.io/eo/v1.1.0/schema.json'],\n 'collection': 'sentinel2_ard'}\n\n\n\nfor key, value in items[1].assets.items():\n    print(key, value.href)\n\ncloud https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/23/S2A_20230223_lat53lon071_T30UXD_ORB037_utm30n_osgb_clouds.tif\nmetadata https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/23/S2A_20230223_lat53lon071_T30UXD_ORB037_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_meta.xml\nthumbnail https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/23/S2A_20230223_lat53lon071_T30UXD_ORB037_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref_thumbnail.jpg\ntopographic_shadow https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/23/S2A_20230223_lat53lon071_T30UXD_ORB037_utm30n_osgb_toposhad.tif\ncog https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/23/S2A_20230223_lat53lon071_T30UXD_ORB037_utm30n_osgb_vmsk_sharp_rad_srefdem_stdsref.tif\nvalid_pixels https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/23/S2A_20230223_lat53lon071_T30UXD_ORB037_utm30n_osgb_valid.tif\nsaturated_pixels https://dap.ceda.ac.uk/neodc/sentinel_ard/data/sentinel_2/2023/02/23/S2A_20230223_lat53lon071_T30UXD_ORB037_utm30n_osgb_sat.tif\n\n\n\n# SET UP DASK CLIENT\n\nclient3 = dask.distributed.Client()\nconfigure_rio(cloud_defaults=True, aws={\"aws_unsigned\": True}, client=client) # sets up gdal for cloud use\ndisplay(client3)\n\n\n     \n    \n        Client\n        Client-be9a6db2-75ca-11ef-bf9a-f40669402fbd\n        \n\n\n\nConnection method: Cluster object\nCluster type: distributed.LocalCluster\n\n\nDashboard: http://127.0.0.1:8787/status\n\n\n\n\n\n\n        \n\n        \n            \n            Cluster Info\n            \n    \n    \n    \n        LocalCluster\n        4dcb16e5\n        \n\n\n\nDashboard: http://127.0.0.1:8787/status\nWorkers: 4\n\n\nTotal threads: 4\nTotal memory: 15.48 GiB\n\n\nStatus: running\nUsing processes: True\n\n\n\n\n\n        \n            \n                Scheduler Info\n            \n\n            \n    \n         \n        \n            Scheduler\n            Scheduler-db0af68a-d8f9-4a97-9546-ed5911dddf0c\n            \n\n\n\nComm: tcp://127.0.0.1:34791\nWorkers: 4\n\n\nDashboard: http://127.0.0.1:8787/status\nTotal threads: 4\n\n\nStarted: Just now\nTotal memory: 15.48 GiB\n\n\n\n\n        \n    \n\n    \n        \n            Workers\n        \n\n        \n        \n             \n            \n            \n                \n                    Worker: 0\n                \n                \n\n\n\nComm: tcp://127.0.0.1:36473\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:36613/status\nMemory: 3.87 GiB\n\n\nNanny: tcp://127.0.0.1:34453\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-7uv32axl\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 1\n                \n                \n\n\n\nComm: tcp://127.0.0.1:34507\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:35983/status\nMemory: 3.87 GiB\n\n\nNanny: tcp://127.0.0.1:40119\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-wngmmuug\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 2\n                \n                \n\n\n\nComm: tcp://127.0.0.1:38845\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:38525/status\nMemory: 3.87 GiB\n\n\nNanny: tcp://127.0.0.1:46169\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-5_ey1q50\n\n\n\n\n            \n            \n        \n        \n        \n             \n            \n            \n                \n                    Worker: 3\n                \n                \n\n\n\nComm: tcp://127.0.0.1:38677\nTotal threads: 1\n\n\nDashboard: http://127.0.0.1:44171/status\nMemory: 3.87 GiB\n\n\nNanny: tcp://127.0.0.1:45463\n\n\n\nLocal directory: /tmp/dask-scratch-space/worker-oialu_md\n\n\n\n\n            \n            \n        \n        \n\n    \n\n\n        \n    \n\n            \n        \n\n    \n\n\n\n\nprint(f\"Found: {len(items):d} datasets\")\n\n# Convert STAC items into a GeoJSON FeatureCollection\nstac_json = item_search.item_collection_as_dict()\n\nFound: 10 datasets\n\n\n\n# REVIEW SEARCH RESULTS\n# MAYBE DELETE\n\ngdf = gpd.GeoDataFrame.from_features(stac_json, \"epsg:4326\")\n\n# Compute granule id from components\n#gdf[\"granule\"] = (\n#    gdf[\"esa_file_name\"].apply(lambda x: f\"{x:02d}\")\n#    + gdf[\"mgrs:latitude_band\"]\n#    + gdf[\"mgrs:grid_square\"]\n#)\n\nfig = gdf.plot(\n    \"esa_file_name\",\n    edgecolor=\"black\",\n    categorical=True,\n    aspect=\"equal\",\n    alpha=0.5,\n    figsize=(6, 12),\n    legend=True,\n    legend_kwds={\"loc\": \"upper left\", \"frameon\": False, \"ncol\": 1},\n)\n_ = fig.set_title(\"STAC Query Results\")\n\n\n\n\n\n\n\n\n\n# PLOT THE SAME, but using FOLIUM\n\n# https://github.com/python-visualization/folium/issues/1501\n#from branca.element import Figure\n\n#import folium\nf = folium.Figure(width=600, height=400)\nm = folium.Map(location=[52, 2], zoom_start=5).add_to(f)\n\n\n\n\n\n#fig = Figure(width=\"400px\", height=\"500px\")\n#map1 = folium.Map()\n#fig.add_child(map1)\n\n#folium.GeoJson(\n#    shapely.geometry.box(*bbox),\n#    style_function=lambda x: dict(fill=False, weight=1, opacity=0.7, color=\"olive\"),\n#    name=\"Query\",\n#).add_to(m)\n\n\ngdf.explore(\n    \"esa_file_name\",\n    categorical=True,\n    tooltip=[\n        \"esa_file_name\",\n        \"datetime\",\n        \"eo:cloud_cover\",\n    ],\n    popup=False,\n    legend=False,\n    style_kwds=dict(fillOpacity=0.1, width=2),\n    name=\"STAC\",\n    m=m,\n)\n\n#map1.fit_bounds(bounds=convert_bounds(gdf.unary_union.bounds))\n#display(fig)\n\n\n\n\n\n# CONSTRUCT DASK DATASET\n# Note: there are 9 STAC Items on input, and only one timeslice on output. \n# Due to groupby=\"solar_day\" (all items that occured on the same day added to one image plane).\n\n# Since we will plot it on a map we need to use `EPSG:3857` projection\ncrs = \"epsg:3857\"\nzoom = 2**5  # overview level 5\n\n#xx = stac_load(\n#    items,\n#    bands=(\"B04\", \"B03\", \"B02\"),\n#    crs=crs,\n#    resolution=10 * zoom)#,\n#    chunks={},  # &lt;-- use Dask\n#    groupby=\"solar_day\",\n#)\n#display(xx)\n\n\n#xx = stac_load(\n#    items,\n#    chunks={\"x\": 2048, \"y\": 2048},\n#    patch_url=pc.sign,\n#    resolution=resolution,\n#    # force dtype and nodata\n#    dtype=\"uint16\",\n#    nodata=0,\n#)\n\nxx = stac_load(\n    items,\n    crs=crs,\n    resolution=10 * zoom,\n    chunks={\"x\": 2048, \"y\": 2048},  # &lt;-- use Dask\n)\n\nprint(f\"Bands: {','.join(list(xx.data_vars))}\")\ndisplay(xx)\n\nBands: cloud,thumbnail,topographic_shadow,cog,valid_pixels,saturated_pixels\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.Dataset&gt; Size: 82MB\nDimensions:             (y: 586, x: 584, time: 10)\nCoordinates:\n  * y                   (y) float64 5kB 7.028e+06 7.027e+06 ... 6.84e+06\n  * x                   (x) float64 5kB -1.707e+05 -1.704e+05 ... 1.584e+04\n    spatial_ref         int32 4B 3857\n  * time                (time) datetime64[ns] 80B 2023-01-24T11:23:41 ... 202...\nData variables:\n    cloud               (time, y, x) float32 14MB dask.array&lt;chunksize=(1, 586, 584), meta=np.ndarray&gt;\n    thumbnail           (time, y, x) float32 14MB dask.array&lt;chunksize=(1, 586, 584), meta=np.ndarray&gt;\n    topographic_shadow  (time, y, x) float32 14MB dask.array&lt;chunksize=(1, 586, 584), meta=np.ndarray&gt;\n    cog                 (time, y, x) float32 14MB dask.array&lt;chunksize=(1, 586, 584), meta=np.ndarray&gt;\n    valid_pixels        (time, y, x) float32 14MB dask.array&lt;chunksize=(1, 586, 584), meta=np.ndarray&gt;\n    saturated_pixels    (time, y, x) float32 14MB dask.array&lt;chunksize=(1, 586, 584), meta=np.ndarray&gt;xarray.DatasetDimensions:y: 586x: 584time: 10Coordinates: (4)y(y)float647.028e+06 7.027e+06 ... 6.84e+06units :metreresolution :-320.0crs :EPSG:3857array([7027680., 7027360., 7027040., ..., 6841120., 6840800., 6840480.])x(x)float64-1.707e+05 -1.704e+05 ... 1.584e+04units :metreresolution :320.0crs :EPSG:3857array([-170720., -170400., -170080., ...,   15200.,   15520.,   15840.])spatial_ref()int323857spatial_ref :PROJCRS[\"WGS 84 / Pseudo-Mercator\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"Popular Visualisation Pseudo-Mercator\",METHOD[\"Popular Visualisation Pseudo Mercator\",ID[\"EPSG\",1024]],PARAMETER[\"Latitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"easting (X)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"northing (Y)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Web mapping and visualisation.\"],AREA[\"World between 85.06°S and 85.06°N.\"],BBOX[-85.06,-180,85.06,180]],ID[\"EPSG\",3857]]crs_wkt :PROJCRS[\"WGS 84 / Pseudo-Mercator\",BASEGEOGCRS[\"WGS 84\",ENSEMBLE[\"World Geodetic System 1984 ensemble\",MEMBER[\"World Geodetic System 1984 (Transit)\"],MEMBER[\"World Geodetic System 1984 (G730)\"],MEMBER[\"World Geodetic System 1984 (G873)\"],MEMBER[\"World Geodetic System 1984 (G1150)\"],MEMBER[\"World Geodetic System 1984 (G1674)\"],MEMBER[\"World Geodetic System 1984 (G1762)\"],MEMBER[\"World Geodetic System 1984 (G2139)\"],ELLIPSOID[\"WGS 84\",6378137,298.257223563,LENGTHUNIT[\"metre\",1]],ENSEMBLEACCURACY[2.0]],PRIMEM[\"Greenwich\",0,ANGLEUNIT[\"degree\",0.0174532925199433]],ID[\"EPSG\",4326]],CONVERSION[\"Popular Visualisation Pseudo-Mercator\",METHOD[\"Popular Visualisation Pseudo Mercator\",ID[\"EPSG\",1024]],PARAMETER[\"Latitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8801]],PARAMETER[\"Longitude of natural origin\",0,ANGLEUNIT[\"degree\",0.0174532925199433],ID[\"EPSG\",8802]],PARAMETER[\"False easting\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8806]],PARAMETER[\"False northing\",0,LENGTHUNIT[\"metre\",1],ID[\"EPSG\",8807]]],CS[Cartesian,2],AXIS[\"easting (X)\",east,ORDER[1],LENGTHUNIT[\"metre\",1]],AXIS[\"northing (Y)\",north,ORDER[2],LENGTHUNIT[\"metre\",1]],USAGE[SCOPE[\"Web mapping and visualisation.\"],AREA[\"World between 85.06°S and 85.06°N.\"],BBOX[-85.06,-180,85.06,180]],ID[\"EPSG\",3857]]GeoTransform :-170880 320 0 7027840 0 -320array(3857, dtype=int32)time(time)datetime64[ns]2023-01-24T11:23:41 ... 2023-02-...array(['2023-01-24T11:23:41.000000000', '2023-01-26T11:12:39.000000000',\n       '2023-01-29T11:22:29.000000000', '2023-01-31T11:13:11.000000000',\n       '2023-02-08T11:21:29.000000000', '2023-02-13T11:21:51.000000000',\n       '2023-02-15T11:10:49.000000000', '2023-02-20T11:11:01.000000000',\n       '2023-02-23T11:21:11.000000000', '2023-02-25T11:09:39.000000000'],\n      dtype='datetime64[ns]')Data variables: (6)cloud(time, y, x)float32dask.array&lt;chunksize=(1, 586, 584), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n13.05 MiB\n1.31 MiB\n\n\nShape\n(10, 586, 584)\n(1, 586, 584)\n\n\nDask graph\n10 chunks in 1 graph layer\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                           584 586 10\n\n\n\n\nthumbnail(time, y, x)float32dask.array&lt;chunksize=(1, 586, 584), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n13.05 MiB\n1.31 MiB\n\n\nShape\n(10, 586, 584)\n(1, 586, 584)\n\n\nDask graph\n10 chunks in 1 graph layer\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                           584 586 10\n\n\n\n\ntopographic_shadow(time, y, x)float32dask.array&lt;chunksize=(1, 586, 584), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n13.05 MiB\n1.31 MiB\n\n\nShape\n(10, 586, 584)\n(1, 586, 584)\n\n\nDask graph\n10 chunks in 1 graph layer\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                           584 586 10\n\n\n\n\ncog(time, y, x)float32dask.array&lt;chunksize=(1, 586, 584), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n13.05 MiB\n1.31 MiB\n\n\nShape\n(10, 586, 584)\n(1, 586, 584)\n\n\nDask graph\n10 chunks in 1 graph layer\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                           584 586 10\n\n\n\n\nvalid_pixels(time, y, x)float32dask.array&lt;chunksize=(1, 586, 584), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n13.05 MiB\n1.31 MiB\n\n\nShape\n(10, 586, 584)\n(1, 586, 584)\n\n\nDask graph\n10 chunks in 1 graph layer\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                           584 586 10\n\n\n\n\nsaturated_pixels(time, y, x)float32dask.array&lt;chunksize=(1, 586, 584), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n13.05 MiB\n1.31 MiB\n\n\nShape\n(10, 586, 584)\n(1, 586, 584)\n\n\nDask graph\n10 chunks in 1 graph layer\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n                                           584 586 10\n\n\n\n\nIndexes: (3)yPandasIndexPandasIndex(Index([7027680.0, 7027360.0, 7027040.0, 7026720.0, 7026400.0, 7026080.0,\n       7025760.0, 7025440.0, 7025120.0, 7024800.0,\n       ...\n       6843360.0, 6843040.0, 6842720.0, 6842400.0, 6842080.0, 6841760.0,\n       6841440.0, 6841120.0, 6840800.0, 6840480.0],\n      dtype='float64', name='y', length=586))xPandasIndexPandasIndex(Index([-170720.0, -170400.0, -170080.0, -169760.0, -169440.0, -169120.0,\n       -168800.0, -168480.0, -168160.0, -167840.0,\n       ...\n         12960.0,   13280.0,   13600.0,   13920.0,   14240.0,   14560.0,\n         14880.0,   15200.0,   15520.0,   15840.0],\n      dtype='float64', name='x', length=584))timePandasIndexPandasIndex(DatetimeIndex(['2023-01-24 11:23:41', '2023-01-26 11:12:39',\n               '2023-01-29 11:22:29', '2023-01-31 11:13:11',\n               '2023-02-08 11:21:29', '2023-02-13 11:21:51',\n               '2023-02-15 11:10:49', '2023-02-20 11:11:01',\n               '2023-02-23 11:21:11', '2023-02-25 11:09:39'],\n              dtype='datetime64[ns]', name='time', freq=None))Attributes: (0)\n\n\n\n# DATA FOOTPRINT\n#xx.odc.geobox\n\n# TEST\nxx.data_vars[cog]\n\n\n%%time\nxx = xx.compute() # LOAD INTO LOCAL MEMORY",
    "crumbs": [
      "Presentations",
      "DEFRA Data Analysis"
    ]
  },
  {
    "objectID": "website/about.html",
    "href": "website/about.html",
    "title": "About",
    "section": "",
    "text": "What is EODH\n\n\nResources on this website",
    "crumbs": [
      "About"
    ]
  }
]