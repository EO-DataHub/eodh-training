{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Description & purpose__: This Notebook explains what a workflow is (in the context of the EODH platform) and provides information on the technology surrounding the workflows. \n",
    "\n",
    "__Author(s)__: Alastair Graham\n",
    "\n",
    "__Date created__: 2024-11-08\n",
    "\n",
    "__Date last modified__: 2025-03-11\n",
    "\n",
    "__Licence__: This file is licensed under [Creative Commons Attribution-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-sa/4.0/).  Any included code is released using the [BSD-2-Clause](https://www.tldrlegal.com/license/bsd-2-clause-license-freebsd) license.\n",
    "\n",
    "\n",
    "<span style=\"font-size:0.75em;\">\n",
    "Copyright (c) , All rights reserved.</span>\n",
    "\n",
    "<span style=\"font-size:0.75em;\">\n",
    "Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</span>\n",
    "\n",
    "<span style=\"font-size:0.75em;\">\n",
    "Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is a Workflow\n",
    "\n",
    "One of the provisioned services made available to users of the EODH is the Workflow Runner (WR). More information about the WR is provided later on this page, but the fundamental question that requires answering is...\n",
    "\n",
    "<p style=\"text-align:center;\"> In the context of the EODH, what is a workflow? </p>\n",
    "\n",
    "Using the terminology of the EODH, a workflow is a file written in CWL (the Common Workflow Language) that creates a data processing chain. However, this CWL file only provides the orchestration of a wider set of tools that are brought together as an entity known as an Earth Observation Application Package (EOAP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is the Workflow Runner?\n",
    "\n",
    "The WR is a required component of the Hub, designed to interprate CWL files and ensure that the algorithms wrapped within them are sensibly scaled across the available infrastructure. In the case of the EODH, the infrastructure is a Kubernetes cluster running on an AWS backend, but this is not a hard-set requirement. \n",
    "\n",
    "The WR itself is a piece of software called ADES. If you want to understand the internal components of the WR then the ADES Design Document is available here: https://eoepca.github.io/proc-ades/master/. \n",
    "\n",
    "The use case is that EOAPs can be transfered from platform to platform e.g. they could be developed on EODH and run on EOEPCA or the other way round. Platforms run by DLR and NASA also utilise EOAPs and processing algorithms can be shared between them.  \n",
    "\n",
    "The ADES software uses the [ZOO-Project](https://github.com/ZOO-Project) as the main framework for exposing the OGC compliant web services. The ZOO-kernel powering the web services is included in the software package.\n",
    "\n",
    "The ADES functions are designed to perform the processing and chaining function on a Kubernetes cluster using the Calrissian Tool. Calrissian uses CWL over Kubernetes and enables the implementation of each step in a workflow as a container. It provides simple, flexible mechanisms for specifying constraints between the steps in a workflow and artifact management for linking the output of any step as an input to subsequent steps."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is CWL?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why CWL?\n",
    "The Common Workflow Language (CWL) is an open standard designed for defining and executing data analysis workflows. It provides a formal way to describe the individual steps in a workflow, the inputs and outputs of each step, and how those steps are connected. CWL is platform-independent and focuses on portability, reproducibility, and scalability, enabling workflows to be executed in various environments, from personal computers to large cloud infrastructures.\n",
    "\n",
    "By fostering collaboration and standardisation, CWL plays a crucial role in advancing research, and is particularly used in fields such as bioinformatics and climate science.\n",
    "\n",
    "## Scripting workflows\n",
    "\n",
    "While shell scripts or other code scripts (e.g. Python) can meet the need of data processing workflows, using a formal workflow language (such as CWL) brings additional benefits such as abstraction and improved scalability and portability. \n",
    "\n",
    "Computational workflows explicitly create a divide between a userâ€™s dataflow and the computational details which underpin the chain of tools. \n",
    "\n",
    "The dataflow is described by the workflow and the tool implementation is specified by descriptors that remove the workflow complexity.\n",
    "\n",
    "Workflow managers such as `cwltool` (see below) help with the automation, monitoring and tracking of a dataflow. By producing computational workflows in a standardised format, and publishing them (alongside any data) with open access, the workflows become more FAIR (Findable, Accessible, Interoperable, and Reusable). The Common Workflow Language (CWL) standard has been developed to standardise workflow needs across different thematic areas.\n",
    "\n",
    "## Execution sequence\n",
    "The generic execution sequence of a CWL process (including Workflows and CommandLineTools) is as follows.\n",
    "\n",
    "* Load an input object.\n",
    "* Load, process and validate a CWL document.\n",
    "* If there are multiple process objects (due to $graph) then choose the process with the id of \"#main\" or \"main\".\n",
    "* Validate the input object against the inputs schema for the process.\n",
    "* Perform any further setup required by the specific process type.\n",
    "* Execute the process.\n",
    "* Capture results of process execution into the output object.\n",
    "* Validate the output object against the outputs schema for the process.\n",
    "* Report the output object to the process caller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A simple example to introduce CWL\n",
    "## Context\n",
    "**Note**: This workflow has been designed and tested using `cwltool` on a local machine.\n",
    "\n",
    "The first thing to do when designing a workflow is understand the context of what is desired, and how that may need to be referred to in the workflow. For this example workflow, we will take a list of Sentinel-2 ARD images, clip them to an area of interest, and stack them. The flow will look like the following:\n",
    "\n",
    "```mermaid\n",
    "graph LR;\n",
    "  get_data -- S2_ARD --> clip -- clipped --> stack -- stacked--> Output ;\n",
    "\n",
    "```\n",
    "\n",
    "The next thing to do is access the data to be used in the Workflow. In this case we will download two bands of a Sentinel 2 image held on AWS. We will use the [curl](https://curl.se/) tool to do this, saving the accessed image as `B0$.tif` (where $ is the band number):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "curl -o B04.tif https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B04.tif\n",
    "\n",
    "curl -o B03.tif https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/H/PA/2021/7/S2B_53HPA_20210723_0_L2A/B03.tif "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The commands that we will use in the workflow are all available through [gdal](https://gdal.org/index.html).  \n",
    "\n",
    "### Clip the image\n",
    "We will use `gdal_-_translate` to clip the larger image to a smaller more manageable dataset. The gdal command that we can test and that we will need to replicate in CWL is: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "gdal_translate -projwin ULX ULY LRX LRY  -projwin_srs EPSG:4326 BO4.tif B04_clipped.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where the coordinates UL refer to upper left and LR to lower right X and Y.\n",
    "\n",
    "### Stack the clips\n",
    "Similarly, we will use `gdal_merge.py` to construct the stacked images from the clipped image. This can be tested using the following command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "gdal_merge.py -separate B04_clipped.tif B03_clipped.tif -o stacked.tif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Workflow\n",
    "### Required files\n",
    "There are three main files that are required to construct a CWL Workflow. These are:\n",
    "* DockerFile or existing online container\n",
    "* CWL file\n",
    "* YAML file\n",
    "\n",
    "It may be that other files e.g. a .sh script or a Python script are also needed, depending on how bespoke and/or complex the desired workflow is. \n",
    "\n",
    "### cwltool\n",
    "To run CWL workflows you will need a CWL runner. The most commonly used (locally) is `cwltool` which is maintained by the CWL community. `cwltool` is the reference executor for Common Workflow Language standards and  supports everything in the current CWL specification. `cwltool` can be installed using `pip` or variants of `conda`. More information can be found [here](https://www.commonwl.org/user_guide/introduction/prerequisites.html) and [here](https://cwl-for-eo.github.io/guide/requirements/), or via [ReadTheDocs](https://cwltool.readthedocs.io/en/latest/cli.html). \n",
    "\n",
    "### Containers\n",
    "For the purposes of this example, we will be pulling the GDAL container from the OSgeo repository (see [here](https://github.com/OSGeo/gdal/tree/master/docker)).\n",
    "\n",
    "**NOTE**: There are a number of different images that can be accessed. To use the .py tools available through GDAL then 'GDAL Python' is required.\n",
    "\n",
    "If we wanted to we could also build our own bespoke image using a DockerFile and then run that. This is often used when data processing scripts need to be copied into the container.\n",
    "\n",
    "We will also be using [Podman](https://podman.io/) as our container software. 'podman' is a drop in replacement for Docker but does require the `--podman` arguement in the `cwltool` command. If using Windows, or if you are more familiar with Docker, then using Docker is the default containerisation method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CWL files\n",
    "For this example we require a CWL CommandLine file for both the clipping and stacking components of the workflow. We will also need a CWL Workflow file to bring these together and run the entire process. The next block of code outlines the overall Workflow file.\n",
    "\n",
    "**Note**: This example is based on the example found [here](https://cwl-for-eo.github.io/guide/101/cwl-101/tutorial-2/workflow/). Some errors were found in the original CWL files and the version presented here has been tested and is known to work on a local Linux (Debian based) system. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class: Workflow\n",
    "label: Sentinel-2 clipping and stacking\n",
    "doc:  This workflow creates a stacked composite. File name: composite.cwl\n",
    "id: main\n",
    "\n",
    "requirements:\n",
    "- class: ScatterFeatureRequirement\n",
    "\n",
    "inputs:\n",
    "\n",
    "  geotiff:\n",
    "    doc: list of geotifs\n",
    "    type: File[]\n",
    "\n",
    "  bbox: \n",
    "    doc: area of interest as a bounding box\n",
    "    type: string\n",
    "\n",
    "  epsg:\n",
    "    doc: EPSG code \n",
    "    type: string\n",
    "    default: \"EPSG:4326\"\n",
    "\n",
    "outputs:\n",
    "  rgb:\n",
    "    outputSource:\n",
    "    - node_concatenate/composite\n",
    "    type: File\n",
    "\n",
    "steps:\n",
    "\n",
    "  node_translate:\n",
    "\n",
    "    run: gdal-translate.cwl\n",
    "\n",
    "    in:\n",
    "\n",
    "      geotiff: geotiff  \n",
    "      bbox: bbox\n",
    "      epsg: epsg\n",
    "\n",
    "    out:\n",
    "    - clipped_tif\n",
    "\n",
    "    scatter: geotiff\n",
    "    scatterMethod: dotproduct\n",
    "\n",
    "  node_concatenate:\n",
    "\n",
    "    run: concatenate2.cwl\n",
    "\n",
    "    in: \n",
    "      tifs:\n",
    "        source: node_translate/clipped_tif\n",
    "\n",
    "    out:\n",
    "    - composite\n",
    "\n",
    "\n",
    "cwlVersion: v1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this example, we can see that we require two CommandLine CWL files: `gdal-translate.cwl`  and `concatenate2.cwl`. Let's deal with these in order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class: CommandLineTool\n",
    "\n",
    "cwlVersion: v1.0\n",
    "doc:  This runs GDAL Translate to clip an image to bbox corner coordinates.\n",
    "\n",
    "requirements: \n",
    "  InlineJavascriptRequirement: {}\n",
    "  DockerRequirement: \n",
    "    dockerPull: ghcr.io/osgeo/gdal:ubuntu-small-latest\n",
    "\n",
    "baseCommand: gdal_translate\n",
    "\n",
    "arguments:\n",
    "- -projwin \n",
    "- valueFrom: ${ return inputs.bbox.split(\",\")[0]; }\n",
    "- valueFrom: ${ return inputs.bbox.split(\",\")[3]; }\n",
    "- valueFrom: ${ return inputs.bbox.split(\",\")[2]; }\n",
    "- valueFrom: ${ return inputs.bbox.split(\",\")[1]; }\n",
    "- valueFrom: ${ return inputs.geotiff.basename.replace(\".tif\", \"\") + \"_clipped.tif\"; }\n",
    "  position: 8\n",
    "\n",
    "inputs:\n",
    "  geotiff: \n",
    "    type: File\n",
    "    inputBinding:\n",
    "      position: 7\n",
    "  bbox: \n",
    "    type: string\n",
    "  epsg:\n",
    "    type: string\n",
    "    default: \"EPSG:4326\" \n",
    "    inputBinding:\n",
    "      position: 6\n",
    "      prefix: -projwin_srs\n",
    "      separate: true\n",
    "\n",
    "outputs:\n",
    "  clipped_tif:\n",
    "    outputBinding:\n",
    "      glob: '*_clipped.tif'\n",
    "    type: File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "class: CommandLineTool\n",
    "\n",
    "cwlVersion: v1.0\n",
    "doc: This runs GDAL Merge to stack images together.\n",
    "\n",
    "requirements:\n",
    "  InlineJavascriptRequirement: {}\n",
    "  DockerRequirement: \n",
    "    dockerPull: ghcr.io/osgeo/gdal:ubuntu-small-latest\n",
    "\n",
    "baseCommand: gdal_merge.py\n",
    "\n",
    "arguments: \n",
    "- -separate \n",
    "- valueFrom: ${ return inputs.tifs; }\n",
    "- -o\n",
    "- composite.tif\n",
    "# gdal_merge.py -separate 1.tif 2.tif 3.tif -o rgb.tif\n",
    "\n",
    "inputs:\n",
    "\n",
    "  tifs:\n",
    "    type: File[]\n",
    "\n",
    "outputs:\n",
    "\n",
    "  composite:\n",
    "    outputBinding:\n",
    "      glob: '*.tif'\n",
    "    type: File"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: YAML generally doesn't play well with tabs as whitespace so it's best practice to use spaces for indentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the Workflow\n",
    "Now that we have our commandline CWL component files, and the Workflow CWL file that brings the tools together, we need to specify the input parameters. This is done using a `parameters.yml` file, where the name of the file can be anything that you want. The contents should follow the layout that we will be using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "bbox: \"136.659,-35.96,136.923,-35.791\"\n",
    "geotiff: \n",
    "- { \"class\": \"File\", \"path\": \"../B04.tif\" }\n",
    "- { \"class\": \"File\", \"path\": \"../B03.tif\" }\n",
    "epsg: \"EPSG:4326\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to change the `path` parameter to match the location of your input files. \n",
    "\n",
    "Now we run it with the command:\n",
    "\n",
    "`cwltool --podman composite.cwl composite-params.yml`\n",
    "\n",
    "**Note**: remember that if you are using Docker then you do not need the `--podman` arguement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "This workflow takes a couple of minutes to run, during which time the executed commands and their runtime messages are displayed on the command line. Once the workflow completes, the output file will be found in the directory from where the workflow was run. Intermediate files that are not specified in the out block in the workflow are automatically deleted.\n",
    "\n",
    "The output .tif file can now be opened in QGIS or a similar software application to check that the output is as expected (in this case a 2-layer image of a clipped area of the extent of the input files).\n",
    "\n",
    "## Tips\n",
    "You can pass `--leave-tmpdirs` to the `cwltool` command. This is often helpful to figure out if the outputs from a step are what you think they should be.\n",
    "\n",
    "Another [good (non-spatial) tutorial can be found here](https://andrewjesaitis.com/posts/2017-02-06-cwl-tutorial/)\n",
    "\n",
    "If you have a CWL file in an earlier version than the current one (1.2 in March 2025) then it can be updated using a useful tool called [CWL Upgrader](https://github.com/common-workflow-language/cwl-upgrader). That said, earlier versions should run on the Workflow Runner on the Hub."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
