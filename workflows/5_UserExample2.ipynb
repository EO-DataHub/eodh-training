{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Example: Temporal Mosaics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Description & purpose__: This Notebook introduces the science behind a user example looking to create temporal best pixel temporal mosaics using the Sentinel 2 ARD dataset. It also introduces the EOAP that has been created to run a scaled workflow on EODH.\n",
    "\n",
    "__Author(s)__: Alastair Graham, Dusan Figala\n",
    "\n",
    "__Date created__: 2024-11-08\n",
    "\n",
    "__Date last modified__: 2025-03-11\n",
    "\n",
    "__Licence__: This file is licensed under [Creative Commons Attribution-ShareAlike 4.0 International](https://creativecommons.org/licenses/by-sa/4.0/).  Any included code is released using the [BSD-2-Clause](https://www.tldrlegal.com/license/bsd-2-clause-license-freebsd) license.\n",
    "\n",
    "\n",
    "<span style=\"font-size:0.75em;\">\n",
    "Copyright (c) , All rights reserved.</span>\n",
    "\n",
    "<span style=\"font-size:0.75em;\">\n",
    "Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:</span>\n",
    "\n",
    "<span style=\"font-size:0.75em;\">\n",
    "Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution. THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS \"AS IS\" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we are required to create a dataset that is cloud-free and temporally mosaiced. The input dataset is to be the CEDA Sentinel 2 ARD image data. \n",
    "\n",
    "Cloud-free temporal mosaics of optical satellite images are composites created by combining multiple satellite acquisitions over a specific time period to generate a seamless and cloud-free view of a region. Optical satellite imagery, such as data from Sentinel-2, is often obstructed by clouds and atmospheric conditions, limiting the usability of individual acquisitions. Temporal mosaics overcome this challenge by selecting the clearest pixels from a time series of images, typically based on cloud masking algorithms or quality indices. These mosaics preserve spatial and spectral information while minimizing data gaps caused by clouds. Additional methods of data creation include using cloud-masks to remove clouds and/or shadow before the mosaicing step. \n",
    "\n",
    "A user would want a cloud-free temporal mosaic of Sentinel-2 data to ensure consistent, high-quality imagery for analyzing surface features and environmental changes without the interference of clouds or shadows. Sentinel-2, part of the European Space Agency's Copernicus program, provides high-resolution optical imagery across 13 spectral bands, making it ideal for applications in agriculture, forestry, urban planning, and climate monitoring. By creating a cloud-free mosaic, users can integrate multiple acquisitions into a single, seamless dataset that eliminates gaps caused by clouds and ensures better temporal and spatial coverage.\n",
    "\n",
    "Analysis Ready Data (ARD) refers to satellite data that has been pre-processed and formatted to a standardized level, enabling users to perform analysis without needing to conduct significant additional preprocessing. ARD is designed to be easily accessible, interoperable, and suitable for a wide range of scientific and operational applications. The pre-processing typically includes geometric correction, radiometric calibration and atmospheric correction (removing the effects of the atmosphere on reflectance). It may also include cloud masking. The aim of creating ARD is to ensure data is consistent across time and space, and minimise the technical barriers for users, allowing them to focus on extracting insights rather than preparing raw data. By eliminating much of the preprocessing workload, ARD democratises the use of satellite data, allowing non-specialists and researchers to use the data more efficiently and reliably.\n",
    "\n",
    "Such temporal mosaics are particularly valuable for applications requiring reliable, large-area analysis. For example, in agriculture, a cloud-free mosaic allows precise monitoring of crop health, phenological changes, and yield estimation by preserving uninterrupted vegetation indices. In forestry, it supports accurate assessments of deforestation, canopy density, and biomass. For urban planning and disaster management, cloud-free mosaics provide unobstructed views of land use changes, infrastructure, and affected regions, critical for decision-making. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Scientific Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before creating a workflow on the EODH platform it was important to step through the scientific process to make sure that the correct tools and data were being considered.\n",
    "\n",
    "To create the cloud-free outputs we use the cloud mask supplied with the ARD dataset. The information held in the cloud mask layer is used to block out the existing areas of cloud, and is applied to every band.\n",
    "\n",
    "The temporal mosaic is created using a command line set of tools called `pktools`. Although a slightly older set of tools it is incredibly versatile, and being command-line first lends itself to the EOAP/CWl way of working. One of the tools, [pkcomposite](https://pktools.nongnu.org/html/pkcomposite.html), is used to generate a median image from all input images over a one month period.  \n",
    "\n",
    "### Processing steps\n",
    "\n",
    "- pyeodh search of sentinel2_ard STAC (inputs are an AOI polygon (we need this later) and a date range)\n",
    "- STEP 1: for each band in each returned image apply the cloud mask to remove cloud pixels from the data\n",
    "  - this results in a multibanded image that is cloud-masked\n",
    "  - need to retain information on original image capture date\n",
    "  - output should be a temporary STAC catalog\n",
    "- STEP 2: for each cloud-masked image in a given month create band composites cropped to the AOI\n",
    "  - e.g. `pkcomposite -i in_A.tif -i in_B.tif -i in_C.tif -o out_b1.tif -cr median -b 0 -e aoi.geojson`\n",
    "  - need to be able to supply all images, the aoi polygon, and the composite method (e.g. median)\n",
    "  - output should be a STAC catalog of spatially cropped single-band composites for each month (e.g. for a three month period and 4 band input data\n",
    "    there should be 3x Band1 outputs, 3x Band2 outputs, 3x Band3 outputs, 3x Band4 outputs)\n",
    "\n",
    "\n",
    "The following tutorial demonstrates how to process data held in the Sentinel S2 ARD STAC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scientific method\n",
    "\n",
    "First we need to import the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyeodh\n",
    "import xarray as xr\n",
    "import rioxarray\n",
    "import os\n",
    "from pathlib import Path\n",
    "import requests\n",
    "import threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the area of interest\n",
    "\n",
    "thetford_aoi = {\n",
    "    \"coordinates\": [\n",
    "        [\n",
    "            [0.08905898091569497, 52.69722175598818],\n",
    "            [0.08905898091569497, 52.15527412683906],\n",
    "            [0.9565339502005088, 52.15527412683906],\n",
    "            [0.9565339502005088, 52.69722175598818],\n",
    "            [0.08905898091569497, 52.69722175598818],\n",
    "        ]\n",
    "    ],\n",
    "    \"type\": \"Polygon\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to connect to the resource catalogue and undertake a search of the sentinel2_ard catalogue for the AOI location within a specific date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to \n",
    "rc = pyeodh.Client(\n",
    "    base_url=\"https://staging.eodatahub.org.uk\"\n",
    "    ).get_catalog_service()\n",
    "\n",
    "items = rc.search(\n",
    "    collections=[\"sentinel2_ard\"],\n",
    "    catalog_paths=[\"supported-datasets/catalogs/ceda-stac-catalogue\"],\n",
    "    intersects=thetford_aoi,\n",
    "    query=[\n",
    "        \"start_datetime>=2023-04-01\",\n",
    "        \"end_datetime<=2023-06-30\",\n",
    "    ],\n",
    "    limit=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, for each item open the `cog`, `cloud` and `valid` .tif assets and download them if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in items.get_limited()[0:1]:\n",
    "    cloud_href = item.assets[\"cloud\"].href\n",
    "    valid_href = item.assets[\"valid_pixels\"].href\n",
    "    cog_href = item.assets[\"cog\"].href\n",
    "    item\n",
    "    print(item.id, cloud_href, valid_href, cog_href, sep=\"\\n\")\n",
    "    valid = rioxarray.open_rasterio(\n",
    "        valid_href,\n",
    "        chunks=True,\n",
    "    )\n",
    "    cloud = rioxarray.open_rasterio(\n",
    "        cloud_href,\n",
    "        chunks=True,\n",
    "    )\n",
    "\n",
    "    # Check if cog file exists locally, if not download it\n",
    "    cog_filename = f\"data/{Path(cog_href).name}\"\n",
    "    if not os.path.isfile(cog_filename):\n",
    "        with requests.get(cog_href, stream=True) as r:\n",
    "            r.raise_for_status()\n",
    "            with open(cog_filename, \"wb\") as f:\n",
    "                for chunk in r.iter_content(chunk_size=8192):\n",
    "                    f.write(chunk)\n",
    "\n",
    "    cog = rioxarray.open_rasterio(cog_filename, chunks=True)\n",
    "    print(\"==\" * 10)\n",
    "    print(\"success\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next steps are to create a definitive mask using the amalgamation of the valid pixels layer and the cloud mask layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = valid + cloud\n",
    "\n",
    "# Set values greater than 1 to 0, others remain as 1\n",
    "result = xr.where(result > 1, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we now multiply the cloud optimised geotif file by the `result` maskfile, expanded to match the shape of `cog` then each of the bands will have the clouds removed. This is a brute force approach for the purposes of generating a demonstrable workflow and in an operational context a user would likely want to undertand the impact of cloud in individual bands and use specific methods to remove that. \n",
    "\n",
    "Finally the output is saved to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiply cog.tif by the result\n",
    "# We need to expand the result to match the shape of cog\n",
    "fin = cog * result.squeeze(\"band\").expand_dims(band=cog.band)\n",
    "\n",
    "# save to a file\n",
    "fin.rio.to_raster(raster_path=f\"data/rm_cloud.tif\", tiled=True, lock=threading.Lock())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As mentioned, one method of generating the composite is to use `pktools`. It's an older code, but it checks out. An alternative using Python might be to use xarray and the functions within that package. `pktools` works well for this use case as the command can be inserted directly into the workflow CWL. More information regarding this excellent tool can be found here:    \n",
    "\n",
    "https://pktools.nongnu.org/html/pkcomposite.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outputs\n",
    "\n",
    "The following images provide an indication of how the pkcomposite tool works. The first image shows three input images (single band in this instance, coloured red, green and blue for clarity) that overlap a specific area of interest. The AOI is marked by the red boundary.\n",
    "\n",
    "![](../img/tc1.png){width=700px}\n",
    "\n",
    "The second image plots the result of the pkcomposite command over the top. It shows how a median layer is created within the bounding box of the AOI.  \n",
    "\n",
    "![](../img/tc2.png){width=700px}\n",
    "\n",
    "In an EOAP cointext this could be scaled up across multiple multi-band images for a larger AOI. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other methods\n",
    "There are plenty of alternative ways in which the cloudless mosaic could be generated. One example is shown [here](https://planetarycomputer.microsoft.com/docs/tutorials/cloudless-mosaic-sentinel2/#Discover-data) for the Planetary Computer. It should be reasonably easy to transfer the procesisng chain explained in that example into something that would run in the JupyterHub instance on the EODH."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating the workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use `eoap-gen` to create a suitable workflow for this methodology. The first thing to do is understand the steps and the flow of data through the EODH workflow runner. The following diagram demonstrates how images are searched for and then scattered across numerous processing nodes to remove the cloud. The cloud-free images are then returned to fewer nodes to be mosaiced by month. Finally the mosaics are written out to a searchable STAC directory.  \n",
    "\n",
    "![Cloudfree Workflow](../img/cfm.png){width=900px}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the configuration file [here](https://github.com/EO-DataHub/user-workflows/blob/main/S2-cloud-free-best-pixel/eoap-gen-config.yml) and reproduced below, it is possible to run `eoap-gen` to create the full package requirements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id: cloud-free-best-pixel\n",
    "doc: Generate cloud free best pixel mosaic on a per month basis\n",
    "label: Cloud free best pixel\n",
    "\n",
    "resources: # current ADES max is 4 cores and 16GB RAM, we need all we can get\n",
    "  cores_min: 4\n",
    "  ram_min: 16000\n",
    "\n",
    "inputs:\n",
    "  - id: catalog\n",
    "    label: Catalog path\n",
    "    doc: Full catalog path\n",
    "    type: string\n",
    "    default: supported-datasets/ceda-stac-catalogue\n",
    "  - id: collection\n",
    "    label: collection id\n",
    "    doc: collection id\n",
    "    type: string\n",
    "    default: sentinel2_ard\n",
    "  - id: intersects\n",
    "    label: Intersects\n",
    "    doc: >\n",
    "      a GeoJSON-like json string, which provides a \"type\" member describing the type of the geometry and \"coordinates\" \n",
    "      member providing a list of coordinates. Will search for images intersecting this geometry.\n",
    "    type: string\n",
    "    default: >\n",
    "      {\n",
    "        \"type\": \"Polygon\",\n",
    "        \"coordinates\": [\n",
    "          [\n",
    "            [0.08905898091569497, 52.69722175598818],\n",
    "            [0.08905898091569497, 52.15527412683906],\n",
    "            [0.9565339502005088, 52.15527412683906],\n",
    "            [0.9565339502005088, 52.69722175598818],\n",
    "            [0.08905898091569497, 52.69722175598818]\n",
    "          ]\n",
    "        ]\n",
    "      }\n",
    "  - id: start_datetime\n",
    "    label: Start datetime\n",
    "    doc: Start datetime\n",
    "    type: string\n",
    "    default: \"2023-04-01\"\n",
    "  - id: end_datetime\n",
    "    label: End datetime\n",
    "    doc: End datetime\n",
    "    type: string\n",
    "    default: \"2023-06-30\"\n",
    "\n",
    "outputs:\n",
    "  - id: stac_output\n",
    "    type: Directory\n",
    "    source: s2_make_stac/stac_catalog\n",
    "steps:\n",
    "  - id: s2_search\n",
    "    script: S2-cloud-free-best-pixel/cli/search/search.py\n",
    "    requirements: S2-cloud-free-best-pixel/cli/search/requirements.txt\n",
    "    inputs:\n",
    "      - id: catalog\n",
    "        source: cloud-free-best-pixel/catalog\n",
    "      - id: collection\n",
    "        source: cloud-free-best-pixel/collection\n",
    "      - id: intersects\n",
    "        source: cloud-free-best-pixel/intersects\n",
    "      - id: start_datetime\n",
    "        source: cloud-free-best-pixel/start_datetime\n",
    "      - id: end_datetime\n",
    "        source: cloud-free-best-pixel/end_datetime\n",
    "    outputs:\n",
    "      - id: urls\n",
    "        type: string[]\n",
    "        outputBinding:\n",
    "          loadContents: true\n",
    "          glob: urls.txt\n",
    "          outputEval: $(self[0].contents.split('\\n'))\n",
    "      - id: months\n",
    "        type: File[]\n",
    "        outputBinding:\n",
    "          glob: month_*.json\n",
    "\n",
    "  - id: s2_rm_cloud\n",
    "    script: S2-cloud-free-best-pixel/cli/rm_cloud/rm_cloud.py\n",
    "    requirements: S2-cloud-free-best-pixel/cli/rm_cloud/requirements.txt\n",
    "    conda:\n",
    "      - dask\n",
    "      - gdal\n",
    "    scatter_method: dotproduct\n",
    "    inputs:\n",
    "      - id: item_url\n",
    "        source: s2_search/urls\n",
    "        scatter: true\n",
    "    outputs:\n",
    "      - id: cloud_masked\n",
    "        type: File\n",
    "        outputBinding:\n",
    "          glob: \"*.tif\"\n",
    "\n",
    "  - id: s2_mosaic\n",
    "    script: S2-cloud-free-best-pixel/cli/mosaic/mosaic.py\n",
    "    requirements: S2-cloud-free-best-pixel/cli/mosaic/requirements.txt\n",
    "    apt_install:\n",
    "      - pktools\n",
    "    scatter_method: dotproduct\n",
    "    inputs:\n",
    "      - id: intersects\n",
    "        source: cloud-free-best-pixel/intersects\n",
    "      - id: month_json\n",
    "        source: s2_search/months\n",
    "        scatter: true\n",
    "        type: File\n",
    "      - id: all_images\n",
    "        source: s2_rm_cloud/cloud_masked\n",
    "        type: File[]\n",
    "    outputs:\n",
    "      - id: best_pixel\n",
    "        type: File\n",
    "        outputBinding:\n",
    "          glob: \"*.tif\"\n",
    "\n",
    "  - id: s2_make_stac\n",
    "    script: S2-cloud-free-best-pixel/cli/make_stac/make_stac.py\n",
    "    requirements: S2-cloud-free-best-pixel/cli/make_stac/requirements.txt\n",
    "    inputs:\n",
    "      - id: geometry\n",
    "        source: cloud-free-best-pixel/intersects\n",
    "      - id: files\n",
    "        source: s2_mosaic/best_pixel\n",
    "        type: File[]\n",
    "    outputs:\n",
    "      - id: stac_catalog\n",
    "        outputBinding:\n",
    "          glob: .\n",
    "        type: Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running the configuration file results in the directory available [here](https://github.com/EO-DataHub/user-workflows/tree/main/S2-cloud-free-best-pixel/eoap-gen-out/cli) which can then be submitted to EODH using `pyeodh` and run using either the API client or QGIS plugin. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "workflows",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
